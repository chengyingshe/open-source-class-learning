{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYlaRwNu7ojq"
      },
      "source": [
        "# **Homework 2: Phoneme Classification**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7DRC5V7_8A5"
      },
      "source": [
        "Objectives:\n",
        "* Solve a classification problem with deep neural networks (DNNs).\n",
        "* Understand recursive neural networks (RNNs).\n",
        "\n",
        "If you have any questions, please contact the TAs via TA hours, NTU COOL, or email to mlta-2023-spring@googlegroups.com"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVUGfWTo7_Oj"
      },
      "source": [
        "# Download Data\n",
        "Download data from google drive, then unzip it.\n",
        "\n",
        "You should have\n",
        "- `libriphone/train_split.txt`: training metadata\n",
        "- `libriphone/train_labels`: training labels\n",
        "- `libriphone/test_split.txt`: testing metadata\n",
        "- `libriphone/feat/train/*.pt`: training feature\n",
        "- `libriphone/feat/test/*.pt`:  testing feature\n",
        "\n",
        "after running the following block.\n",
        "\n",
        "> **Notes: if the google drive link is dead, you can download the data directly from [Kaggle](https://www.kaggle.com/c/ml2023spring-hw2/data) and upload it to the workspace.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzkiMEcC3Foq",
        "outputId": "d488b8e6-5886-4e29-ee97-ac41d72dd416"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
            "Requirement already satisfied: gdown in d:\\anaconda3\\envs\\cv\\lib\\site-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in d:\\anaconda3\\envs\\cv\\lib\\site-packages (from gdown) (4.12.3)\n",
            "Requirement already satisfied: filelock in d:\\anaconda3\\envs\\cv\\lib\\site-packages (from gdown) (3.15.4)\n",
            "Requirement already satisfied: requests[socks] in d:\\anaconda3\\envs\\cv\\lib\\site-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in d:\\anaconda3\\envs\\cv\\lib\\site-packages (from gdown) (4.66.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in d:\\anaconda3\\envs\\cv\\lib\\site-packages (from beautifulsoup4->gdown) (2.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda3\\envs\\cv\\lib\\site-packages (from requests[socks]->gdown) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda3\\envs\\cv\\lib\\site-packages (from requests[socks]->gdown) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda3\\envs\\cv\\lib\\site-packages (from requests[socks]->gdown) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda3\\envs\\cv\\lib\\site-packages (from requests[socks]->gdown) (2024.6.2)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in d:\\anaconda3\\envs\\cv\\lib\\site-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Requirement already satisfied: colorama in d:\\anaconda3\\envs\\cv\\lib\\site-packages (from tqdm->gdown) (0.4.6)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "D:\\Anaconda3\\envs\\cv\\lib\\site-packages\\gdown\\__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Failed to retrieve file url:\n",
            "\n",
            "\tCannot retrieve the public link of the file. You may need to change\n",
            "\tthe permission to 'Anyone with the link', or have had many accesses.\n",
            "\tCheck FAQ in https://github.com/wkentaro/gdown?tab=readme-ov-file#faq.\n",
            "\n",
            "You may still be able to access the file from the browser:\n",
            "\n",
            "\thttps://drive.google.com/uc?id='1qzCRnywKh30mTbWUEjXuNT2isOCAPdO1'\n",
            "\n",
            "but Gdown can't. Please check connections and permissions.\n",
            "unzip:  cannot find either libriphone.zip or libriphone.zip.zip.\n",
            "'ls' �����ڲ����ⲿ���Ҳ���ǿ����еĳ���\n",
            "���������ļ���\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade gdown\n",
        "\n",
        "# Main link\n",
        "# !gdown --id '1N1eVIDe9hKM5uiNRGmifBlwSDGiVXPJe' --output libriphone.zip\n",
        "!gdown --id '1qzCRnywKh30mTbWUEjXuNT2isOCAPdO1' --output libriphone.zip\n",
        "\n",
        "!unzip -q libriphone.zip\n",
        "!ls libriphone"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pADUiYODJE1O"
      },
      "source": [
        "# Some Utility Functions\n",
        "**Fixes random number generator seeds for reproducibility.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BsZKgBZQJjaE"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import random\n",
        "\n",
        "def same_seeds(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_L_4anls8Drv"
      },
      "source": [
        "**Helper functions to pre-process the training data from raw MFCC features of each utterance.**\n",
        "\n",
        "A phoneme may span several frames and is dependent to past and future frames. \\\n",
        "Hence we concatenate neighboring phonemes for training to achieve higher accuracy. The **concat_feat** function concatenates past and future k frames (total 2k+1 = n frames), and we predict the center frame.\n",
        "\n",
        "Feel free to modify the data preprocess functions, but **do not drop any frame** (if you modify the functions, remember to check that the number of frames are the same as mentioned in the slides)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IJjLT8em-y9G"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "def load_feat(path):\n",
        "    feat = torch.load(path)\n",
        "    return feat\n",
        "\n",
        "def shift(x, n):\n",
        "    if n < 0:\n",
        "        left = x[0].repeat(-n, 1)\n",
        "        right = x[:n]\n",
        "    elif n > 0:\n",
        "        right = x[-1].repeat(n, 1)\n",
        "        left = x[n:]\n",
        "    else:\n",
        "        return x\n",
        "\n",
        "    return torch.cat((left, right), dim=0)\n",
        "\n",
        "def concat_feat(x, concat_n):\n",
        "    assert concat_n % 2 == 1 # n must be odd\n",
        "    if concat_n < 2:\n",
        "        return x\n",
        "    seq_len, feature_dim = x.size(0), x.size(1)\n",
        "    x = x.repeat(1, concat_n)\n",
        "    x = x.view(seq_len, concat_n, feature_dim).permute(1, 0, 2) # concat_n, seq_len, feature_dim\n",
        "    mid = (concat_n // 2)\n",
        "    for r_idx in range(1, mid+1):\n",
        "        x[mid + r_idx, :] = shift(x[mid + r_idx], r_idx)\n",
        "        x[mid - r_idx, :] = shift(x[mid - r_idx], -r_idx)\n",
        "\n",
        "    return x.permute(1, 0, 2).view(seq_len, concat_n * feature_dim)\n",
        "\n",
        "def preprocess_data(split, feat_dir, phone_path, concat_nframes, train_ratio=0.8, random_seed=1213):\n",
        "    class_num = 41 # NOTE: pre-computed, should not need change\n",
        "\n",
        "    if split == 'train' or split == 'val':\n",
        "        mode = 'train'\n",
        "    elif split == 'test':\n",
        "        mode = 'test'\n",
        "    else:\n",
        "        raise ValueError('Invalid \\'split\\' argument for dataset: PhoneDataset!')\n",
        "\n",
        "    label_dict = {}\n",
        "    if mode == 'train':\n",
        "        for line in open(os.path.join(phone_path, f'{mode}_labels.txt')).readlines():\n",
        "            line = line.strip('\\n').split(' ')\n",
        "            label_dict[line[0]] = [int(p) for p in line[1:]]\n",
        "\n",
        "        # split training and validation data\n",
        "        usage_list = open(os.path.join(phone_path, 'train_split.txt')).readlines()\n",
        "        random.seed(random_seed)\n",
        "        random.shuffle(usage_list)\n",
        "        train_len = int(len(usage_list) * train_ratio)\n",
        "        usage_list = usage_list[:train_len] if split == 'train' else usage_list[train_len:]\n",
        "\n",
        "    elif mode == 'test':\n",
        "        usage_list = open(os.path.join(phone_path, 'test_split.txt')).readlines()\n",
        "\n",
        "    usage_list = [line.strip('\\n') for line in usage_list]\n",
        "    print('[Dataset] - # phone classes: ' + str(class_num) + ', number of utterances for ' + split + ': ' + str(len(usage_list)))\n",
        "\n",
        "    max_len = 3000000\n",
        "    X = torch.empty(max_len, 39 * concat_nframes)\n",
        "    if mode == 'train':\n",
        "        y = torch.empty(max_len, dtype=torch.long)\n",
        "\n",
        "    idx = 0\n",
        "    for i, fname in tqdm(enumerate(usage_list)):\n",
        "        feat = load_feat(os.path.join(feat_dir, mode, f'{fname}.pt'))\n",
        "        cur_len = len(feat)\n",
        "        feat = concat_feat(feat, concat_nframes)\n",
        "        if mode == 'train':\n",
        "          label = torch.LongTensor(label_dict[fname])\n",
        "\n",
        "        X[idx: idx + cur_len, :] = feat\n",
        "        if mode == 'train':\n",
        "          y[idx: idx + cur_len] = label\n",
        "\n",
        "        idx += cur_len\n",
        "\n",
        "    X = X[:idx, :]\n",
        "    if mode == 'train':\n",
        "      y = y[:idx]\n",
        "\n",
        "    print(f'[INFO] {split} set')\n",
        "    print(X.shape)\n",
        "    if mode == 'train':\n",
        "      print(y.shape)\n",
        "      return X, y\n",
        "    else:\n",
        "      return X\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "us5XW_x6udZQ"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Fjf5EcmJtf4e"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class LibriDataset(Dataset):\n",
        "    def __init__(self, X, y=None):\n",
        "        self.data = X\n",
        "        if y is not None:\n",
        "            self.label = torch.LongTensor(y)\n",
        "        else:\n",
        "            self.label = None\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.label is not None:\n",
        "            return self.data[idx], self.label[idx]\n",
        "        else:\n",
        "            return self.data[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRqKNvNZwe3V"
      },
      "source": [
        "# Model\n",
        "Feel free to modify the structure of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Bg-GRd7ywdrL"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, batchnorm=False, dropout=0.0):\n",
        "        super(BasicBlock, self).__init__()\n",
        "\n",
        "        # TODO: apply batch normalization and dropout for strong baseline.\n",
        "        # Reference: https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html (batch normalization)\n",
        "        #       https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html (dropout)\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Linear(input_dim, output_dim),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        if dropout:\n",
        "            self.block.append(nn.Dropout(dropout))\n",
        "        if batchnorm:\n",
        "            self.block.append(nn.BatchNorm1d(output_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.block(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim=41, hidden_layers=1, hidden_dim=256):\n",
        "        super(Classifier, self).__init__()\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            BasicBlock(input_dim, hidden_dim),\n",
        "            *[BasicBlock(hidden_dim, hidden_dim) for _ in range(hidden_layers)],\n",
        "            nn.Linear(hidden_dim, output_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "    \n",
        "class ClassifierV2(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim=41, hidden_layers=1, hidden_dim=256, dropout=0.0):\n",
        "        super().__init__()\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            BasicBlock(input_dim, hidden_dim),\n",
        "            *[BasicBlock(hidden_dim, hidden_dim, batchnorm=True, dropout=dropout) for _ in range(hidden_layers)],\n",
        "            nn.Linear(hidden_dim, output_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class Classifier_GRU(nn.Module):\n",
        "    \"\"\"包含GRU模型的分类器\"\"\"\n",
        "    def __init__(self, input_dim, \n",
        "                 output_dim=41, \n",
        "                 hidden_dim=1024, \n",
        "                 num_layers=2, \n",
        "                 bidirectional=False, \n",
        "                 dropout=0.0,\n",
        "                 mlp_layers=[512, 256]):\n",
        "        super().__init__()\n",
        "        self.bidirectional = bidirectional\n",
        "        self.gru = nn.GRU(input_size=input_dim, \n",
        "                          hidden_size=hidden_dim, \n",
        "                          num_layers=num_layers, \n",
        "                          batch_first=True,\n",
        "                          dropout=dropout,\n",
        "                          bidirectional=bidirectional)\n",
        "        \n",
        "        self.seq_len = None\n",
        "        \n",
        "        self.fc = []\n",
        "        gru_output_dim = hidden_dim * 2 if bidirectional else hidden_dim\n",
        "        for i in range(len(mlp_layers)):\n",
        "            if i == 0:\n",
        "                self.fc.append(nn.Linear(gru_output_dim, mlp_layers[i]))\n",
        "            else:\n",
        "                self.fc.append(nn.Linear(mlp_layers[i-1], mlp_layers[i]))\n",
        "            self.fc.append(nn.ReLU())\n",
        "        self.fc.append(nn.Linear(mlp_layers[-1], output_dim))\n",
        "        self.fc = nn.Sequential(*self.fc)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        assert self.seq_len is not None\n",
        "        batch_size, feature_size = x.shape\n",
        "        assert feature_size % self.seq_len == 0\n",
        "        x = x.view(batch_size, self.seq_len, feature_size // self.seq_len)\n",
        "        output, _ = self.gru(x)\n",
        "        x = self.fc(output[:, -1, :])  # [B, output_dim]\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def count_parameters(model):\n",
        "    \"\"\"\n",
        "    计算模型的总参数量\n",
        "\n",
        "    参数:\n",
        "    model (torch.nn.Module): PyTorch模型实例\n",
        "\n",
        "    返回:\n",
        "    int: 模型的总参数量\n",
        "    \"\"\"\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlIq8JeqvvHC"
      },
      "source": [
        "# Hyper-parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "iIHn79Iav1ri"
      },
      "outputs": [],
      "source": [
        "# data prarameters\n",
        "# TODO: change the value of \"concat_nframes\" for medium baseline\n",
        "concat_nframes = 5   # the number of frames to concat with, n must be odd (total 2k+1 = n frames)\n",
        "train_ratio = 0.75   # the ratio of data used for training, the rest will be used for validation\n",
        "\n",
        "# training parameters\n",
        "seed = 1213          # random seed\n",
        "batch_size = 2048        # batch size\n",
        "num_epoch = 10         # the number of training epoch\n",
        "learning_rate = 1e-4      # learning rate\n",
        "model_path = './model.ckpt'  # the path where the checkpoint will be saved\n",
        "# model parameters\n",
        "# TODO: change the value of \"hidden_layers\" or \"hidden_dim\" for medium baseline\n",
        "input_dim = 39 * concat_nframes  # the input dim of the model, you should not change the value\n",
        "hidden_layers = 2          # the number of hidden layers\n",
        "hidden_dim = 64           # the hidden dim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of parameters of model_1: 8639529\n",
            "number of parameters of model_2: 8878121\n"
          ]
        }
      ],
      "source": [
        "model_1 = Classifier(input_dim=input_dim, hidden_layers=8, hidden_dim=1024)\n",
        "model_2 = Classifier(input_dim=input_dim, hidden_layers=2, hidden_dim=2048)\n",
        "print(f'number of parameters of model_1: {count_parameters(model_1)}')\n",
        "print(f'number of parameters of model_2: {count_parameters(model_2)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIUFRgG5yoDn"
      },
      "source": [
        "# Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1zI3v5jyrDn",
        "outputId": "71dff0ad-86a8-42b2-a6e0-c869a525b8e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEVICE: cuda\n",
            "[Dataset] - # phone classes: 41, number of utterances for train: 2571\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2571it [00:01, 1334.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] train set\n",
            "torch.Size([1588590, 195])\n",
            "torch.Size([1588590])\n",
            "[Dataset] - # phone classes: 41, number of utterances for val: 858\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "858it [00:00, 1347.43it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] val set\n",
            "torch.Size([528204, 195])\n",
            "torch.Size([528204])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "import gc\n",
        "\n",
        "same_seeds(seed)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'DEVICE: {device}')\n",
        "\n",
        "# preprocess data\n",
        "train_X, train_y = preprocess_data(split='train', feat_dir='./libriphone/feat', phone_path='./libriphone', concat_nframes=concat_nframes, train_ratio=train_ratio, random_seed=seed)\n",
        "val_X, val_y = preprocess_data(split='val', feat_dir='./libriphone/feat', phone_path='./libriphone', concat_nframes=concat_nframes, train_ratio=train_ratio, random_seed=seed)\n",
        "\n",
        "# get dataset\n",
        "train_set = LibriDataset(train_X, train_y)\n",
        "val_set = LibriDataset(val_X, val_y)\n",
        "\n",
        "# remove raw feature to save memory\n",
        "del train_X, train_y, val_X, val_y\n",
        "gc.collect()\n",
        "\n",
        "# get dataloader\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2048, 195])\n",
            "torch.Size([2048])\n"
          ]
        }
      ],
      "source": [
        "for X, y in train_loader:\n",
        "    print(X.shape)\n",
        "    print(y.shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwWH1KIqzxEr"
      },
      "source": [
        "# Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdMWsBs7zzNs",
        "outputId": "5f600fec-d607-469f-db9d-f1088a8400f4"
      },
      "outputs": [],
      "source": [
        "from torch.optim.lr_scheduler import PolynomialLR, StepLR\n",
        "\n",
        "# train function\n",
        "def train(num_epoch, model, optimizer, criterion, train_loader, val_loader, device, model_path, lr_scheduler=None):\n",
        "    best_acc = 0.0\n",
        "    for epoch in range(num_epoch):\n",
        "        train_acc = 0.0\n",
        "        train_loss = 0.0\n",
        "        val_acc = 0.0\n",
        "        val_loss = 0.0\n",
        "        \n",
        "        print(f'learning_rate: {lr_scheduler.get_last_lr()[0]}')\n",
        "        # training\n",
        "        model.train() # set the model to training mode\n",
        "        for i, batch in enumerate(tqdm(train_loader)):\n",
        "            features, labels = batch\n",
        "            features = features.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(features)\n",
        "            \n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            _, train_pred = torch.max(outputs, 1) # get the index of the class with the highest probability\n",
        "            train_acc += (train_pred.detach() == labels.detach()).sum().item()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        # validation\n",
        "        model.eval() # set the model to evaluation mode\n",
        "        with torch.no_grad():\n",
        "            for i, batch in enumerate(tqdm(val_loader)):\n",
        "                features, labels = batch\n",
        "                features = features.to(device)\n",
        "                labels = labels.to(device)\n",
        "                outputs = model(features)\n",
        "\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                _, val_pred = torch.max(outputs, 1)\n",
        "                val_acc += (val_pred.cpu() == labels.cpu()).sum().item() # get the index of the class with the highest probability\n",
        "                val_loss += loss.item()\n",
        "\n",
        "        print(f'[{epoch+1:03d}/{num_epoch:03d}] Train Acc: {train_acc/len(train_set):3.5f} Loss: {train_loss/len(train_loader):3.5f} | Val Acc: {val_acc/len(val_set):3.5f} loss: {val_loss/len(val_loader):3.5f}')\n",
        "\n",
        "        # if the model improves, save a checkpoint at this epoch\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            torch.save(model.state_dict(), model_path)\n",
        "            print(f'saving model with acc {best_acc/len(val_set):.5f}')\n",
        "\n",
        "        if lr_scheduler:\n",
        "            lr_scheduler.step()\n",
        "\n",
        "def train_from_init(num_epoch, model, train_loader, val_loader, device, learning_rate, model_path):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    scheduler = StepLR(optimizer, step_size=10, gamma=0.6)\n",
        "    train(num_epoch, model, optimizer, criterion, train_loader, val_loader, device, model_path, scheduler)\n",
        "\n",
        "# create model, define a loss function, and optimizer\n",
        "# model = Classifier(input_dim=input_dim, hidden_layers=hidden_layers, hidden_dim=hidden_dim).to(device)\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "# train(num_epoch, model, train_loader, val_loader, device, learning_rate, model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Start to train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start to train model_1 on cuda.\n",
            "learning_rate: 0.0001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 776/776 [00:28<00:00, 26.99it/s]\n",
            "100%|██████████| 258/258 [00:05<00:00, 49.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[001/010] Train Acc: 0.39434 Loss: 2.14627 | Val Acc: 0.48664 loss: 1.76620\n",
            "saving model with acc 0.48664\n",
            "learning_rate: 0.0001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 776/776 [00:32<00:00, 24.11it/s]\n",
            "100%|██████████| 258/258 [00:05<00:00, 48.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[002/010] Train Acc: 0.51804 Loss: 1.63657 | Val Acc: 0.53103 loss: 1.59208\n",
            "saving model with acc 0.53103\n",
            "learning_rate: 0.0001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 776/776 [00:30<00:00, 25.05it/s]\n",
            "100%|██████████| 258/258 [00:05<00:00, 47.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[003/010] Train Acc: 0.55179 Loss: 1.50738 | Val Acc: 0.54933 loss: 1.52171\n",
            "saving model with acc 0.54933\n",
            "learning_rate: 0.0001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 776/776 [00:29<00:00, 26.09it/s]\n",
            "100%|██████████| 258/258 [00:05<00:00, 51.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[004/010] Train Acc: 0.57160 Loss: 1.43409 | Val Acc: 0.56206 loss: 1.47502\n",
            "saving model with acc 0.56206\n",
            "learning_rate: 0.0001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 776/776 [00:28<00:00, 26.77it/s]\n",
            "100%|██████████| 258/258 [00:05<00:00, 49.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[005/010] Train Acc: 0.58646 Loss: 1.38017 | Val Acc: 0.57190 loss: 1.44078\n",
            "saving model with acc 0.57190\n",
            "learning_rate: 0.0001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 776/776 [00:31<00:00, 24.85it/s]\n",
            "100%|██████████| 258/258 [00:05<00:00, 45.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[006/010] Train Acc: 0.59883 Loss: 1.33523 | Val Acc: 0.57627 loss: 1.43087\n",
            "saving model with acc 0.57627\n",
            "learning_rate: 0.0001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  8%|▊         | 64/776 [00:02<00:28, 24.69it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[16], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m model_2 \u001b[38;5;241m=\u001b[39m model_2\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStart to train model_1 on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m \u001b[43mtrain_from_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel_1.ckpt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# print('-----------------------------------')\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# print(f'Start to train model_2 on {device}.')\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# train(num_epoch, model_2, train_loader, val_loader, device, learning_rate, 'model_2.ckpt')\u001b[39;00m\n",
            "Cell \u001b[1;32mIn[15], line 61\u001b[0m, in \u001b[0;36mtrain_from_init\u001b[1;34m(num_epoch, model, train_loader, val_loader, device, learning_rate, model_path)\u001b[0m\n\u001b[0;32m     59\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m     60\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m StepLR(optimizer, step_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.6\u001b[39m)\n\u001b[1;32m---> 61\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[15], line 15\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(num_epoch, model, optimizer, criterion, train_loader, val_loader, device, model_path, lr_scheduler)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# training\u001b[39;00m\n\u001b[0;32m     14\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain() \u001b[38;5;66;03m# set the model to training mode\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(train_loader)):\n\u001b[0;32m     16\u001b[0m     features, labels \u001b[38;5;241m=\u001b[39m batch\n\u001b[0;32m     17\u001b[0m     features \u001b[38;5;241m=\u001b[39m features\u001b[38;5;241m.\u001b[39mto(device)\n",
            "File \u001b[1;32md:\\Anaconda3\\envs\\cv\\lib\\site-packages\\tqdm\\std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
            "File \u001b[1;32md:\\Anaconda3\\envs\\cv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[1;32md:\\Anaconda3\\envs\\cv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
            "File \u001b[1;32md:\\Anaconda3\\envs\\cv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
            "File \u001b[1;32md:\\Anaconda3\\envs\\cv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
            "Cell \u001b[1;32mIn[3], line 14\u001b[0m, in \u001b[0;36mLibriDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 14\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[idx], \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel\u001b[49m[idx]\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     16\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[idx]\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model_1 = model_1.to(device)\n",
        "model_2 = model_2.to(device)\n",
        "print(f'Start to train model_1 on {device}.')\n",
        "train_from_init(num_epoch, model_1, train_loader, val_loader, device, learning_rate, 'model_1.ckpt')\n",
        "# print('-----------------------------------')\n",
        "# print(f'Start to train model_2 on {device}.')\n",
        "# train(num_epoch, model_2, train_loader, val_loader, device, learning_rate, 'model_2.ckpt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start to train model_3 on cuda.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:39<00:00, 77.92it/s]\n",
            "100%|██████████| 1032/1032 [00:05<00:00, 201.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[001/010] Train Acc: 0.46160 Loss: 1.88658 | Val Acc: 0.52039 loss: 1.61677\n",
            "saving model with acc 0.52039\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:39<00:00, 78.54it/s]\n",
            "100%|██████████| 1032/1032 [00:05<00:00, 189.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[002/010] Train Acc: 0.51538 Loss: 1.63815 | Val Acc: 0.54076 loss: 1.53246\n",
            "saving model with acc 0.54076\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:39<00:00, 79.19it/s]\n",
            "100%|██████████| 1032/1032 [00:05<00:00, 201.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[003/010] Train Acc: 0.53278 Loss: 1.56754 | Val Acc: 0.54971 loss: 1.49152\n",
            "saving model with acc 0.54971\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:39<00:00, 78.86it/s]\n",
            "100%|██████████| 1032/1032 [00:05<00:00, 202.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[004/010] Train Acc: 0.54314 Loss: 1.52439 | Val Acc: 0.55647 loss: 1.46713\n",
            "saving model with acc 0.55647\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:39<00:00, 78.94it/s]\n",
            "100%|██████████| 1032/1032 [00:05<00:00, 201.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[005/010] Train Acc: 0.55213 Loss: 1.49162 | Val Acc: 0.56104 loss: 1.44815\n",
            "saving model with acc 0.56104\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:40<00:00, 76.86it/s]\n",
            "100%|██████████| 1032/1032 [00:05<00:00, 194.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[006/010] Train Acc: 0.55831 Loss: 1.46657 | Val Acc: 0.56423 loss: 1.43639\n",
            "saving model with acc 0.56423\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:41<00:00, 75.43it/s]\n",
            "100%|██████████| 1032/1032 [00:05<00:00, 192.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[007/010] Train Acc: 0.56378 Loss: 1.44490 | Val Acc: 0.56619 loss: 1.42730\n",
            "saving model with acc 0.56619\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:40<00:00, 77.17it/s]\n",
            "100%|██████████| 1032/1032 [00:05<00:00, 203.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[008/010] Train Acc: 0.56863 Loss: 1.42562 | Val Acc: 0.56870 loss: 1.42186\n",
            "saving model with acc 0.56870\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:39<00:00, 77.75it/s]\n",
            "100%|██████████| 1032/1032 [00:05<00:00, 201.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[009/010] Train Acc: 0.57293 Loss: 1.40892 | Val Acc: 0.57072 loss: 1.41145\n",
            "saving model with acc 0.57072\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:39<00:00, 78.88it/s]\n",
            "100%|██████████| 1032/1032 [00:05<00:00, 199.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[010/010] Train Acc: 0.57703 Loss: 1.39413 | Val Acc: 0.57247 loss: 1.40599\n",
            "saving model with acc 0.57247\n",
            "-----------------------------------\n",
            "Start to train model_4 on cuda.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:39<00:00, 77.64it/s]\n",
            "100%|██████████| 1032/1032 [00:05<00:00, 198.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[001/010] Train Acc: 0.38498 Loss: 2.23369 | Val Acc: 0.46846 loss: 1.86001\n",
            "saving model with acc 0.46846\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:38<00:00, 80.70it/s]\n",
            "100%|██████████| 1032/1032 [00:05<00:00, 198.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[002/010] Train Acc: 0.46531 Loss: 1.86520 | Val Acc: 0.50394 loss: 1.70246\n",
            "saving model with acc 0.50394\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:39<00:00, 79.26it/s]\n",
            "100%|██████████| 1032/1032 [00:05<00:00, 193.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[003/010] Train Acc: 0.48814 Loss: 1.77384 | Val Acc: 0.51762 loss: 1.64336\n",
            "saving model with acc 0.51762\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:39<00:00, 79.29it/s]\n",
            "100%|██████████| 1032/1032 [00:05<00:00, 193.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[004/010] Train Acc: 0.50053 Loss: 1.72555 | Val Acc: 0.52719 loss: 1.60852\n",
            "saving model with acc 0.52719\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:39<00:00, 77.93it/s]\n",
            "100%|██████████| 1032/1032 [00:04<00:00, 207.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[005/010] Train Acc: 0.50895 Loss: 1.69271 | Val Acc: 0.53220 loss: 1.58875\n",
            "saving model with acc 0.53220\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:37<00:00, 82.11it/s]\n",
            "100%|██████████| 1032/1032 [00:04<00:00, 209.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[006/010] Train Acc: 0.51539 Loss: 1.66676 | Val Acc: 0.53743 loss: 1.56663\n",
            "saving model with acc 0.53743\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:38<00:00, 79.68it/s]\n",
            "100%|██████████| 1032/1032 [00:05<00:00, 201.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[007/010] Train Acc: 0.52135 Loss: 1.64573 | Val Acc: 0.54087 loss: 1.55206\n",
            "saving model with acc 0.54087\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:38<00:00, 81.02it/s]\n",
            "100%|██████████| 1032/1032 [00:05<00:00, 204.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[008/010] Train Acc: 0.52591 Loss: 1.62753 | Val Acc: 0.54453 loss: 1.53666\n",
            "saving model with acc 0.54453\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:39<00:00, 79.26it/s]\n",
            "100%|██████████| 1032/1032 [00:05<00:00, 196.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[009/010] Train Acc: 0.52952 Loss: 1.61218 | Val Acc: 0.54745 loss: 1.52518\n",
            "saving model with acc 0.54745\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:40<00:00, 77.50it/s]\n",
            "100%|██████████| 1032/1032 [00:05<00:00, 196.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[010/010] Train Acc: 0.53329 Loss: 1.59803 | Val Acc: 0.54972 loss: 1.51496\n",
            "saving model with acc 0.54972\n",
            "-----------------------------------\n",
            "Start to train model_5 on cuda.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:39<00:00, 78.77it/s]\n",
            "100%|██████████| 1032/1032 [00:05<00:00, 203.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[001/010] Train Acc: 0.24932 Loss: 2.83059 | Val Acc: 0.17339 loss: 4.59497\n",
            "saving model with acc 0.17339\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:39<00:00, 78.75it/s]\n",
            "100%|██████████| 1032/1032 [00:05<00:00, 203.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[002/010] Train Acc: 0.29090 Loss: 2.59934 | Val Acc: 0.17701 loss: 4.15001\n",
            "saving model with acc 0.17701\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:39<00:00, 78.35it/s]\n",
            "100%|██████████| 1032/1032 [00:05<00:00, 199.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[003/010] Train Acc: 0.34496 Loss: 2.39569 | Val Acc: 0.25961 loss: 3.26559\n",
            "saving model with acc 0.25961\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:40<00:00, 76.27it/s]\n",
            "100%|██████████| 1032/1032 [00:05<00:00, 196.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[004/010] Train Acc: 0.37325 Loss: 2.27328 | Val Acc: 0.33278 loss: 2.61053\n",
            "saving model with acc 0.33278\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:38<00:00, 81.41it/s]\n",
            "100%|██████████| 1032/1032 [00:04<00:00, 206.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[005/010] Train Acc: 0.39439 Loss: 2.16606 | Val Acc: 0.40365 loss: 2.11111\n",
            "saving model with acc 0.40365\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:37<00:00, 83.50it/s]\n",
            "100%|██████████| 1032/1032 [00:04<00:00, 210.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[006/010] Train Acc: 0.40869 Loss: 2.09753 | Val Acc: 0.43111 loss: 1.99037\n",
            "saving model with acc 0.43111\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:36<00:00, 84.04it/s]\n",
            "100%|██████████| 1032/1032 [00:04<00:00, 209.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[007/010] Train Acc: 0.42101 Loss: 2.05073 | Val Acc: 0.44994 loss: 1.93188\n",
            "saving model with acc 0.44994\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:37<00:00, 83.30it/s]\n",
            "100%|██████████| 1032/1032 [00:04<00:00, 211.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[008/010] Train Acc: 0.43018 Loss: 2.02155 | Val Acc: 0.45768 loss: 1.90302\n",
            "saving model with acc 0.45768\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:38<00:00, 81.28it/s]\n",
            "100%|██████████| 1032/1032 [00:04<00:00, 208.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[009/010] Train Acc: 0.43755 Loss: 1.99804 | Val Acc: 0.46303 loss: 1.88218\n",
            "saving model with acc 0.46303\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:37<00:00, 83.76it/s]\n",
            "100%|██████████| 1032/1032 [00:04<00:00, 211.85it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[010/010] Train Acc: 0.44367 Loss: 1.98042 | Val Acc: 0.47175 loss: 1.85445\n",
            "saving model with acc 0.47175\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "model_3 = ClassifierV2(input_dim=input_dim, hidden_layers=8, hidden_dim=1024, dropout=0.25).to(device)\n",
        "model_4 = ClassifierV2(input_dim=input_dim, hidden_layers=8, hidden_dim=1024, dropout=0.5).to(device)\n",
        "model_5 = ClassifierV2(input_dim=input_dim, hidden_layers=8, hidden_dim=1024, dropout=0.75).to(device)\n",
        "print(f'Start to train model_3 on {device}.')\n",
        "train(num_epoch, model_3, train_loader, val_loader, device, learning_rate, 'model_3.ckpt')\n",
        "print('-----------------------------------')\n",
        "print(f'Start to train model_4 on {device}.')\n",
        "train(num_epoch, model_4, train_loader, val_loader, device, learning_rate, 'model_4.ckpt')\n",
        "print('-----------------------------------')\n",
        "print(f'Start to train model_5 on {device}.')\n",
        "train(num_epoch, model_5, train_loader, val_loader, device, learning_rate, 'model_5.ckpt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start to train model_3 on cuda.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:37<00:00, 83.54it/s]\n",
            "100%|██████████| 1032/1032 [00:04<00:00, 206.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[001/050] Train Acc: 0.46064 Loss: 1.89040 | Val Acc: 0.52081 loss: 1.62239\n",
            "saving model with acc 0.52081\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:36<00:00, 84.39it/s]\n",
            "100%|██████████| 1032/1032 [00:04<00:00, 210.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[002/050] Train Acc: 0.51576 Loss: 1.63735 | Val Acc: 0.53954 loss: 1.53431\n",
            "saving model with acc 0.53954\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:37<00:00, 83.72it/s]\n",
            "100%|██████████| 1032/1032 [00:04<00:00, 209.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[003/050] Train Acc: 0.53265 Loss: 1.56656 | Val Acc: 0.54970 loss: 1.49048\n",
            "saving model with acc 0.54970\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:36<00:00, 84.27it/s]\n",
            "100%|██████████| 1032/1032 [00:04<00:00, 209.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[004/050] Train Acc: 0.54352 Loss: 1.52299 | Val Acc: 0.55580 loss: 1.46631\n",
            "saving model with acc 0.55580\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:36<00:00, 84.55it/s]\n",
            "100%|██████████| 1032/1032 [00:04<00:00, 212.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[005/050] Train Acc: 0.55162 Loss: 1.49146 | Val Acc: 0.56139 loss: 1.44709\n",
            "saving model with acc 0.56139\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:36<00:00, 84.51it/s]\n",
            "100%|██████████| 1032/1032 [00:04<00:00, 212.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[006/050] Train Acc: 0.55838 Loss: 1.46545 | Val Acc: 0.56554 loss: 1.43463\n",
            "saving model with acc 0.56554\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:37<00:00, 82.40it/s]\n",
            "100%|██████████| 1032/1032 [00:05<00:00, 205.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[007/050] Train Acc: 0.56414 Loss: 1.44283 | Val Acc: 0.56767 loss: 1.42504\n",
            "saving model with acc 0.56767\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:37<00:00, 83.24it/s]\n",
            "100%|██████████| 1032/1032 [00:04<00:00, 211.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[008/050] Train Acc: 0.56926 Loss: 1.42479 | Val Acc: 0.56999 loss: 1.41483\n",
            "saving model with acc 0.56999\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:37<00:00, 83.19it/s]\n",
            "100%|██████████| 1032/1032 [00:04<00:00, 212.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[009/050] Train Acc: 0.57352 Loss: 1.40743 | Val Acc: 0.57236 loss: 1.40891\n",
            "saving model with acc 0.57236\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:37<00:00, 83.77it/s]\n",
            "100%|██████████| 1032/1032 [00:04<00:00, 212.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[010/050] Train Acc: 0.57723 Loss: 1.39235 | Val Acc: 0.57345 loss: 1.40263\n",
            "saving model with acc 0.57345\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:36<00:00, 84.23it/s]\n",
            "100%|██████████| 1032/1032 [00:04<00:00, 211.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[011/050] Train Acc: 0.58110 Loss: 1.37752 | Val Acc: 0.57346 loss: 1.40008\n",
            "saving model with acc 0.57346\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:37<00:00, 83.78it/s]\n",
            "100%|██████████| 1032/1032 [00:04<00:00, 210.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[012/050] Train Acc: 0.58467 Loss: 1.36419 | Val Acc: 0.57513 loss: 1.39748\n",
            "saving model with acc 0.57513\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:36<00:00, 84.26it/s]\n",
            "100%|██████████| 1032/1032 [00:04<00:00, 211.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[013/050] Train Acc: 0.58762 Loss: 1.35247 | Val Acc: 0.57565 loss: 1.39534\n",
            "saving model with acc 0.57565\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:36<00:00, 84.23it/s]\n",
            "100%|██████████| 1032/1032 [00:04<00:00, 211.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[014/050] Train Acc: 0.59093 Loss: 1.34039 | Val Acc: 0.57665 loss: 1.39254\n",
            "saving model with acc 0.57665\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:37<00:00, 83.84it/s]\n",
            "100%|██████████| 1032/1032 [00:04<00:00, 213.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[015/050] Train Acc: 0.59405 Loss: 1.32948 | Val Acc: 0.57745 loss: 1.38900\n",
            "saving model with acc 0.57745\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:36<00:00, 83.90it/s]\n",
            "100%|██████████| 1032/1032 [00:04<00:00, 210.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[016/050] Train Acc: 0.59615 Loss: 1.31936 | Val Acc: 0.57849 loss: 1.38804\n",
            "saving model with acc 0.57849\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:37<00:00, 83.08it/s]\n",
            "100%|██████████| 1032/1032 [00:04<00:00, 211.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[017/050] Train Acc: 0.59929 Loss: 1.30886 | Val Acc: 0.57817 loss: 1.39029\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:37<00:00, 83.69it/s]\n",
            "100%|██████████| 1032/1032 [00:04<00:00, 212.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[018/050] Train Acc: 0.60185 Loss: 1.29997 | Val Acc: 0.57814 loss: 1.38952\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:36<00:00, 84.28it/s]\n",
            "100%|██████████| 1032/1032 [00:04<00:00, 212.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[019/050] Train Acc: 0.60389 Loss: 1.29193 | Val Acc: 0.57799 loss: 1.39086\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:36<00:00, 84.28it/s]\n",
            "100%|██████████| 1032/1032 [00:04<00:00, 211.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[020/050] Train Acc: 0.60604 Loss: 1.28341 | Val Acc: 0.57788 loss: 1.39210\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:37<00:00, 83.86it/s]\n",
            "100%|██████████| 1032/1032 [00:04<00:00, 212.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[021/050] Train Acc: 0.60866 Loss: 1.27442 | Val Acc: 0.57810 loss: 1.39122\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:37<00:00, 83.12it/s]\n",
            "100%|██████████| 1032/1032 [00:05<00:00, 201.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[022/050] Train Acc: 0.61101 Loss: 1.26617 | Val Acc: 0.57799 loss: 1.39393\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:38<00:00, 80.69it/s]\n",
            "100%|██████████| 1032/1032 [00:05<00:00, 200.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[023/050] Train Acc: 0.61265 Loss: 1.25873 | Val Acc: 0.57825 loss: 1.39338\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:38<00:00, 80.05it/s]\n",
            "100%|██████████| 1032/1032 [00:04<00:00, 207.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[024/050] Train Acc: 0.61427 Loss: 1.25214 | Val Acc: 0.57887 loss: 1.39356\n",
            "saving model with acc 0.57887\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:37<00:00, 83.36it/s]\n",
            "100%|██████████| 1032/1032 [00:04<00:00, 210.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[025/050] Train Acc: 0.61650 Loss: 1.24521 | Val Acc: 0.57860 loss: 1.39447\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:36<00:00, 84.51it/s]\n",
            "100%|██████████| 1032/1032 [00:04<00:00, 208.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[026/050] Train Acc: 0.61827 Loss: 1.23806 | Val Acc: 0.57808 loss: 1.39651\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:37<00:00, 83.54it/s]\n",
            "100%|██████████| 1032/1032 [00:04<00:00, 209.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[027/050] Train Acc: 0.62027 Loss: 1.23190 | Val Acc: 0.57854 loss: 1.39650\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:36<00:00, 84.27it/s]\n",
            "100%|██████████| 1032/1032 [00:04<00:00, 209.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[028/050] Train Acc: 0.62166 Loss: 1.22607 | Val Acc: 0.57858 loss: 1.39688\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:37<00:00, 83.76it/s]\n",
            "100%|██████████| 1032/1032 [00:04<00:00, 209.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[029/050] Train Acc: 0.62384 Loss: 1.21943 | Val Acc: 0.57894 loss: 1.39968\n",
            "saving model with acc 0.57894\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:36<00:00, 84.30it/s]\n",
            "100%|██████████| 1032/1032 [00:04<00:00, 211.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[030/050] Train Acc: 0.62499 Loss: 1.21411 | Val Acc: 0.57826 loss: 1.40063\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:36<00:00, 84.34it/s]\n",
            "100%|██████████| 1032/1032 [00:04<00:00, 211.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[031/050] Train Acc: 0.62663 Loss: 1.20806 | Val Acc: 0.57793 loss: 1.40466\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:37<00:00, 83.44it/s]\n",
            "100%|██████████| 1032/1032 [00:04<00:00, 209.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[032/050] Train Acc: 0.62861 Loss: 1.20261 | Val Acc: 0.57772 loss: 1.40432\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:36<00:00, 83.90it/s]\n",
            "100%|██████████| 1032/1032 [00:04<00:00, 212.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[033/050] Train Acc: 0.62997 Loss: 1.19619 | Val Acc: 0.57728 loss: 1.40649\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:36<00:00, 84.37it/s]\n",
            "100%|██████████| 1032/1032 [00:04<00:00, 212.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[034/050] Train Acc: 0.63126 Loss: 1.19136 | Val Acc: 0.57727 loss: 1.40653\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:37<00:00, 83.53it/s]\n",
            "100%|██████████| 1032/1032 [00:04<00:00, 209.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[035/050] Train Acc: 0.63265 Loss: 1.18749 | Val Acc: 0.57830 loss: 1.40832\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:37<00:00, 83.82it/s]\n",
            "100%|██████████| 1032/1032 [00:04<00:00, 211.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[036/050] Train Acc: 0.63380 Loss: 1.18235 | Val Acc: 0.57705 loss: 1.41127\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:36<00:00, 84.09it/s]\n",
            "100%|██████████| 1032/1032 [00:04<00:00, 208.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[037/050] Train Acc: 0.63527 Loss: 1.17769 | Val Acc: 0.57739 loss: 1.41133\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:37<00:00, 83.79it/s]\n",
            "100%|██████████| 1032/1032 [00:04<00:00, 211.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[038/050] Train Acc: 0.63639 Loss: 1.17302 | Val Acc: 0.57729 loss: 1.41224\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:37<00:00, 83.44it/s]\n",
            "100%|██████████| 1032/1032 [00:04<00:00, 212.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[039/050] Train Acc: 0.63767 Loss: 1.16834 | Val Acc: 0.57736 loss: 1.41343\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:36<00:00, 84.37it/s]\n",
            "100%|██████████| 1032/1032 [00:04<00:00, 212.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[040/050] Train Acc: 0.63896 Loss: 1.16352 | Val Acc: 0.57676 loss: 1.41917\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:36<00:00, 84.48it/s]\n",
            "100%|██████████| 1032/1032 [00:04<00:00, 212.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[041/050] Train Acc: 0.64058 Loss: 1.15944 | Val Acc: 0.57715 loss: 1.41845\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:36<00:00, 84.37it/s]\n",
            "100%|██████████| 1032/1032 [00:04<00:00, 211.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[042/050] Train Acc: 0.64128 Loss: 1.15584 | Val Acc: 0.57726 loss: 1.41951\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:36<00:00, 84.37it/s]\n",
            "100%|██████████| 1032/1032 [00:05<00:00, 205.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[043/050] Train Acc: 0.64259 Loss: 1.15126 | Val Acc: 0.57602 loss: 1.42003\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:36<00:00, 84.29it/s]\n",
            "100%|██████████| 1032/1032 [00:04<00:00, 211.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[044/050] Train Acc: 0.64371 Loss: 1.14709 | Val Acc: 0.57610 loss: 1.42217\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:36<00:00, 84.31it/s]\n",
            "100%|██████████| 1032/1032 [00:04<00:00, 210.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[045/050] Train Acc: 0.64472 Loss: 1.14382 | Val Acc: 0.57623 loss: 1.42124\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:36<00:00, 83.93it/s]\n",
            "100%|██████████| 1032/1032 [00:04<00:00, 209.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[046/050] Train Acc: 0.64582 Loss: 1.13944 | Val Acc: 0.57587 loss: 1.42577\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:37<00:00, 82.53it/s]\n",
            "100%|██████████| 1032/1032 [00:05<00:00, 193.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[047/050] Train Acc: 0.64686 Loss: 1.13686 | Val Acc: 0.57625 loss: 1.42598\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:38<00:00, 79.82it/s]\n",
            "100%|██████████| 1032/1032 [00:05<00:00, 201.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[048/050] Train Acc: 0.64753 Loss: 1.13318 | Val Acc: 0.57639 loss: 1.42443\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:38<00:00, 79.57it/s]\n",
            "100%|██████████| 1032/1032 [00:05<00:00, 201.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[049/050] Train Acc: 0.64875 Loss: 1.12926 | Val Acc: 0.57542 loss: 1.42798\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3103/3103 [00:37<00:00, 82.50it/s]\n",
            "100%|██████████| 1032/1032 [00:05<00:00, 194.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[050/050] Train Acc: 0.64949 Loss: 1.12580 | Val Acc: 0.57555 loss: 1.43203\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "model_3 = ClassifierV2(input_dim=input_dim, hidden_layers=8, hidden_dim=1024, dropout=0.25).to(device)\n",
        "print(f'Start to train model_3 on {device}.')\n",
        "train(50, model_3, train_loader, val_loader, device, learning_rate, 'model_3.ckpt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start to train model_7 on cuda.\n",
            "learning_rate: 0.0001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 776/776 [09:57<00:00,  1.30it/s]\n",
            " 51%|█████     | 131/258 [00:33<00:32,  3.93it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[14], line 13\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStart to train model_7 on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# optimizer = torch.optim.Adam(model_7.parameters(), lr=learning_rate)\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# criterion = nn.CrossEntropyLoss()\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# scheduler = StepLR(optimizer, step_size=10, gamma=0.6)\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# train(50, model_7, optimizer, criterion, train_loader, val_loader, device, 'model_7.ckpt', scheduler)\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[43mtrain_from_init\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_7\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel_7.ckpt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[12], line 61\u001b[0m, in \u001b[0;36mtrain_from_init\u001b[1;34m(num_epoch, model, train_loader, val_loader, device, learning_rate, model_path)\u001b[0m\n\u001b[0;32m     59\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m     60\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m StepLR(optimizer, step_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.6\u001b[39m)\n\u001b[1;32m---> 61\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[12], line 43\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(num_epoch, model, optimizer, criterion, train_loader, val_loader, device, model_path, lr_scheduler)\u001b[0m\n\u001b[0;32m     40\u001b[0m         loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     42\u001b[0m         _, val_pred \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 43\u001b[0m         val_acc \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[43mval_pred\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m==\u001b[39m labels\u001b[38;5;241m.\u001b[39mcpu())\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;66;03m# get the index of the class with the highest probability\u001b[39;00m\n\u001b[0;32m     44\u001b[0m         val_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m03d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epoch\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m03d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] Train Acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_acc\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_set)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m3.5f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_loader)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m3.5f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Val Acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_acc\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(val_set)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m3.5f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(val_loader)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m3.5f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model_7 = Classifier_GRU(input_dim=input_dim // concat_nframes, \n",
        "                         hidden_dim=1024, \n",
        "                         bidirectional=True, \n",
        "                         num_layers=4, \n",
        "                         dropout=0.5,\n",
        "                         mlp_layers=[1024, 512, 32]).to(device)\n",
        "model_7.seq_len = concat_nframes\n",
        "print(f'Start to train model_7 on {device}.')\n",
        "# optimizer = torch.optim.Adam(model_7.parameters(), lr=learning_rate)\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "# scheduler = StepLR(optimizer, step_size=10, gamma=0.6)\n",
        "# train(50, model_7, optimizer, criterion, train_loader, val_loader, device, 'model_7.ckpt', scheduler)\n",
        "train_from_init(20, model_7, train_loader, val_loader, device, learning_rate, 'model_7.ckpt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab33MxosWLmG",
        "outputId": "b41d3d23-d1a4-4733-8f0a-eb11960518ce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "del train_set, val_set\n",
        "del train_loader, val_loader\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Hi7jTn3PX-m"
      },
      "source": [
        "# Testing\n",
        "Create a testing dataset, and load model from the saved checkpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOG1Ou0PGrhc",
        "outputId": "2c7c909c-b60b-43cf-a49d-b1e92838aafd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Dataset] - # phone classes: 41, number of utterances for test: 857\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0it [00:00, ?it/s]<ipython-input-3-794249a209e1>:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  feat = torch.load(path)\n",
            "857it [00:00, 1375.02it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] test set\n",
            "torch.Size([527364, 117])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# load data\n",
        "test_X = preprocess_data(split='test', feat_dir='./libriphone/feat', phone_path='./libriphone', concat_nframes=concat_nframes)\n",
        "test_set = LibriDataset(test_X, None)\n",
        "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ay0Fu8Ovkdad",
        "outputId": "f19da307-2ace-4419-fffa-fb54c722f969"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-11-f7b7612de35f>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path))\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# load model\n",
        "model = Classifier(input_dim=input_dim, hidden_layers=hidden_layers, hidden_dim=hidden_dim).to(device)\n",
        "model.load_state_dict(torch.load(model_path))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zp-DV1p4r7Nz"
      },
      "source": [
        "Make prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84HU5GGjPqR0",
        "outputId": "5cf704cb-4ce9-4e8b-f79f-9d9395aec316"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1031/1031 [00:01<00:00, 518.37it/s]\n"
          ]
        }
      ],
      "source": [
        "pred = np.array([], dtype=np.int32)\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for i, batch in enumerate(tqdm(test_loader)):\n",
        "        features = batch\n",
        "        features = features.to(device)\n",
        "\n",
        "        outputs = model(features)\n",
        "\n",
        "        _, test_pred = torch.max(outputs, 1) # get the index of the class with the highest probability\n",
        "        pred = np.concatenate((pred, test_pred.cpu().numpy()), axis=0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyZqy40Prz0v"
      },
      "source": [
        "Write prediction to a CSV file.\n",
        "\n",
        "After finish running this block, download the file `prediction.csv` from the files section on the left-hand side and submit it to Kaggle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GuljYSPHcZir"
      },
      "outputs": [],
      "source": [
        "with open('prediction.csv', 'w') as f:\n",
        "    f.write('Id,Class\\n')\n",
        "    for i, y in enumerate(pred):\n",
        "        f.write('{},{}\\n'.format(i, y))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
