{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcb19d53",
   "metadata": {
    "id": "guE34D3Fj2R9",
    "papermill": {
     "duration": 0.006186,
     "end_time": "2023-02-23T06:53:37.048569",
     "exception": false,
     "start_time": "2023-02-23T06:53:37.042383",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Homework 1: COVID-19 Cases Prediction (Regression)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290f3605",
   "metadata": {
    "id": "V57zhcTp1Xxb",
    "papermill": {
     "duration": 0.005972,
     "end_time": "2023-02-23T06:53:37.059683",
     "exception": false,
     "start_time": "2023-02-23T06:53:37.053711",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Objectives:\n",
    "* Solve a regression problem with deep neural networks (DNN).\n",
    "* Understand basic DNN training tips.\n",
    "* Familiarize yourself with PyTorch.\n",
    "\n",
    "If you have any questions, please contact the TAs via TA hours, NTU COOL, or email to mlta-2023-spring@googlegroups.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ce0538",
   "metadata": {
    "id": "igqIMEgu64-F",
    "papermill": {
     "duration": 0.006557,
     "end_time": "2023-02-23T06:53:43.368086",
     "exception": false,
     "start_time": "2023-02-23T06:53:43.361529",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d40f549",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T06:53:43.382394Z",
     "iopub.status.busy": "2023-02-23T06:53:43.382067Z",
     "iopub.status.idle": "2023-02-23T06:53:45.415626Z",
     "shell.execute_reply": "2023-02-23T06:53:45.414625Z"
    },
    "id": "xybQNYCXYu13",
    "papermill": {
     "duration": 2.043748,
     "end_time": "2023-02-23T06:53:45.418311",
     "exception": false,
     "start_time": "2023-02-23T06:53:43.374563",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Numerical Operations\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "# Reading/Writing Data\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# For Progress Bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Pytorch\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "# For plotting learning curve\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4443519",
   "metadata": {
    "id": "fTAVqRfc2KK3",
    "papermill": {
     "duration": 0.006276,
     "end_time": "2023-02-23T06:53:45.431382",
     "exception": false,
     "start_time": "2023-02-23T06:53:45.425106",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Some Utility Functions\n",
    "\n",
    "You do not need to modify this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42449d5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T06:53:45.445764Z",
     "iopub.status.busy": "2023-02-23T06:53:45.445269Z",
     "iopub.status.idle": "2023-02-23T06:53:45.454019Z",
     "shell.execute_reply": "2023-02-23T06:53:45.453103Z"
    },
    "id": "RbrcpfYN2I-H",
    "papermill": {
     "duration": 0.018326,
     "end_time": "2023-02-23T06:53:45.456081",
     "exception": false,
     "start_time": "2023-02-23T06:53:45.437755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def same_seed(seed): \n",
    "    '''Fixes random number generator seeds for reproducibility.'''\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def train_valid_split(data_set, valid_ratio, seed):\n",
    "    '''Split provided training data into training set and validation set'''\n",
    "    valid_set_size = int(valid_ratio * len(data_set)) \n",
    "    train_set_size = len(data_set) - valid_set_size\n",
    "    train_set, valid_set = random_split(data_set, [train_set_size, valid_set_size], generator=torch.Generator().manual_seed(seed))\n",
    "    return np.array(train_set), np.array(valid_set)\n",
    "\n",
    "def predict(test_loader, model, device):\n",
    "    model.eval() # Set your model to evaluation mode.\n",
    "    preds = []\n",
    "    for x in tqdm(test_loader):\n",
    "        x = x.to(device)                        \n",
    "        with torch.no_grad():                   \n",
    "            pred = model(x)                     \n",
    "            preds.append(pred.detach().cpu())   \n",
    "    preds = torch.cat(preds, dim=0).numpy()  \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c5de5c",
   "metadata": {
    "id": "IqO3lTm78nNO",
    "papermill": {
     "duration": 0.006227,
     "end_time": "2023-02-23T06:53:45.468771",
     "exception": false,
     "start_time": "2023-02-23T06:53:45.462544",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1ad40d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T06:53:45.483053Z",
     "iopub.status.busy": "2023-02-23T06:53:45.482294Z",
     "iopub.status.idle": "2023-02-23T06:53:45.488768Z",
     "shell.execute_reply": "2023-02-23T06:53:45.487929Z"
    },
    "id": "-mjaJM0wprMs",
    "papermill": {
     "duration": 0.015706,
     "end_time": "2023-02-23T06:53:45.490763",
     "exception": false,
     "start_time": "2023-02-23T06:53:45.475057",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class COVID19Dataset(Dataset):\n",
    "    '''\n",
    "    x: Features.\n",
    "    y: Targets, if none, do prediction.\n",
    "    '''\n",
    "    def __init__(self, x, y=None):\n",
    "        if y is None:\n",
    "            self.y = y\n",
    "        else:\n",
    "            self.y = torch.FloatTensor(y)\n",
    "        self.x = torch.FloatTensor(x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.y is None:\n",
    "            return self.x[idx]\n",
    "        else:\n",
    "            return self.x[idx], self.y[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ebe8f1",
   "metadata": {
    "id": "m73ooU75CL_j",
    "papermill": {
     "duration": 0.006136,
     "end_time": "2023-02-23T06:53:45.503200",
     "exception": false,
     "start_time": "2023-02-23T06:53:45.497064",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Neural Network Model\n",
    "Try out different model architectures by modifying the class below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a99fdb9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T06:53:45.517288Z",
     "iopub.status.busy": "2023-02-23T06:53:45.516518Z",
     "iopub.status.idle": "2023-02-23T06:53:45.522493Z",
     "shell.execute_reply": "2023-02-23T06:53:45.521640Z"
    },
    "id": "Qn97_WvvrEkG",
    "papermill": {
     "duration": 0.014902,
     "end_time": "2023-02-23T06:53:45.524386",
     "exception": false,
     "start_time": "2023-02-23T06:53:45.509484",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class My_Model(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(My_Model, self).__init__()\n",
    "        # TODO: modify model's structure, be aware of dimensions. \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        x = x.squeeze(1) # (B, 1) -> (B)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86866e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义多层GRU模型\n",
    "class GRU_Model(nn.Module):\n",
    "  def __init__(self, input_dim, hidden_size=16, num_layers=1):\n",
    "    super().__init__()\n",
    "\n",
    "    self.gru = nn.GRU(input_size=input_dim,\n",
    "              hidden_size=hidden_size,\n",
    "              num_layers=num_layers,\n",
    "              batch_first=True)\n",
    "    self.fc = nn.Sequential(\n",
    "        nn.Linear(hidden_size, hidden_size // 2),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(hidden_size // 2, 1)\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    batch_size, feature_size = x.shape\n",
    "    x = x.view(batch_size, 1, feature_size)\n",
    "    output, _ = self.gru(x)\n",
    "    output = output[:, -1, :]  # (batch_size, hidden_size)\n",
    "    output = self.fc(output)  # (batch_size, 1)\n",
    "    return output.squeeze(1) # (batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e904188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup model\n",
    "class MLP_Model(nn.Module):\n",
    "    \"\"\"\n",
    "    简单的MLP模型\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, hidden_layers_dim=[64, 32, 8]):\n",
    "        super().__init__()\n",
    "        self.layers = []\n",
    "        for i in range(len(hidden_layers_dim)):\n",
    "            if i == 0: \n",
    "                self.layers.append(nn.Linear(input_dim, hidden_layers_dim[i]))\n",
    "            else: \n",
    "                self.layers.append(nn.Linear(hidden_layers_dim[i-1], hidden_layers_dim[i]))\n",
    "            self.layers.append(nn.ReLU())\n",
    "        self.layers.append(nn.Linear(hidden_layers_dim[-1], 1))\n",
    "        self.layers = nn.Sequential(*self.layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)  # [B, 1]\n",
    "        x = x.squeeze(1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07e6740",
   "metadata": {
    "id": "x5-LKF6R8xeq",
    "papermill": {
     "duration": 0.00613,
     "end_time": "2023-02-23T06:53:45.536766",
     "exception": false,
     "start_time": "2023-02-23T06:53:45.530636",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Feature Selection\n",
    "Choose features you deem useful by modifying the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30b1a40c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T06:53:45.550438Z",
     "iopub.status.busy": "2023-02-23T06:53:45.550097Z",
     "iopub.status.idle": "2023-02-23T06:53:45.556192Z",
     "shell.execute_reply": "2023-02-23T06:53:45.555249Z"
    },
    "id": "0FEnKRaIIeKp",
    "papermill": {
     "duration": 0.01512,
     "end_time": "2023-02-23T06:53:45.558146",
     "exception": false,
     "start_time": "2023-02-23T06:53:45.543026",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def select_feat(train_data, valid_data, test_data, select_all=True):\n",
    "    '''Selects useful features to perform regression'''\n",
    "    y_train, y_valid = train_data[:,-1], valid_data[:,-1]\n",
    "    raw_x_train, raw_x_valid, raw_x_test = train_data[:,:-1], valid_data[:,:-1], test_data\n",
    "\n",
    "    if select_all:\n",
    "        feat_idx = list(range(raw_x_train.shape[1]))\n",
    "    else:\n",
    "        # [35:length - 1]\n",
    "        feat_idx = list(range(35, raw_x_train.shape[1])) # TODO: Select suitable feature columns.\n",
    "        \n",
    "    return raw_x_train[:,feat_idx], raw_x_valid[:,feat_idx], raw_x_test[:,feat_idx], y_train, y_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200cde20",
   "metadata": {
    "id": "kADIPNQ2Ih5X",
    "papermill": {
     "duration": 0.006257,
     "end_time": "2023-02-23T06:53:45.570649",
     "exception": false,
     "start_time": "2023-02-23T06:53:45.564392",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4984a2f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T06:53:45.584427Z",
     "iopub.status.busy": "2023-02-23T06:53:45.584155Z",
     "iopub.status.idle": "2023-02-23T06:53:45.596088Z",
     "shell.execute_reply": "2023-02-23T06:53:45.595269Z"
    },
    "id": "k4Rq8_TztAhq",
    "papermill": {
     "duration": 0.021112,
     "end_time": "2023-02-23T06:53:45.598003",
     "exception": false,
     "start_time": "2023-02-23T06:53:45.576891",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def trainer(train_loader, valid_loader, model, config, device):\n",
    "\n",
    "    criterion = nn.MSELoss(reduction='mean') # Define your loss function, do not modify this.\n",
    "\n",
    "    # Define your optimization algorithm. \n",
    "    # TODO: Please check https://pytorch.org/docs/stable/optim.html to get more available algorithms.\n",
    "    # TODO: L2 regularization (optimizer(weight decay...) or implement by your self).\n",
    "    # optimizer = torch.optim.SGD(model.parameters(), lr=config['learning_rate'], momentum=0.7) \n",
    "    # change SGD to Adam\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config['learning_rate'], weight_decay=config['weight_decay'])  \n",
    "    writer = SummaryWriter() # Writer of tensoboard.\n",
    "\n",
    "    if not os.path.isdir('./models'):\n",
    "        os.mkdir('./models') # Create directory of saving models.\n",
    "\n",
    "    n_epochs, best_loss, step, early_stop_count = config['n_epochs'], math.inf, 0, 0\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train() # Set your model to train mode.\n",
    "        loss_record = []\n",
    "\n",
    "        # tqdm is a package to visualize your training progress.\n",
    "        train_pbar = tqdm(train_loader, position=0, leave=True)\n",
    "\n",
    "        for x, y in train_pbar:\n",
    "            optimizer.zero_grad()               # Set gradient to zero.\n",
    "            x, y = x.to(device), y.to(device)   # Move your data to device. \n",
    "            pred = model(x)             \n",
    "            loss = criterion(pred, y)\n",
    "            loss.backward()                     # Compute gradient(backpropagation).\n",
    "            optimizer.step()                    # Update parameters.\n",
    "            step += 1\n",
    "            loss_record.append(loss.detach().item())\n",
    "            \n",
    "            # Display current epoch number and loss on tqdm progress bar.\n",
    "            train_pbar.set_description(f'Epoch [{epoch+1}/{n_epochs}]')\n",
    "            train_pbar.set_postfix({'loss': loss.detach().item()})\n",
    "\n",
    "        mean_train_loss = sum(loss_record)/len(loss_record)\n",
    "        writer.add_scalar('Loss/train', mean_train_loss, step)\n",
    "\n",
    "        model.eval() # Set your model to evaluation mode.\n",
    "        loss_record = []\n",
    "        for x, y in valid_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            with torch.no_grad():\n",
    "                pred = model(x)\n",
    "                loss = criterion(pred, y)\n",
    "\n",
    "            loss_record.append(loss.item())\n",
    "            \n",
    "        mean_valid_loss = sum(loss_record)/len(loss_record)\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{n_epochs}]: Train loss: {mean_train_loss:.4f}, Valid loss: {mean_valid_loss:.4f}')\n",
    "            \n",
    "        writer.add_scalar('Loss/valid', mean_valid_loss, step)\n",
    "\n",
    "        if mean_valid_loss < best_loss:\n",
    "            best_loss = mean_valid_loss\n",
    "            torch.save(model.state_dict(), config['save_path']) # Save your best model\n",
    "            # print('Saving model with loss {:.3f}...'.format(best_loss))\n",
    "            early_stop_count = 0\n",
    "        else: \n",
    "            early_stop_count += 1\n",
    "\n",
    "        if early_stop_count >= config['early_stop']:\n",
    "            print('\\nModel is not improving, so we halt the training session.')\n",
    "            return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54c7d28",
   "metadata": {
    "id": "0pgkOh2e9UjE",
    "papermill": {
     "duration": 0.006311,
     "end_time": "2023-02-23T06:53:45.610482",
     "exception": false,
     "start_time": "2023-02-23T06:53:45.604171",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Configurations\n",
    "`config` contains hyper-parameters for training and the path to save your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a462d0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T06:53:45.624668Z",
     "iopub.status.busy": "2023-02-23T06:53:45.623929Z",
     "iopub.status.idle": "2023-02-23T06:53:45.628995Z",
     "shell.execute_reply": "2023-02-23T06:53:45.628043Z"
    },
    "id": "QoWPUahCtoT6",
    "papermill": {
     "duration": 0.014078,
     "end_time": "2023-02-23T06:53:45.630935",
     "exception": false,
     "start_time": "2023-02-23T06:53:45.616857",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "config = {\n",
    "    'seed': 5201314,      # Your seed number, you can pick your lucky number. :)\n",
    "    'select_all': False,   # Whether to use all features.\n",
    "    'valid_ratio': 0.1,   # validation_size = train_size * valid_ratio\n",
    "    'n_epochs': 1000,     # Number of epochs.            \n",
    "    'batch_size': 256, \n",
    "    'learning_rate': 1e-5,              \n",
    "    'weight_decay': 1e-5,  # L2 Regularization (weight decay).\n",
    "    'early_stop': 600,    # If model has not improved for this many consecutive epochs, stop training.     \n",
    "    'save_path': './models/model.ckpt'  # Your model will be saved here.\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7803207f",
   "metadata": {
    "id": "lrS-aJJh9XkW",
    "papermill": {
     "duration": 0.006167,
     "end_time": "2023-02-23T06:53:45.643440",
     "exception": false,
     "start_time": "2023-02-23T06:53:45.637273",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataloader\n",
    "Read data from files and set up training, validation, and testing sets. You do not need to modify this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "387e5ebe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T06:53:45.658059Z",
     "iopub.status.busy": "2023-02-23T06:53:45.656685Z",
     "iopub.status.idle": "2023-02-23T06:53:45.760059Z",
     "shell.execute_reply": "2023-02-23T06:53:45.758565Z"
    },
    "id": "2jc7ZfDot2t9",
    "papermill": {
     "duration": 0.112631,
     "end_time": "2023-02-23T06:53:45.762275",
     "exception": false,
     "start_time": "2023-02-23T06:53:45.649644",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data size: (2709, 89) \n",
      "valid_data size: (300, 89) \n",
      "test_data size: (997, 88)\n",
      "number of features: 53\n"
     ]
    }
   ],
   "source": [
    "# Set seed for reproducibility\n",
    "same_seed(config['seed'])\n",
    "\n",
    "\n",
    "# train_data size: 3009 x 89 (35 states + 18 features x 3 days) \n",
    "# test_data size: 997 x 88 (without last day's positive rate)\n",
    "train_data, test_data = pd.read_csv('./covid_train.csv').values, pd.read_csv('./covid_test.csv').values\n",
    "train_data, valid_data = train_valid_split(train_data, config['valid_ratio'], config['seed'])\n",
    "\n",
    "# Print out the data size.\n",
    "print(f\"\"\"train_data size: {train_data.shape} \n",
    "valid_data size: {valid_data.shape} \n",
    "test_data size: {test_data.shape}\"\"\")\n",
    "\n",
    "# Select features\n",
    "x_train, x_valid, x_test, y_train, y_valid = select_feat(train_data, valid_data, test_data, config['select_all'])\n",
    "\n",
    "# Print out the number of features.\n",
    "print(f'number of features: {x_train.shape[1]}')\n",
    "\n",
    "train_dataset, valid_dataset, test_dataset = COVID19Dataset(x_train, y_train), \\\n",
    "                                            COVID19Dataset(x_valid, y_valid), \\\n",
    "                                            COVID19Dataset(x_test)\n",
    "\n",
    "# Pytorch data loader loads pytorch dataset into batches.\n",
    "train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True, pin_memory=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=config['batch_size'], shuffle=True, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=config['batch_size'], shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a307f7e0",
   "metadata": {
    "id": "0OBYgjCA-YwD",
    "papermill": {
     "duration": 0.006289,
     "end_time": "2023-02-23T06:53:45.774980",
     "exception": false,
     "start_time": "2023-02-23T06:53:45.768691",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Start training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48734c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5000]: Train loss: 297.8206, Valid loss: 329.5889\n",
      "Epoch [101/5000]: Train loss: 71.1066, Valid loss: 67.7874\n",
      "Epoch [201/5000]: Train loss: 39.7642, Valid loss: 40.7335\n",
      "Epoch [301/5000]: Train loss: 14.3153, Valid loss: 15.9319\n",
      "Epoch [401/5000]: Train loss: 8.2726, Valid loss: 9.7267\n",
      "Epoch [501/5000]: Train loss: 7.0340, Valid loss: 8.1743\n",
      "Epoch [601/5000]: Train loss: 5.6929, Valid loss: 6.8278\n",
      "Epoch [701/5000]: Train loss: 4.3485, Valid loss: 4.9007\n",
      "Epoch [801/5000]: Train loss: 3.0026, Valid loss: 3.9864\n",
      "Epoch [901/5000]: Train loss: 2.1507, Valid loss: 2.4618\n",
      "Epoch [1001/5000]: Train loss: 1.7536, Valid loss: 2.3425\n",
      "Epoch [1101/5000]: Train loss: 1.5750, Valid loss: 1.7562\n",
      "Epoch [1201/5000]: Train loss: 1.4672, Valid loss: 1.6212\n",
      "Epoch [1301/5000]: Train loss: 1.4010, Valid loss: 1.5785\n",
      "Epoch [1401/5000]: Train loss: 1.3464, Valid loss: 1.4413\n",
      "Epoch [1501/5000]: Train loss: 1.2982, Valid loss: 1.8244\n",
      "Epoch [1601/5000]: Train loss: 1.2702, Valid loss: 1.2780\n",
      "Epoch [1701/5000]: Train loss: 1.2456, Valid loss: 1.2465\n",
      "Epoch [1801/5000]: Train loss: 1.2140, Valid loss: 1.3519\n",
      "Epoch [1901/5000]: Train loss: 1.1994, Valid loss: 1.2869\n",
      "Epoch [2001/5000]: Train loss: 1.1665, Valid loss: 1.1252\n",
      "Epoch [2101/5000]: Train loss: 1.1459, Valid loss: 1.1159\n",
      "Epoch [2201/5000]: Train loss: 1.1455, Valid loss: 1.1186\n",
      "Epoch [2301/5000]: Train loss: 1.1150, Valid loss: 1.1349\n",
      "Epoch [2401/5000]: Train loss: 1.1128, Valid loss: 1.1596\n",
      "Epoch [2501/5000]: Train loss: 1.1019, Valid loss: 1.0882\n",
      "Epoch [2601/5000]: Train loss: 1.0869, Valid loss: 1.0234\n",
      "Epoch [2701/5000]: Train loss: 1.0725, Valid loss: 1.2885\n",
      "Epoch [2801/5000]: Train loss: 1.0606, Valid loss: 0.9732\n",
      "Epoch [2901/5000]: Train loss: 1.0557, Valid loss: 0.9999\n",
      "Epoch [3001/5000]: Train loss: 1.0348, Valid loss: 1.0591\n",
      "Epoch [3101/5000]: Train loss: 1.0375, Valid loss: 1.0582\n",
      "Epoch [3201/5000]: Train loss: 1.0220, Valid loss: 0.9786\n",
      "Epoch [3301/5000]: Train loss: 1.0095, Valid loss: 0.9411\n",
      "Epoch [3401/5000]: Train loss: 1.0060, Valid loss: 1.0555\n",
      "Epoch [3501/5000]: Train loss: 0.9994, Valid loss: 0.9187\n",
      "Epoch [3601/5000]: Train loss: 0.9956, Valid loss: 1.0266\n",
      "Epoch [3701/5000]: Train loss: 0.9859, Valid loss: 0.9713\n",
      "Epoch [3801/5000]: Train loss: 0.9784, Valid loss: 1.0316\n",
      "Epoch [3901/5000]: Train loss: 0.9652, Valid loss: 0.9096\n",
      "Epoch [4001/5000]: Train loss: 0.9615, Valid loss: 1.0390\n",
      "Epoch [4101/5000]: Train loss: 0.9488, Valid loss: 1.0063\n",
      "Epoch [4201/5000]: Train loss: 0.9408, Valid loss: 1.0825\n",
      "Epoch [4301/5000]: Train loss: 0.9370, Valid loss: 0.9081\n",
      "Epoch [4401/5000]: Train loss: 0.9294, Valid loss: 0.9538\n",
      "Epoch [4501/5000]: Train loss: 0.9317, Valid loss: 1.0430\n",
      "Epoch [4601/5000]: Train loss: 0.9215, Valid loss: 0.9253\n",
      "Epoch [4701/5000]: Train loss: 0.9187, Valid loss: 0.9918\n",
      "Epoch [4801/5000]: Train loss: 0.9145, Valid loss: 0.8878\n",
      "Epoch [4901/5000]: Train loss: 0.9088, Valid loss: 0.9667\n"
     ]
    }
   ],
   "source": [
    "config['save_path'] = './models/mlp_model.ckpt'\n",
    "config['n_epochs'] = 5000\n",
    "\n",
    "mlp_model = MLP_Model(input_dim=x_train.shape[1]).to(device)\n",
    "trainer(train_loader, valid_loader, mlp_model, config, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a02cec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T06:53:45.788703Z",
     "iopub.status.busy": "2023-02-23T06:53:45.788419Z",
     "iopub.status.idle": "2023-02-23T07:00:03.219714Z",
     "shell.execute_reply": "2023-02-23T07:00:03.218132Z"
    },
    "id": "YdttVRkAfu2t",
    "papermill": {
     "duration": 377.441293,
     "end_time": "2023-02-23T07:00:03.222575",
     "exception": false,
     "start_time": "2023-02-23T06:53:45.781282",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config['save_path'] = './models/my_model.ckpt'\n",
    "model = My_Model(input_dim=x_train.shape[1]).to(device) # put your model and data on the same computation device.\n",
    "trainer(train_loader, valid_loader, model, config, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc26048",
   "metadata": {},
   "outputs": [],
   "source": [
    "config['save_path'] = './models/gru_model.ckpt'\n",
    "model = GRU_Model(input_dim=x_train.shape[1]).to(device) # put your model and data on the same computation device.\n",
    "trainer(train_loader, valid_loader, model, config, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258b2b99",
   "metadata": {
    "id": "yhAHGqC9-woK",
    "papermill": {
     "duration": 6.652829,
     "end_time": "2023-02-23T07:00:16.367374",
     "exception": false,
     "start_time": "2023-02-23T07:00:09.714545",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Testing\n",
    "The predictions of your model on testing set will be stored at `pred.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a6ec22d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T07:00:29.785388Z",
     "iopub.status.busy": "2023-02-23T07:00:29.784095Z",
     "iopub.status.idle": "2023-02-23T07:00:29.805412Z",
     "shell.execute_reply": "2023-02-23T07:00:29.804025Z"
    },
    "id": "Q5eVdpbvAlAe",
    "papermill": {
     "duration": 7.035945,
     "end_time": "2023-02-23T07:00:29.807991",
     "exception": false,
     "start_time": "2023-02-23T07:00:22.772046",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 666.79it/s]\n"
     ]
    }
   ],
   "source": [
    "def save_pred(preds, file):\n",
    "    ''' Save predictions to specified file '''\n",
    "    id_list = []\n",
    "    tested_positive_list = []\n",
    "    for i, p in enumerate(preds):\n",
    "        id_list.append(i)\n",
    "        tested_positive_list.append(p)\n",
    "    df = pd.DataFrame({'id': id_list, 'tested_positive': tested_positive_list})\n",
    "    df.to_csv(file, index=False)\n",
    "    \n",
    "\n",
    "model = MLP_Model(input_dim=x_train.shape[1]).to(device)\n",
    "model.load_state_dict(torch.load('models/mlp_model.ckpt'))\n",
    "preds = predict(test_loader, model, device) \n",
    "save_pred(preds, 'pred.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc6eb28",
   "metadata": {
    "id": "T_N-wBvVahc7",
    "papermill": {
     "duration": 6.547361,
     "end_time": "2023-02-23T07:00:42.693851",
     "exception": false,
     "start_time": "2023-02-23T07:00:36.146490",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Download\n",
    "\n",
    "Run this block to download the `pred.csv` by clicking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31951e23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-23T07:00:55.664064Z",
     "iopub.status.busy": "2023-02-23T07:00:55.663408Z",
     "iopub.status.idle": "2023-02-23T07:00:55.679885Z",
     "shell.execute_reply": "2023-02-23T07:00:55.678696Z"
    },
    "id": "PmMnwrHeavJv",
    "papermill": {
     "duration": 6.365205,
     "end_time": "2023-02-23T07:00:55.683158",
     "exception": false,
     "start_time": "2023-02-23T07:00:49.317953",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink(r'pred.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633c6684",
   "metadata": {
    "id": "IJ_k5rY0GvSV",
    "papermill": {
     "duration": 6.346526,
     "end_time": "2023-02-23T07:01:08.935429",
     "exception": false,
     "start_time": "2023-02-23T07:01:02.588903",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Reference\n",
    "This notebook uses code written by Heng-Jui Chang @ NTUEE (https://github.com/ga642381/ML2021-Spring/blob/main/HW01/HW01.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8af08c0",
   "metadata": {},
   "source": [
    "# My Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89c602d",
   "metadata": {},
   "source": [
    "## TSNE - 特征降维"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8f7cb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "from sklearn import manifold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "432b1d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('covid.train.csv')\n",
    "feature, label = train_df.iloc[:, :-1], train_df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b88c2776",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = manifold.TSNE(2, random_state=22)\n",
    "transformed_data = tsne.fit_transform(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d03afaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_df = pd.DataFrame(np.column_stack((transformed_data, label)), columns=[\"x\", \"y\", \"targets\"])\n",
    "tsne_df.loc[:, \"targets\"] = tsne_df.targets.astype(int)\n",
    "tsne_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55caefd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = sns.FacetGrid(tsne_df, hue=\"targets\")\n",
    "grid.map(plt.scatter, \"x\", \"y\").add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e23e97",
   "metadata": {},
   "source": [
    "## 源码详解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69fe2618",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import random_split, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f799f376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置随机数种子（保证随机结果的一致性）\n",
    "def same_seed(seed): \n",
    "    '''Fixes random number generator seeds for reproducibility.'''\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a681c9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分训练集和验证集（用于模型训练）\n",
    "def train_valid_split(data_set, valid_ratio, seed):\n",
    "    '''Split provided training data into training set and validation set'''\n",
    "    valid_set_size = int(valid_ratio * len(data_set)) \n",
    "    train_set_size = len(data_set) - valid_set_size\n",
    "    train_set, valid_set = random_split(data_set, [train_set_size, valid_set_size], generator=torch.Generator().manual_seed(seed))\n",
    "    return np.array(train_set), np.array(valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22d48da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup dataset\n",
    "class MyDataset(Dataset):\n",
    "    \"\"\"\n",
    "    x: Features\n",
    "    y: Targets, if None, do prediction\n",
    "    \"\"\"\n",
    "    def __init__(self, x, y=None):\n",
    "        self.x = torch.FloatTensor(x)\n",
    "        if y is not None:\n",
    "            self.y = torch.FloatTensor(y)\n",
    "        else:\n",
    "            self.y = None\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        if self.y is not None:\n",
    "            return self.x[index], self.y[index]\n",
    "        else:\n",
    "            return self.x[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e108177c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup model\n",
    "class MyModel(nn.Module):\n",
    "    \"\"\"\n",
    "    简单的MLP模型\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, hidden_layers_dim=[64, 32, 8]):\n",
    "        super().__init__()\n",
    "        self.layers = []\n",
    "        for i in range(len(hidden_layers_dim)):\n",
    "            if i == 0:\n",
    "                self.layers.append(nn.Linear(input_dim, hidden_layers_dim[i]))\n",
    "            else:\n",
    "                self.layers.append(nn.Linear(hidden_layers_dim[i-1], hidden_layers_dim[i]))\n",
    "            self.layers.append(nn.ReLU())\n",
    "        self.layers.append(nn.Linear(hidden_layers_dim[-1], 1))\n",
    "        self.layers = nn.Sequential(*self.layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)  # [B, 1]\n",
    "        x = x.squeeze(1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ecf4335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 001/1000] Train loss: 168.5975\n",
      "[Epoch 001/1000] Eval loss: 93.9501\n",
      "[Epoch 002/1000] Train loss: 90.6762\n",
      "[Epoch 002/1000] Eval loss: 82.7290\n",
      "[Epoch 003/1000] Train loss: 83.9212\n",
      "[Epoch 003/1000] Eval loss: 81.2391\n",
      "[Epoch 004/1000] Train loss: 78.1389\n",
      "[Epoch 004/1000] Eval loss: 72.4522\n",
      "[Epoch 005/1000] Train loss: 73.2024\n",
      "[Epoch 005/1000] Eval loss: 71.7948\n",
      "[Epoch 006/1000] Train loss: 67.1212\n",
      "[Epoch 006/1000] Eval loss: 65.0780\n",
      "[Epoch 007/1000] Train loss: 62.9391\n",
      "[Epoch 007/1000] Eval loss: 59.2695\n",
      "[Epoch 008/1000] Train loss: 56.5817\n",
      "[Epoch 008/1000] Eval loss: 51.1962\n",
      "[Epoch 009/1000] Train loss: 50.4657\n",
      "[Epoch 009/1000] Eval loss: 46.3813\n",
      "[Epoch 010/1000] Train loss: 43.7894\n",
      "[Epoch 010/1000] Eval loss: 40.8719\n",
      "[Epoch 011/1000] Train loss: 37.2479\n",
      "[Epoch 011/1000] Eval loss: 36.6337\n",
      "[Epoch 012/1000] Train loss: 30.4682\n",
      "[Epoch 012/1000] Eval loss: 26.8779\n",
      "[Epoch 013/1000] Train loss: 24.5607\n",
      "[Epoch 013/1000] Eval loss: 20.3865\n",
      "[Epoch 014/1000] Train loss: 18.8649\n",
      "[Epoch 014/1000] Eval loss: 16.7698\n",
      "[Epoch 015/1000] Train loss: 15.0505\n",
      "[Epoch 015/1000] Eval loss: 14.7657\n",
      "[Epoch 016/1000] Train loss: 12.5924\n",
      "[Epoch 016/1000] Eval loss: 11.4842\n",
      "[Epoch 017/1000] Train loss: 11.0599\n",
      "[Epoch 017/1000] Eval loss: 10.4089\n",
      "[Epoch 018/1000] Train loss: 10.0775\n",
      "[Epoch 018/1000] Eval loss: 9.5599\n",
      "[Epoch 019/1000] Train loss: 9.2895\n",
      "[Epoch 019/1000] Eval loss: 9.1427\n",
      "[Epoch 020/1000] Train loss: 8.8954\n",
      "[Epoch 020/1000] Eval loss: 8.9274\n",
      "[Epoch 021/1000] Train loss: 8.6548\n",
      "[Epoch 021/1000] Eval loss: 8.3529\n",
      "[Epoch 022/1000] Train loss: 8.2938\n",
      "[Epoch 022/1000] Eval loss: 8.2578\n",
      "[Epoch 023/1000] Train loss: 8.0918\n",
      "[Epoch 023/1000] Eval loss: 8.4771\n",
      "[Epoch 024/1000] Train loss: 8.1613\n",
      "[Epoch 024/1000] Eval loss: 7.7507\n",
      "[Epoch 025/1000] Train loss: 8.0184\n",
      "[Epoch 025/1000] Eval loss: 8.0600\n",
      "[Epoch 026/1000] Train loss: 7.8965\n",
      "[Epoch 026/1000] Eval loss: 7.4906\n",
      "[Epoch 027/1000] Train loss: 7.6831\n",
      "[Epoch 027/1000] Eval loss: 7.8687\n",
      "[Epoch 028/1000] Train loss: 7.7141\n",
      "[Epoch 028/1000] Eval loss: 7.6370\n",
      "[Epoch 029/1000] Train loss: 7.3988\n",
      "[Epoch 029/1000] Eval loss: 7.5775\n",
      "[Epoch 030/1000] Train loss: 7.2801\n",
      "[Epoch 030/1000] Eval loss: 7.3577\n",
      "[Epoch 031/1000] Train loss: 7.1628\n",
      "[Epoch 031/1000] Eval loss: 7.3388\n",
      "[Epoch 032/1000] Train loss: 7.0797\n",
      "[Epoch 032/1000] Eval loss: 7.1683\n",
      "[Epoch 033/1000] Train loss: 6.9342\n",
      "[Epoch 033/1000] Eval loss: 7.0746\n",
      "[Epoch 034/1000] Train loss: 6.9666\n",
      "[Epoch 034/1000] Eval loss: 7.2690\n",
      "[Epoch 035/1000] Train loss: 6.8050\n",
      "[Epoch 035/1000] Eval loss: 7.1628\n",
      "[Epoch 036/1000] Train loss: 6.6418\n",
      "[Epoch 036/1000] Eval loss: 6.6227\n",
      "[Epoch 037/1000] Train loss: 6.8224\n",
      "[Epoch 037/1000] Eval loss: 7.1427\n",
      "[Epoch 038/1000] Train loss: 6.6306\n",
      "[Epoch 038/1000] Eval loss: 6.9617\n",
      "[Epoch 039/1000] Train loss: 6.5030\n",
      "[Epoch 039/1000] Eval loss: 6.8333\n",
      "[Epoch 040/1000] Train loss: 6.4766\n",
      "[Epoch 040/1000] Eval loss: 6.5530\n",
      "[Epoch 041/1000] Train loss: 6.3567\n",
      "[Epoch 041/1000] Eval loss: 6.5091\n",
      "[Epoch 042/1000] Train loss: 6.2573\n",
      "[Epoch 042/1000] Eval loss: 6.5251\n",
      "[Epoch 043/1000] Train loss: 6.2154\n",
      "[Epoch 043/1000] Eval loss: 6.6969\n",
      "[Epoch 044/1000] Train loss: 6.1195\n",
      "[Epoch 044/1000] Eval loss: 6.4433\n",
      "[Epoch 045/1000] Train loss: 5.9151\n",
      "[Epoch 045/1000] Eval loss: 6.2176\n",
      "[Epoch 046/1000] Train loss: 5.9286\n",
      "[Epoch 046/1000] Eval loss: 5.9392\n",
      "[Epoch 047/1000] Train loss: 5.8303\n",
      "[Epoch 047/1000] Eval loss: 5.9649\n",
      "[Epoch 048/1000] Train loss: 5.8290\n",
      "[Epoch 048/1000] Eval loss: 5.7863\n",
      "[Epoch 049/1000] Train loss: 5.7860\n",
      "[Epoch 049/1000] Eval loss: 6.2979\n",
      "[Epoch 050/1000] Train loss: 5.6774\n",
      "[Epoch 050/1000] Eval loss: 6.0565\n",
      "[Epoch 051/1000] Train loss: 5.5822\n",
      "[Epoch 051/1000] Eval loss: 5.7579\n",
      "[Epoch 052/1000] Train loss: 5.4605\n",
      "[Epoch 052/1000] Eval loss: 5.4587\n",
      "[Epoch 053/1000] Train loss: 5.4188\n",
      "[Epoch 053/1000] Eval loss: 5.7891\n",
      "[Epoch 054/1000] Train loss: 5.2849\n",
      "[Epoch 054/1000] Eval loss: 5.6233\n",
      "[Epoch 055/1000] Train loss: 5.3668\n",
      "[Epoch 055/1000] Eval loss: 5.7014\n",
      "[Epoch 056/1000] Train loss: 5.1501\n",
      "[Epoch 056/1000] Eval loss: 5.3125\n",
      "[Epoch 057/1000] Train loss: 4.9794\n",
      "[Epoch 057/1000] Eval loss: 5.1745\n",
      "[Epoch 058/1000] Train loss: 5.0663\n",
      "[Epoch 058/1000] Eval loss: 5.4425\n",
      "[Epoch 059/1000] Train loss: 4.9842\n",
      "[Epoch 059/1000] Eval loss: 5.0108\n",
      "[Epoch 060/1000] Train loss: 4.9646\n",
      "[Epoch 060/1000] Eval loss: 5.2293\n",
      "[Epoch 061/1000] Train loss: 4.8632\n",
      "[Epoch 061/1000] Eval loss: 4.9953\n",
      "[Epoch 062/1000] Train loss: 4.7925\n",
      "[Epoch 062/1000] Eval loss: 4.7820\n",
      "[Epoch 063/1000] Train loss: 4.7657\n",
      "[Epoch 063/1000] Eval loss: 4.7418\n",
      "[Epoch 064/1000] Train loss: 4.6602\n",
      "[Epoch 064/1000] Eval loss: 4.7712\n",
      "[Epoch 065/1000] Train loss: 4.6028\n",
      "[Epoch 065/1000] Eval loss: 4.6790\n",
      "[Epoch 066/1000] Train loss: 4.4781\n",
      "[Epoch 066/1000] Eval loss: 4.6831\n",
      "[Epoch 067/1000] Train loss: 4.5136\n",
      "[Epoch 067/1000] Eval loss: 4.4894\n",
      "[Epoch 068/1000] Train loss: 4.4095\n",
      "[Epoch 068/1000] Eval loss: 4.5734\n",
      "[Epoch 069/1000] Train loss: 4.3176\n",
      "[Epoch 069/1000] Eval loss: 4.5200\n",
      "[Epoch 070/1000] Train loss: 4.3067\n",
      "[Epoch 070/1000] Eval loss: 4.6239\n",
      "[Epoch 071/1000] Train loss: 4.3315\n",
      "[Epoch 071/1000] Eval loss: 4.1306\n",
      "[Epoch 072/1000] Train loss: 4.1323\n",
      "[Epoch 072/1000] Eval loss: 4.3765\n",
      "[Epoch 073/1000] Train loss: 4.1251\n",
      "[Epoch 073/1000] Eval loss: 4.2155\n",
      "[Epoch 074/1000] Train loss: 4.1257\n",
      "[Epoch 074/1000] Eval loss: 3.9308\n",
      "[Epoch 075/1000] Train loss: 4.0606\n",
      "[Epoch 075/1000] Eval loss: 4.2370\n",
      "[Epoch 076/1000] Train loss: 3.9719\n",
      "[Epoch 076/1000] Eval loss: 4.0285\n",
      "[Epoch 077/1000] Train loss: 3.9079\n",
      "[Epoch 077/1000] Eval loss: 4.1394\n",
      "[Epoch 078/1000] Train loss: 3.8460\n",
      "[Epoch 078/1000] Eval loss: 4.2345\n",
      "[Epoch 079/1000] Train loss: 3.8302\n",
      "[Epoch 079/1000] Eval loss: 3.8561\n",
      "[Epoch 080/1000] Train loss: 3.7914\n",
      "[Epoch 080/1000] Eval loss: 3.8378\n",
      "[Epoch 081/1000] Train loss: 3.7574\n",
      "[Epoch 081/1000] Eval loss: 3.8695\n",
      "[Epoch 082/1000] Train loss: 3.6967\n",
      "[Epoch 082/1000] Eval loss: 3.7694\n",
      "[Epoch 083/1000] Train loss: 3.6970\n",
      "[Epoch 083/1000] Eval loss: 3.6017\n",
      "[Epoch 084/1000] Train loss: 3.5947\n",
      "[Epoch 084/1000] Eval loss: 3.9786\n",
      "[Epoch 085/1000] Train loss: 3.5756\n",
      "[Epoch 085/1000] Eval loss: 3.5642\n",
      "[Epoch 086/1000] Train loss: 3.4979\n",
      "[Epoch 086/1000] Eval loss: 3.4269\n",
      "[Epoch 087/1000] Train loss: 3.4192\n",
      "[Epoch 087/1000] Eval loss: 3.6662\n",
      "[Epoch 088/1000] Train loss: 3.3873\n",
      "[Epoch 088/1000] Eval loss: 3.4371\n",
      "[Epoch 089/1000] Train loss: 3.3680\n",
      "[Epoch 089/1000] Eval loss: 3.3440\n",
      "[Epoch 090/1000] Train loss: 3.3405\n",
      "[Epoch 090/1000] Eval loss: 3.5375\n",
      "[Epoch 091/1000] Train loss: 3.2859\n",
      "[Epoch 091/1000] Eval loss: 3.2519\n",
      "[Epoch 092/1000] Train loss: 3.2375\n",
      "[Epoch 092/1000] Eval loss: 3.3058\n",
      "[Epoch 093/1000] Train loss: 3.1641\n",
      "[Epoch 093/1000] Eval loss: 3.2967\n",
      "[Epoch 094/1000] Train loss: 3.1440\n",
      "[Epoch 094/1000] Eval loss: 3.1316\n",
      "[Epoch 095/1000] Train loss: 3.1322\n",
      "[Epoch 095/1000] Eval loss: 3.2558\n",
      "[Epoch 096/1000] Train loss: 3.1559\n",
      "[Epoch 096/1000] Eval loss: 3.2552\n",
      "[Epoch 097/1000] Train loss: 3.0477\n",
      "[Epoch 097/1000] Eval loss: 3.1397\n",
      "[Epoch 098/1000] Train loss: 3.0237\n",
      "[Epoch 098/1000] Eval loss: 3.1701\n",
      "[Epoch 099/1000] Train loss: 3.0144\n",
      "[Epoch 099/1000] Eval loss: 3.1403\n",
      "[Epoch 100/1000] Train loss: 2.9420\n",
      "[Epoch 100/1000] Eval loss: 2.9908\n",
      "[Epoch 101/1000] Train loss: 2.9169\n",
      "[Epoch 101/1000] Eval loss: 3.1096\n",
      "[Epoch 102/1000] Train loss: 2.8522\n",
      "[Epoch 102/1000] Eval loss: 2.9824\n",
      "[Epoch 103/1000] Train loss: 2.8401\n",
      "[Epoch 103/1000] Eval loss: 2.8427\n",
      "[Epoch 104/1000] Train loss: 2.8210\n",
      "[Epoch 104/1000] Eval loss: 3.0281\n",
      "[Epoch 105/1000] Train loss: 2.7756\n",
      "[Epoch 105/1000] Eval loss: 2.9349\n",
      "[Epoch 106/1000] Train loss: 2.7448\n",
      "[Epoch 106/1000] Eval loss: 2.9244\n",
      "[Epoch 107/1000] Train loss: 2.7521\n",
      "[Epoch 107/1000] Eval loss: 2.8692\n",
      "[Epoch 108/1000] Train loss: 2.7376\n",
      "[Epoch 108/1000] Eval loss: 2.7718\n",
      "[Epoch 109/1000] Train loss: 2.6510\n",
      "[Epoch 109/1000] Eval loss: 2.7112\n",
      "[Epoch 110/1000] Train loss: 2.6705\n",
      "[Epoch 110/1000] Eval loss: 2.6769\n",
      "[Epoch 111/1000] Train loss: 2.6674\n",
      "[Epoch 111/1000] Eval loss: 2.8292\n",
      "[Epoch 112/1000] Train loss: 2.6534\n",
      "[Epoch 112/1000] Eval loss: 2.6951\n",
      "[Epoch 113/1000] Train loss: 2.5708\n",
      "[Epoch 113/1000] Eval loss: 2.6785\n",
      "[Epoch 114/1000] Train loss: 2.5563\n",
      "[Epoch 114/1000] Eval loss: 2.5251\n",
      "[Epoch 115/1000] Train loss: 2.5777\n",
      "[Epoch 115/1000] Eval loss: 2.6878\n",
      "[Epoch 116/1000] Train loss: 2.4960\n",
      "[Epoch 116/1000] Eval loss: 2.5710\n",
      "[Epoch 117/1000] Train loss: 2.5588\n",
      "[Epoch 117/1000] Eval loss: 2.4773\n",
      "[Epoch 118/1000] Train loss: 2.4615\n",
      "[Epoch 118/1000] Eval loss: 2.6865\n",
      "[Epoch 119/1000] Train loss: 2.4272\n",
      "[Epoch 119/1000] Eval loss: 2.4370\n",
      "[Epoch 120/1000] Train loss: 2.4483\n",
      "[Epoch 120/1000] Eval loss: 2.4407\n",
      "[Epoch 121/1000] Train loss: 2.4539\n",
      "[Epoch 121/1000] Eval loss: 2.6804\n",
      "[Epoch 122/1000] Train loss: 2.4005\n",
      "[Epoch 122/1000] Eval loss: 2.6153\n",
      "[Epoch 123/1000] Train loss: 2.3583\n",
      "[Epoch 123/1000] Eval loss: 2.5300\n",
      "[Epoch 124/1000] Train loss: 2.3593\n",
      "[Epoch 124/1000] Eval loss: 2.5508\n",
      "[Epoch 125/1000] Train loss: 2.3251\n",
      "[Epoch 125/1000] Eval loss: 2.4927\n",
      "[Epoch 126/1000] Train loss: 2.3330\n",
      "[Epoch 126/1000] Eval loss: 2.3785\n",
      "[Epoch 127/1000] Train loss: 2.3238\n",
      "[Epoch 127/1000] Eval loss: 2.4557\n",
      "[Epoch 128/1000] Train loss: 2.2657\n",
      "[Epoch 128/1000] Eval loss: 2.3890\n",
      "[Epoch 129/1000] Train loss: 2.2435\n",
      "[Epoch 129/1000] Eval loss: 2.2422\n",
      "[Epoch 130/1000] Train loss: 2.2517\n",
      "[Epoch 130/1000] Eval loss: 2.3710\n",
      "[Epoch 131/1000] Train loss: 2.2600\n",
      "[Epoch 131/1000] Eval loss: 2.3632\n",
      "[Epoch 132/1000] Train loss: 2.1709\n",
      "[Epoch 132/1000] Eval loss: 2.3193\n",
      "[Epoch 133/1000] Train loss: 2.2418\n",
      "[Epoch 133/1000] Eval loss: 2.1866\n",
      "[Epoch 134/1000] Train loss: 2.1523\n",
      "[Epoch 134/1000] Eval loss: 2.2385\n",
      "[Epoch 135/1000] Train loss: 2.1516\n",
      "[Epoch 135/1000] Eval loss: 2.3190\n",
      "[Epoch 136/1000] Train loss: 2.1331\n",
      "[Epoch 136/1000] Eval loss: 2.2505\n",
      "[Epoch 137/1000] Train loss: 2.1378\n",
      "[Epoch 137/1000] Eval loss: 2.1666\n",
      "[Epoch 138/1000] Train loss: 2.1494\n",
      "[Epoch 138/1000] Eval loss: 2.1923\n",
      "[Epoch 139/1000] Train loss: 2.0857\n",
      "[Epoch 139/1000] Eval loss: 2.2178\n",
      "[Epoch 140/1000] Train loss: 2.1042\n",
      "[Epoch 140/1000] Eval loss: 2.1965\n",
      "[Epoch 141/1000] Train loss: 2.0619\n",
      "[Epoch 141/1000] Eval loss: 2.1755\n",
      "[Epoch 142/1000] Train loss: 2.0437\n",
      "[Epoch 142/1000] Eval loss: 2.2794\n",
      "[Epoch 143/1000] Train loss: 2.0781\n",
      "[Epoch 143/1000] Eval loss: 2.1188\n",
      "[Epoch 144/1000] Train loss: 2.0660\n",
      "[Epoch 144/1000] Eval loss: 2.2235\n",
      "[Epoch 145/1000] Train loss: 2.0095\n",
      "[Epoch 145/1000] Eval loss: 2.1356\n",
      "[Epoch 146/1000] Train loss: 2.0071\n",
      "[Epoch 146/1000] Eval loss: 2.0681\n",
      "[Epoch 147/1000] Train loss: 2.0068\n",
      "[Epoch 147/1000] Eval loss: 2.0765\n",
      "[Epoch 148/1000] Train loss: 1.9858\n",
      "[Epoch 148/1000] Eval loss: 2.0685\n",
      "[Epoch 149/1000] Train loss: 1.9848\n",
      "[Epoch 149/1000] Eval loss: 2.0543\n",
      "[Epoch 150/1000] Train loss: 1.9598\n",
      "[Epoch 150/1000] Eval loss: 2.1325\n",
      "[Epoch 151/1000] Train loss: 1.9563\n",
      "[Epoch 151/1000] Eval loss: 2.0546\n",
      "[Epoch 152/1000] Train loss: 1.9647\n",
      "[Epoch 152/1000] Eval loss: 2.0433\n",
      "[Epoch 153/1000] Train loss: 1.9483\n",
      "[Epoch 153/1000] Eval loss: 2.1225\n",
      "[Epoch 154/1000] Train loss: 1.9425\n",
      "[Epoch 154/1000] Eval loss: 2.1497\n",
      "[Epoch 155/1000] Train loss: 1.9340\n",
      "[Epoch 155/1000] Eval loss: 1.9408\n",
      "[Epoch 156/1000] Train loss: 1.9223\n",
      "[Epoch 156/1000] Eval loss: 1.9651\n",
      "[Epoch 157/1000] Train loss: 1.9185\n",
      "[Epoch 157/1000] Eval loss: 2.0048\n",
      "[Epoch 158/1000] Train loss: 1.9183\n",
      "[Epoch 158/1000] Eval loss: 1.9238\n",
      "[Epoch 159/1000] Train loss: 1.8904\n",
      "[Epoch 159/1000] Eval loss: 1.9417\n",
      "[Epoch 160/1000] Train loss: 1.8880\n",
      "[Epoch 160/1000] Eval loss: 2.0276\n",
      "[Epoch 161/1000] Train loss: 1.8814\n",
      "[Epoch 161/1000] Eval loss: 1.9474\n",
      "[Epoch 162/1000] Train loss: 1.8461\n",
      "[Epoch 162/1000] Eval loss: 1.8933\n",
      "[Epoch 163/1000] Train loss: 1.8581\n",
      "[Epoch 163/1000] Eval loss: 1.9249\n",
      "[Epoch 164/1000] Train loss: 1.8653\n",
      "[Epoch 164/1000] Eval loss: 1.8671\n",
      "[Epoch 165/1000] Train loss: 1.8571\n",
      "[Epoch 165/1000] Eval loss: 1.9537\n",
      "[Epoch 166/1000] Train loss: 1.8579\n",
      "[Epoch 166/1000] Eval loss: 1.9407\n",
      "[Epoch 167/1000] Train loss: 1.8323\n",
      "[Epoch 167/1000] Eval loss: 1.9735\n",
      "[Epoch 168/1000] Train loss: 1.8022\n",
      "[Epoch 168/1000] Eval loss: 1.8845\n",
      "[Epoch 169/1000] Train loss: 1.8211\n",
      "[Epoch 169/1000] Eval loss: 1.9095\n",
      "[Epoch 170/1000] Train loss: 1.8131\n",
      "[Epoch 170/1000] Eval loss: 1.9873\n",
      "[Epoch 171/1000] Train loss: 1.8146\n",
      "[Epoch 171/1000] Eval loss: 1.9252\n",
      "[Epoch 172/1000] Train loss: 1.7883\n",
      "[Epoch 172/1000] Eval loss: 1.9736\n",
      "[Epoch 173/1000] Train loss: 1.8474\n",
      "[Epoch 173/1000] Eval loss: 1.8755\n",
      "[Epoch 174/1000] Train loss: 1.7872\n",
      "[Epoch 174/1000] Eval loss: 1.9468\n",
      "[Epoch 175/1000] Train loss: 1.7782\n",
      "[Epoch 175/1000] Eval loss: 1.8047\n",
      "[Epoch 176/1000] Train loss: 1.7837\n",
      "[Epoch 176/1000] Eval loss: 1.8329\n",
      "[Epoch 177/1000] Train loss: 1.8026\n",
      "[Epoch 177/1000] Eval loss: 1.8777\n",
      "[Epoch 178/1000] Train loss: 1.7743\n",
      "[Epoch 178/1000] Eval loss: 1.8417\n",
      "[Epoch 179/1000] Train loss: 1.7383\n",
      "[Epoch 179/1000] Eval loss: 1.8609\n",
      "[Epoch 180/1000] Train loss: 1.7879\n",
      "[Epoch 180/1000] Eval loss: 1.8554\n",
      "[Epoch 181/1000] Train loss: 1.7543\n",
      "[Epoch 181/1000] Eval loss: 1.7933\n",
      "[Epoch 182/1000] Train loss: 1.7395\n",
      "[Epoch 182/1000] Eval loss: 1.8866\n",
      "[Epoch 183/1000] Train loss: 1.7861\n",
      "[Epoch 183/1000] Eval loss: 1.9317\n",
      "[Epoch 184/1000] Train loss: 1.7439\n",
      "[Epoch 184/1000] Eval loss: 1.8318\n",
      "[Epoch 185/1000] Train loss: 1.7385\n",
      "[Epoch 185/1000] Eval loss: 1.8012\n",
      "[Epoch 186/1000] Train loss: 1.7214\n",
      "[Epoch 186/1000] Eval loss: 1.8207\n",
      "[Epoch 187/1000] Train loss: 1.7076\n",
      "[Epoch 187/1000] Eval loss: 1.8594\n",
      "[Epoch 188/1000] Train loss: 1.7064\n",
      "[Epoch 188/1000] Eval loss: 1.8279\n",
      "[Epoch 189/1000] Train loss: 1.7230\n",
      "[Epoch 189/1000] Eval loss: 1.7253\n",
      "[Epoch 190/1000] Train loss: 1.7101\n",
      "[Epoch 190/1000] Eval loss: 1.6966\n",
      "[Epoch 191/1000] Train loss: 1.7527\n",
      "[Epoch 191/1000] Eval loss: 1.8725\n",
      "[Epoch 192/1000] Train loss: 1.7311\n",
      "[Epoch 192/1000] Eval loss: 1.8100\n",
      "[Epoch 193/1000] Train loss: 1.7372\n",
      "[Epoch 193/1000] Eval loss: 1.7178\n",
      "[Epoch 194/1000] Train loss: 1.6823\n",
      "[Epoch 194/1000] Eval loss: 1.8447\n",
      "[Epoch 195/1000] Train loss: 1.7002\n",
      "[Epoch 195/1000] Eval loss: 1.8334\n",
      "[Epoch 196/1000] Train loss: 1.6996\n",
      "[Epoch 196/1000] Eval loss: 1.8142\n",
      "[Epoch 197/1000] Train loss: 1.7139\n",
      "[Epoch 197/1000] Eval loss: 1.6710\n",
      "[Epoch 198/1000] Train loss: 1.7100\n",
      "[Epoch 198/1000] Eval loss: 1.9296\n",
      "[Epoch 199/1000] Train loss: 1.6600\n",
      "[Epoch 199/1000] Eval loss: 1.8538\n",
      "[Epoch 200/1000] Train loss: 1.6976\n",
      "[Epoch 200/1000] Eval loss: 1.6309\n",
      "[Epoch 201/1000] Train loss: 1.6885\n",
      "[Epoch 201/1000] Eval loss: 1.7628\n",
      "[Epoch 202/1000] Train loss: 1.6864\n",
      "[Epoch 202/1000] Eval loss: 1.7420\n",
      "[Epoch 203/1000] Train loss: 1.6346\n",
      "[Epoch 203/1000] Eval loss: 1.8248\n",
      "[Epoch 204/1000] Train loss: 1.6451\n",
      "[Epoch 204/1000] Eval loss: 1.8504\n",
      "[Epoch 205/1000] Train loss: 1.6629\n",
      "[Epoch 205/1000] Eval loss: 1.7065\n",
      "[Epoch 206/1000] Train loss: 1.6609\n",
      "[Epoch 206/1000] Eval loss: 1.7085\n",
      "[Epoch 207/1000] Train loss: 1.6423\n",
      "[Epoch 207/1000] Eval loss: 1.8608\n",
      "[Epoch 208/1000] Train loss: 1.6316\n",
      "[Epoch 208/1000] Eval loss: 1.8017\n",
      "[Epoch 209/1000] Train loss: 1.6537\n",
      "[Epoch 209/1000] Eval loss: 1.6731\n",
      "[Epoch 210/1000] Train loss: 1.6675\n",
      "[Epoch 210/1000] Eval loss: 1.7125\n",
      "[Epoch 211/1000] Train loss: 1.6238\n",
      "[Epoch 211/1000] Eval loss: 1.6625\n",
      "[Epoch 212/1000] Train loss: 1.6266\n",
      "[Epoch 212/1000] Eval loss: 2.0126\n",
      "[Epoch 213/1000] Train loss: 1.6608\n",
      "[Epoch 213/1000] Eval loss: 1.7659\n",
      "[Epoch 214/1000] Train loss: 1.6415\n",
      "[Epoch 214/1000] Eval loss: 1.6971\n",
      "[Epoch 215/1000] Train loss: 1.6082\n",
      "[Epoch 215/1000] Eval loss: 1.8534\n",
      "[Epoch 216/1000] Train loss: 1.6013\n",
      "[Epoch 216/1000] Eval loss: 1.7839\n",
      "[Epoch 217/1000] Train loss: 1.6088\n",
      "[Epoch 217/1000] Eval loss: 1.7158\n",
      "[Epoch 218/1000] Train loss: 1.5915\n",
      "[Epoch 218/1000] Eval loss: 1.7892\n",
      "[Epoch 219/1000] Train loss: 1.6469\n",
      "[Epoch 219/1000] Eval loss: 1.6481\n",
      "[Epoch 220/1000] Train loss: 1.6205\n",
      "[Epoch 220/1000] Eval loss: 1.7336\n",
      "[Epoch 221/1000] Train loss: 1.6299\n",
      "[Epoch 221/1000] Eval loss: 1.6571\n",
      "[Epoch 222/1000] Train loss: 1.6079\n",
      "[Epoch 222/1000] Eval loss: 1.6492\n",
      "[Epoch 223/1000] Train loss: 1.6332\n",
      "[Epoch 223/1000] Eval loss: 1.7382\n",
      "[Epoch 224/1000] Train loss: 1.6224\n",
      "[Epoch 224/1000] Eval loss: 1.6014\n",
      "[Epoch 225/1000] Train loss: 1.5916\n",
      "[Epoch 225/1000] Eval loss: 1.7770\n",
      "[Epoch 226/1000] Train loss: 1.5959\n",
      "[Epoch 226/1000] Eval loss: 1.6653\n",
      "[Epoch 227/1000] Train loss: 1.6103\n",
      "[Epoch 227/1000] Eval loss: 1.7251\n",
      "[Epoch 228/1000] Train loss: 1.5915\n",
      "[Epoch 228/1000] Eval loss: 1.6357\n",
      "[Epoch 229/1000] Train loss: 1.5965\n",
      "[Epoch 229/1000] Eval loss: 1.7154\n",
      "[Epoch 230/1000] Train loss: 1.6249\n",
      "[Epoch 230/1000] Eval loss: 1.6485\n",
      "[Epoch 231/1000] Train loss: 1.5949\n",
      "[Epoch 231/1000] Eval loss: 1.5738\n",
      "[Epoch 232/1000] Train loss: 1.6039\n",
      "[Epoch 232/1000] Eval loss: 1.6517\n",
      "[Epoch 233/1000] Train loss: 1.5693\n",
      "[Epoch 233/1000] Eval loss: 1.6017\n",
      "[Epoch 234/1000] Train loss: 1.5454\n",
      "[Epoch 234/1000] Eval loss: 1.6575\n",
      "[Epoch 235/1000] Train loss: 1.5511\n",
      "[Epoch 235/1000] Eval loss: 1.6182\n",
      "[Epoch 236/1000] Train loss: 1.5902\n",
      "[Epoch 236/1000] Eval loss: 1.7174\n",
      "[Epoch 237/1000] Train loss: 1.5441\n",
      "[Epoch 237/1000] Eval loss: 1.7015\n",
      "[Epoch 238/1000] Train loss: 1.5430\n",
      "[Epoch 238/1000] Eval loss: 1.7192\n",
      "[Epoch 239/1000] Train loss: 1.5565\n",
      "[Epoch 239/1000] Eval loss: 1.6528\n",
      "[Epoch 240/1000] Train loss: 1.5309\n",
      "[Epoch 240/1000] Eval loss: 1.5943\n",
      "[Epoch 241/1000] Train loss: 1.5592\n",
      "[Epoch 241/1000] Eval loss: 1.5630\n",
      "[Epoch 242/1000] Train loss: 1.5739\n",
      "[Epoch 242/1000] Eval loss: 1.5858\n",
      "[Epoch 243/1000] Train loss: 1.5390\n",
      "[Epoch 243/1000] Eval loss: 1.5403\n",
      "[Epoch 244/1000] Train loss: 1.5593\n",
      "[Epoch 244/1000] Eval loss: 1.7021\n",
      "[Epoch 245/1000] Train loss: 1.5519\n",
      "[Epoch 245/1000] Eval loss: 1.5951\n",
      "[Epoch 246/1000] Train loss: 1.5754\n",
      "[Epoch 246/1000] Eval loss: 1.6250\n",
      "[Epoch 247/1000] Train loss: 1.5290\n",
      "[Epoch 247/1000] Eval loss: 1.6807\n",
      "[Epoch 248/1000] Train loss: 1.5545\n",
      "[Epoch 248/1000] Eval loss: 1.6075\n",
      "[Epoch 249/1000] Train loss: 1.5454\n",
      "[Epoch 249/1000] Eval loss: 1.6450\n",
      "[Epoch 250/1000] Train loss: 1.5412\n",
      "[Epoch 250/1000] Eval loss: 1.7333\n",
      "[Epoch 251/1000] Train loss: 1.5265\n",
      "[Epoch 251/1000] Eval loss: 1.6550\n",
      "[Epoch 252/1000] Train loss: 1.5362\n",
      "[Epoch 252/1000] Eval loss: 1.5837\n",
      "[Epoch 253/1000] Train loss: 1.5348\n",
      "[Epoch 253/1000] Eval loss: 1.5711\n",
      "[Epoch 254/1000] Train loss: 1.5301\n",
      "[Epoch 254/1000] Eval loss: 1.6001\n",
      "[Epoch 255/1000] Train loss: 1.5212\n",
      "[Epoch 255/1000] Eval loss: 1.6201\n",
      "[Epoch 256/1000] Train loss: 1.5085\n",
      "[Epoch 256/1000] Eval loss: 1.5379\n",
      "[Epoch 257/1000] Train loss: 1.4963\n",
      "[Epoch 257/1000] Eval loss: 1.6658\n",
      "[Epoch 258/1000] Train loss: 1.5543\n",
      "[Epoch 258/1000] Eval loss: 1.5827\n",
      "[Epoch 259/1000] Train loss: 1.5449\n",
      "[Epoch 259/1000] Eval loss: 1.6163\n",
      "[Epoch 260/1000] Train loss: 1.5054\n",
      "[Epoch 260/1000] Eval loss: 1.5750\n",
      "[Epoch 261/1000] Train loss: 1.5191\n",
      "[Epoch 261/1000] Eval loss: 1.5925\n",
      "[Epoch 262/1000] Train loss: 1.5306\n",
      "[Epoch 262/1000] Eval loss: 1.5678\n",
      "[Epoch 263/1000] Train loss: 1.4911\n",
      "[Epoch 263/1000] Eval loss: 1.6122\n",
      "[Epoch 264/1000] Train loss: 1.5183\n",
      "[Epoch 264/1000] Eval loss: 1.5802\n",
      "[Epoch 265/1000] Train loss: 1.5000\n",
      "[Epoch 265/1000] Eval loss: 1.5289\n",
      "[Epoch 266/1000] Train loss: 1.5106\n",
      "[Epoch 266/1000] Eval loss: 1.5708\n",
      "[Epoch 267/1000] Train loss: 1.5550\n",
      "[Epoch 267/1000] Eval loss: 1.5546\n",
      "[Epoch 268/1000] Train loss: 1.5009\n",
      "[Epoch 268/1000] Eval loss: 1.5427\n",
      "[Epoch 269/1000] Train loss: 1.4970\n",
      "[Epoch 269/1000] Eval loss: 1.5554\n",
      "[Epoch 270/1000] Train loss: 1.5146\n",
      "[Epoch 270/1000] Eval loss: 1.5473\n",
      "[Epoch 271/1000] Train loss: 1.5232\n",
      "[Epoch 271/1000] Eval loss: 1.5751\n",
      "[Epoch 272/1000] Train loss: 1.4781\n",
      "[Epoch 272/1000] Eval loss: 1.4752\n",
      "[Epoch 273/1000] Train loss: 1.5008\n",
      "[Epoch 273/1000] Eval loss: 1.5236\n",
      "[Epoch 274/1000] Train loss: 1.4515\n",
      "[Epoch 274/1000] Eval loss: 1.7104\n",
      "[Epoch 275/1000] Train loss: 1.5085\n",
      "[Epoch 275/1000] Eval loss: 1.6455\n",
      "[Epoch 276/1000] Train loss: 1.4996\n",
      "[Epoch 276/1000] Eval loss: 1.6342\n",
      "[Epoch 277/1000] Train loss: 1.5198\n",
      "[Epoch 277/1000] Eval loss: 1.5216\n",
      "[Epoch 278/1000] Train loss: 1.4825\n",
      "[Epoch 278/1000] Eval loss: 1.6553\n",
      "[Epoch 279/1000] Train loss: 1.5171\n",
      "[Epoch 279/1000] Eval loss: 1.6522\n",
      "[Epoch 280/1000] Train loss: 1.5243\n",
      "[Epoch 280/1000] Eval loss: 1.6868\n",
      "[Epoch 281/1000] Train loss: 1.4695\n",
      "[Epoch 281/1000] Eval loss: 1.5665\n",
      "[Epoch 282/1000] Train loss: 1.5019\n",
      "[Epoch 282/1000] Eval loss: 1.6338\n",
      "[Epoch 283/1000] Train loss: 1.4818\n",
      "[Epoch 283/1000] Eval loss: 1.5133\n",
      "[Epoch 284/1000] Train loss: 1.4723\n",
      "[Epoch 284/1000] Eval loss: 1.6228\n",
      "[Epoch 285/1000] Train loss: 1.5006\n",
      "[Epoch 285/1000] Eval loss: 1.5134\n",
      "[Epoch 286/1000] Train loss: 1.4753\n",
      "[Epoch 286/1000] Eval loss: 1.6524\n",
      "[Epoch 287/1000] Train loss: 1.4707\n",
      "[Epoch 287/1000] Eval loss: 1.4677\n",
      "[Epoch 288/1000] Train loss: 1.4849\n",
      "[Epoch 288/1000] Eval loss: 1.5821\n",
      "[Epoch 289/1000] Train loss: 1.4839\n",
      "[Epoch 289/1000] Eval loss: 1.5529\n",
      "[Epoch 290/1000] Train loss: 1.4679\n",
      "[Epoch 290/1000] Eval loss: 1.4491\n",
      "[Epoch 291/1000] Train loss: 1.4713\n",
      "[Epoch 291/1000] Eval loss: 1.4964\n",
      "[Epoch 292/1000] Train loss: 1.4737\n",
      "[Epoch 292/1000] Eval loss: 1.5137\n",
      "[Epoch 293/1000] Train loss: 1.4876\n",
      "[Epoch 293/1000] Eval loss: 1.5686\n",
      "[Epoch 294/1000] Train loss: 1.4759\n",
      "[Epoch 294/1000] Eval loss: 1.5916\n",
      "[Epoch 295/1000] Train loss: 1.4714\n",
      "[Epoch 295/1000] Eval loss: 1.5989\n",
      "[Epoch 296/1000] Train loss: 1.5026\n",
      "[Epoch 296/1000] Eval loss: 1.5750\n",
      "[Epoch 297/1000] Train loss: 1.4543\n",
      "[Epoch 297/1000] Eval loss: 1.4864\n",
      "[Epoch 298/1000] Train loss: 1.4758\n",
      "[Epoch 298/1000] Eval loss: 1.4823\n",
      "[Epoch 299/1000] Train loss: 1.4672\n",
      "[Epoch 299/1000] Eval loss: 1.7383\n",
      "[Epoch 300/1000] Train loss: 1.4968\n",
      "[Epoch 300/1000] Eval loss: 1.6324\n",
      "[Epoch 301/1000] Train loss: 1.4975\n",
      "[Epoch 301/1000] Eval loss: 1.4297\n",
      "[Epoch 302/1000] Train loss: 1.4586\n",
      "[Epoch 302/1000] Eval loss: 1.5289\n",
      "[Epoch 303/1000] Train loss: 1.4952\n",
      "[Epoch 303/1000] Eval loss: 1.4631\n",
      "[Epoch 304/1000] Train loss: 1.4972\n",
      "[Epoch 304/1000] Eval loss: 1.5185\n",
      "[Epoch 305/1000] Train loss: 1.5003\n",
      "[Epoch 305/1000] Eval loss: 1.5285\n",
      "[Epoch 306/1000] Train loss: 1.4774\n",
      "[Epoch 306/1000] Eval loss: 1.7139\n",
      "[Epoch 307/1000] Train loss: 1.4865\n",
      "[Epoch 307/1000] Eval loss: 1.5296\n",
      "[Epoch 308/1000] Train loss: 1.4470\n",
      "[Epoch 308/1000] Eval loss: 1.5580\n",
      "[Epoch 309/1000] Train loss: 1.4544\n",
      "[Epoch 309/1000] Eval loss: 1.5842\n",
      "[Epoch 310/1000] Train loss: 1.4207\n",
      "[Epoch 310/1000] Eval loss: 1.4354\n",
      "[Epoch 311/1000] Train loss: 1.4212\n",
      "[Epoch 311/1000] Eval loss: 1.5773\n",
      "[Epoch 312/1000] Train loss: 1.4787\n",
      "[Epoch 312/1000] Eval loss: 1.5113\n",
      "[Epoch 313/1000] Train loss: 1.4520\n",
      "[Epoch 313/1000] Eval loss: 1.3875\n",
      "[Epoch 314/1000] Train loss: 1.4822\n",
      "[Epoch 314/1000] Eval loss: 1.4661\n",
      "[Epoch 315/1000] Train loss: 1.4638\n",
      "[Epoch 315/1000] Eval loss: 1.4827\n",
      "[Epoch 316/1000] Train loss: 1.4454\n",
      "[Epoch 316/1000] Eval loss: 1.6538\n",
      "[Epoch 317/1000] Train loss: 1.4495\n",
      "[Epoch 317/1000] Eval loss: 1.6729\n",
      "[Epoch 318/1000] Train loss: 1.4774\n",
      "[Epoch 318/1000] Eval loss: 1.6087\n",
      "[Epoch 319/1000] Train loss: 1.4525\n",
      "[Epoch 319/1000] Eval loss: 1.5126\n",
      "[Epoch 320/1000] Train loss: 1.4389\n",
      "[Epoch 320/1000] Eval loss: 1.4235\n",
      "[Epoch 321/1000] Train loss: 1.4517\n",
      "[Epoch 321/1000] Eval loss: 1.4629\n",
      "[Epoch 322/1000] Train loss: 1.4632\n",
      "[Epoch 322/1000] Eval loss: 1.5085\n",
      "[Epoch 323/1000] Train loss: 1.4494\n",
      "[Epoch 323/1000] Eval loss: 1.5042\n",
      "[Epoch 324/1000] Train loss: 1.4480\n",
      "[Epoch 324/1000] Eval loss: 1.5289\n",
      "[Epoch 325/1000] Train loss: 1.4322\n",
      "[Epoch 325/1000] Eval loss: 1.5086\n",
      "[Epoch 326/1000] Train loss: 1.4190\n",
      "[Epoch 326/1000] Eval loss: 1.5427\n",
      "[Epoch 327/1000] Train loss: 1.4478\n",
      "[Epoch 327/1000] Eval loss: 1.4455\n",
      "[Epoch 328/1000] Train loss: 1.4584\n",
      "[Epoch 328/1000] Eval loss: 1.5673\n",
      "[Epoch 329/1000] Train loss: 1.4468\n",
      "[Epoch 329/1000] Eval loss: 1.4572\n",
      "[Epoch 330/1000] Train loss: 1.4035\n",
      "[Epoch 330/1000] Eval loss: 1.4948\n",
      "[Epoch 331/1000] Train loss: 1.4094\n",
      "[Epoch 331/1000] Eval loss: 1.4170\n",
      "[Epoch 332/1000] Train loss: 1.4203\n",
      "[Epoch 332/1000] Eval loss: 1.4797\n",
      "[Epoch 333/1000] Train loss: 1.4207\n",
      "[Epoch 333/1000] Eval loss: 1.4294\n",
      "[Epoch 334/1000] Train loss: 1.4052\n",
      "[Epoch 334/1000] Eval loss: 1.4595\n",
      "[Epoch 335/1000] Train loss: 1.3925\n",
      "[Epoch 335/1000] Eval loss: 1.5524\n",
      "[Epoch 336/1000] Train loss: 1.4229\n",
      "[Epoch 336/1000] Eval loss: 1.4463\n",
      "[Epoch 337/1000] Train loss: 1.4077\n",
      "[Epoch 337/1000] Eval loss: 1.5371\n",
      "[Epoch 338/1000] Train loss: 1.4474\n",
      "[Epoch 338/1000] Eval loss: 1.4794\n",
      "[Epoch 339/1000] Train loss: 1.4386\n",
      "[Epoch 339/1000] Eval loss: 1.4383\n",
      "[Epoch 340/1000] Train loss: 1.4027\n",
      "[Epoch 340/1000] Eval loss: 1.4683\n",
      "[Epoch 341/1000] Train loss: 1.4392\n",
      "[Epoch 341/1000] Eval loss: 1.5077\n",
      "[Epoch 342/1000] Train loss: 1.4338\n",
      "[Epoch 342/1000] Eval loss: 1.6314\n",
      "[Epoch 343/1000] Train loss: 1.4597\n",
      "[Epoch 343/1000] Eval loss: 1.4129\n",
      "[Epoch 344/1000] Train loss: 1.3920\n",
      "[Epoch 344/1000] Eval loss: 1.5470\n",
      "[Epoch 345/1000] Train loss: 1.4366\n",
      "[Epoch 345/1000] Eval loss: 1.5362\n",
      "[Epoch 346/1000] Train loss: 1.4021\n",
      "[Epoch 346/1000] Eval loss: 1.4422\n",
      "[Epoch 347/1000] Train loss: 1.4146\n",
      "[Epoch 347/1000] Eval loss: 1.4465\n",
      "[Epoch 348/1000] Train loss: 1.3879\n",
      "[Epoch 348/1000] Eval loss: 1.4260\n",
      "[Epoch 349/1000] Train loss: 1.3858\n",
      "[Epoch 349/1000] Eval loss: 1.5471\n",
      "[Epoch 350/1000] Train loss: 1.3939\n",
      "[Epoch 350/1000] Eval loss: 1.3757\n",
      "[Epoch 351/1000] Train loss: 1.4220\n",
      "[Epoch 351/1000] Eval loss: 1.4754\n",
      "[Epoch 352/1000] Train loss: 1.4274\n",
      "[Epoch 352/1000] Eval loss: 1.4471\n",
      "[Epoch 353/1000] Train loss: 1.4184\n",
      "[Epoch 353/1000] Eval loss: 1.3848\n",
      "[Epoch 354/1000] Train loss: 1.4007\n",
      "[Epoch 354/1000] Eval loss: 1.4923\n",
      "[Epoch 355/1000] Train loss: 1.3935\n",
      "[Epoch 355/1000] Eval loss: 1.3970\n",
      "[Epoch 356/1000] Train loss: 1.3934\n",
      "[Epoch 356/1000] Eval loss: 1.4414\n",
      "[Epoch 357/1000] Train loss: 1.3897\n",
      "[Epoch 357/1000] Eval loss: 1.4456\n",
      "[Epoch 358/1000] Train loss: 1.3943\n",
      "[Epoch 358/1000] Eval loss: 1.5338\n",
      "[Epoch 359/1000] Train loss: 1.3977\n",
      "[Epoch 359/1000] Eval loss: 1.4027\n",
      "[Epoch 360/1000] Train loss: 1.3755\n",
      "[Epoch 360/1000] Eval loss: 1.4586\n",
      "[Epoch 361/1000] Train loss: 1.3652\n",
      "[Epoch 361/1000] Eval loss: 1.4490\n",
      "[Epoch 362/1000] Train loss: 1.3683\n",
      "[Epoch 362/1000] Eval loss: 1.5283\n",
      "[Epoch 363/1000] Train loss: 1.3861\n",
      "[Epoch 363/1000] Eval loss: 1.3707\n",
      "[Epoch 364/1000] Train loss: 1.3978\n",
      "[Epoch 364/1000] Eval loss: 1.3905\n",
      "[Epoch 365/1000] Train loss: 1.3929\n",
      "[Epoch 365/1000] Eval loss: 1.4480\n",
      "[Epoch 366/1000] Train loss: 1.3911\n",
      "[Epoch 366/1000] Eval loss: 1.4759\n",
      "[Epoch 367/1000] Train loss: 1.3747\n",
      "[Epoch 367/1000] Eval loss: 1.6050\n",
      "[Epoch 368/1000] Train loss: 1.4115\n",
      "[Epoch 368/1000] Eval loss: 1.4493\n",
      "[Epoch 369/1000] Train loss: 1.3858\n",
      "[Epoch 369/1000] Eval loss: 1.3964\n",
      "[Epoch 370/1000] Train loss: 1.3855\n",
      "[Epoch 370/1000] Eval loss: 1.4885\n",
      "[Epoch 371/1000] Train loss: 1.3661\n",
      "[Epoch 371/1000] Eval loss: 1.5806\n",
      "[Epoch 372/1000] Train loss: 1.4357\n",
      "[Epoch 372/1000] Eval loss: 1.5543\n",
      "[Epoch 373/1000] Train loss: 1.3677\n",
      "[Epoch 373/1000] Eval loss: 1.4306\n",
      "[Epoch 374/1000] Train loss: 1.4017\n",
      "[Epoch 374/1000] Eval loss: 1.3821\n",
      "[Epoch 375/1000] Train loss: 1.4099\n",
      "[Epoch 375/1000] Eval loss: 1.3811\n",
      "[Epoch 376/1000] Train loss: 1.3890\n",
      "[Epoch 376/1000] Eval loss: 1.3957\n",
      "[Epoch 377/1000] Train loss: 1.3942\n",
      "[Epoch 377/1000] Eval loss: 1.3665\n",
      "[Epoch 378/1000] Train loss: 1.3805\n",
      "[Epoch 378/1000] Eval loss: 1.5396\n",
      "[Epoch 379/1000] Train loss: 1.4096\n",
      "[Epoch 379/1000] Eval loss: 1.4204\n",
      "[Epoch 380/1000] Train loss: 1.3639\n",
      "[Epoch 380/1000] Eval loss: 1.4186\n",
      "[Epoch 381/1000] Train loss: 1.3801\n",
      "[Epoch 381/1000] Eval loss: 1.4374\n",
      "[Epoch 382/1000] Train loss: 1.3656\n",
      "[Epoch 382/1000] Eval loss: 1.4246\n",
      "[Epoch 383/1000] Train loss: 1.3681\n",
      "[Epoch 383/1000] Eval loss: 1.3580\n",
      "[Epoch 384/1000] Train loss: 1.3566\n",
      "[Epoch 384/1000] Eval loss: 1.3701\n",
      "[Epoch 385/1000] Train loss: 1.3655\n",
      "[Epoch 385/1000] Eval loss: 1.5637\n",
      "[Epoch 386/1000] Train loss: 1.3722\n",
      "[Epoch 386/1000] Eval loss: 1.4375\n",
      "[Epoch 387/1000] Train loss: 1.3774\n",
      "[Epoch 387/1000] Eval loss: 1.3534\n",
      "[Epoch 388/1000] Train loss: 1.3778\n",
      "[Epoch 388/1000] Eval loss: 1.4493\n",
      "[Epoch 389/1000] Train loss: 1.3647\n",
      "[Epoch 389/1000] Eval loss: 1.3921\n",
      "[Epoch 390/1000] Train loss: 1.4032\n",
      "[Epoch 390/1000] Eval loss: 1.5108\n",
      "[Epoch 391/1000] Train loss: 1.3520\n",
      "[Epoch 391/1000] Eval loss: 1.4276\n",
      "[Epoch 392/1000] Train loss: 1.3516\n",
      "[Epoch 392/1000] Eval loss: 1.4431\n",
      "[Epoch 393/1000] Train loss: 1.3631\n",
      "[Epoch 393/1000] Eval loss: 1.4093\n",
      "[Epoch 394/1000] Train loss: 1.3578\n",
      "[Epoch 394/1000] Eval loss: 1.3858\n",
      "[Epoch 395/1000] Train loss: 1.3982\n",
      "[Epoch 395/1000] Eval loss: 1.4522\n",
      "[Epoch 396/1000] Train loss: 1.3572\n",
      "[Epoch 396/1000] Eval loss: 1.4123\n",
      "[Epoch 397/1000] Train loss: 1.3352\n",
      "[Epoch 397/1000] Eval loss: 1.4311\n",
      "[Epoch 398/1000] Train loss: 1.3619\n",
      "[Epoch 398/1000] Eval loss: 1.4545\n",
      "[Epoch 399/1000] Train loss: 1.3491\n",
      "[Epoch 399/1000] Eval loss: 1.6099\n",
      "[Epoch 400/1000] Train loss: 1.3622\n",
      "[Epoch 400/1000] Eval loss: 1.3896\n",
      "[Epoch 401/1000] Train loss: 1.3707\n",
      "[Epoch 401/1000] Eval loss: 1.4049\n",
      "[Epoch 402/1000] Train loss: 1.3507\n",
      "[Epoch 402/1000] Eval loss: 1.3841\n",
      "[Epoch 403/1000] Train loss: 1.3649\n",
      "[Epoch 403/1000] Eval loss: 1.4403\n",
      "[Epoch 404/1000] Train loss: 1.3640\n",
      "[Epoch 404/1000] Eval loss: 1.4324\n",
      "[Epoch 405/1000] Train loss: 1.3776\n",
      "[Epoch 405/1000] Eval loss: 1.4215\n",
      "[Epoch 406/1000] Train loss: 1.3629\n",
      "[Epoch 406/1000] Eval loss: 1.4312\n",
      "[Epoch 407/1000] Train loss: 1.3389\n",
      "[Epoch 407/1000] Eval loss: 1.4063\n",
      "[Epoch 408/1000] Train loss: 1.3346\n",
      "[Epoch 408/1000] Eval loss: 1.4558\n",
      "[Epoch 409/1000] Train loss: 1.3486\n",
      "[Epoch 409/1000] Eval loss: 1.3314\n",
      "[Epoch 410/1000] Train loss: 1.3278\n",
      "[Epoch 410/1000] Eval loss: 1.5163\n",
      "[Epoch 411/1000] Train loss: 1.3717\n",
      "[Epoch 411/1000] Eval loss: 1.3850\n",
      "[Epoch 412/1000] Train loss: 1.3525\n",
      "[Epoch 412/1000] Eval loss: 1.4402\n",
      "[Epoch 413/1000] Train loss: 1.3440\n",
      "[Epoch 413/1000] Eval loss: 1.2996\n",
      "[Epoch 414/1000] Train loss: 1.3399\n",
      "[Epoch 414/1000] Eval loss: 1.4630\n",
      "[Epoch 415/1000] Train loss: 1.3684\n",
      "[Epoch 415/1000] Eval loss: 1.3446\n",
      "[Epoch 416/1000] Train loss: 1.3444\n",
      "[Epoch 416/1000] Eval loss: 1.4718\n",
      "[Epoch 417/1000] Train loss: 1.3586\n",
      "[Epoch 417/1000] Eval loss: 1.4834\n",
      "[Epoch 418/1000] Train loss: 1.3687\n",
      "[Epoch 418/1000] Eval loss: 1.3027\n",
      "[Epoch 419/1000] Train loss: 1.3535\n",
      "[Epoch 419/1000] Eval loss: 1.3958\n",
      "[Epoch 420/1000] Train loss: 1.3656\n",
      "[Epoch 420/1000] Eval loss: 1.4156\n",
      "[Epoch 421/1000] Train loss: 1.3631\n",
      "[Epoch 421/1000] Eval loss: 1.3925\n",
      "[Epoch 422/1000] Train loss: 1.3450\n",
      "[Epoch 422/1000] Eval loss: 1.3910\n",
      "[Epoch 423/1000] Train loss: 1.3503\n",
      "[Epoch 423/1000] Eval loss: 1.4294\n",
      "[Epoch 424/1000] Train loss: 1.3647\n",
      "[Epoch 424/1000] Eval loss: 1.3685\n",
      "[Epoch 425/1000] Train loss: 1.3730\n",
      "[Epoch 425/1000] Eval loss: 1.4895\n",
      "[Epoch 426/1000] Train loss: 1.3449\n",
      "[Epoch 426/1000] Eval loss: 1.4471\n",
      "[Epoch 427/1000] Train loss: 1.3269\n",
      "[Epoch 427/1000] Eval loss: 1.3804\n",
      "[Epoch 428/1000] Train loss: 1.3187\n",
      "[Epoch 428/1000] Eval loss: 1.3294\n",
      "[Epoch 429/1000] Train loss: 1.3590\n",
      "[Epoch 429/1000] Eval loss: 1.4491\n",
      "[Epoch 430/1000] Train loss: 1.3457\n",
      "[Epoch 430/1000] Eval loss: 1.5367\n",
      "[Epoch 431/1000] Train loss: 1.3263\n",
      "[Epoch 431/1000] Eval loss: 1.3703\n",
      "[Epoch 432/1000] Train loss: 1.3522\n",
      "[Epoch 432/1000] Eval loss: 1.4180\n",
      "[Epoch 433/1000] Train loss: 1.3427\n",
      "[Epoch 433/1000] Eval loss: 1.4634\n",
      "[Epoch 434/1000] Train loss: 1.3745\n",
      "[Epoch 434/1000] Eval loss: 1.4121\n",
      "[Epoch 435/1000] Train loss: 1.3314\n",
      "[Epoch 435/1000] Eval loss: 1.3847\n",
      "[Epoch 436/1000] Train loss: 1.3396\n",
      "[Epoch 436/1000] Eval loss: 1.4735\n",
      "[Epoch 437/1000] Train loss: 1.3343\n",
      "[Epoch 437/1000] Eval loss: 1.3599\n",
      "[Epoch 438/1000] Train loss: 1.3426\n",
      "[Epoch 438/1000] Eval loss: 1.3898\n",
      "[Epoch 439/1000] Train loss: 1.3330\n",
      "[Epoch 439/1000] Eval loss: 1.4469\n",
      "[Epoch 440/1000] Train loss: 1.3471\n",
      "[Epoch 440/1000] Eval loss: 1.4639\n",
      "[Epoch 441/1000] Train loss: 1.3617\n",
      "[Epoch 441/1000] Eval loss: 1.3038\n",
      "[Epoch 442/1000] Train loss: 1.3331\n",
      "[Epoch 442/1000] Eval loss: 1.4247\n",
      "[Epoch 443/1000] Train loss: 1.3430\n",
      "[Epoch 443/1000] Eval loss: 1.3881\n",
      "[Epoch 444/1000] Train loss: 1.3524\n",
      "[Epoch 444/1000] Eval loss: 1.4147\n",
      "[Epoch 445/1000] Train loss: 1.3473\n",
      "[Epoch 445/1000] Eval loss: 1.4759\n",
      "[Epoch 446/1000] Train loss: 1.3505\n",
      "[Epoch 446/1000] Eval loss: 1.4342\n",
      "[Epoch 447/1000] Train loss: 1.3623\n",
      "[Epoch 447/1000] Eval loss: 1.4396\n",
      "[Epoch 448/1000] Train loss: 1.3508\n",
      "[Epoch 448/1000] Eval loss: 1.4023\n",
      "[Epoch 449/1000] Train loss: 1.3256\n",
      "[Epoch 449/1000] Eval loss: 1.4648\n",
      "[Epoch 450/1000] Train loss: 1.3142\n",
      "[Epoch 450/1000] Eval loss: 1.3435\n",
      "[Epoch 451/1000] Train loss: 1.3133\n",
      "[Epoch 451/1000] Eval loss: 1.2570\n",
      "[Epoch 452/1000] Train loss: 1.3262\n",
      "[Epoch 452/1000] Eval loss: 1.2800\n",
      "[Epoch 453/1000] Train loss: 1.3680\n",
      "[Epoch 453/1000] Eval loss: 1.3891\n",
      "[Epoch 454/1000] Train loss: 1.3555\n",
      "[Epoch 454/1000] Eval loss: 1.3660\n",
      "[Epoch 455/1000] Train loss: 1.3306\n",
      "[Epoch 455/1000] Eval loss: 1.4397\n",
      "[Epoch 456/1000] Train loss: 1.3207\n",
      "[Epoch 456/1000] Eval loss: 1.4469\n",
      "[Epoch 457/1000] Train loss: 1.3181\n",
      "[Epoch 457/1000] Eval loss: 1.4300\n",
      "[Epoch 458/1000] Train loss: 1.3263\n",
      "[Epoch 458/1000] Eval loss: 1.4282\n",
      "[Epoch 459/1000] Train loss: 1.3447\n",
      "[Epoch 459/1000] Eval loss: 1.5861\n",
      "[Epoch 460/1000] Train loss: 1.3327\n",
      "[Epoch 460/1000] Eval loss: 1.4437\n",
      "[Epoch 461/1000] Train loss: 1.3066\n",
      "[Epoch 461/1000] Eval loss: 1.4593\n",
      "[Epoch 462/1000] Train loss: 1.3226\n",
      "[Epoch 462/1000] Eval loss: 1.3613\n",
      "[Epoch 463/1000] Train loss: 1.3357\n",
      "[Epoch 463/1000] Eval loss: 1.3662\n",
      "[Epoch 464/1000] Train loss: 1.3443\n",
      "[Epoch 464/1000] Eval loss: 1.3452\n",
      "[Epoch 465/1000] Train loss: 1.3516\n",
      "[Epoch 465/1000] Eval loss: 1.4542\n",
      "[Epoch 466/1000] Train loss: 1.3245\n",
      "[Epoch 466/1000] Eval loss: 1.2863\n",
      "[Epoch 467/1000] Train loss: 1.3142\n",
      "[Epoch 467/1000] Eval loss: 1.3589\n",
      "[Epoch 468/1000] Train loss: 1.3618\n",
      "[Epoch 468/1000] Eval loss: 1.5070\n",
      "[Epoch 469/1000] Train loss: 1.3356\n",
      "[Epoch 469/1000] Eval loss: 1.4208\n",
      "[Epoch 470/1000] Train loss: 1.3460\n",
      "[Epoch 470/1000] Eval loss: 1.3552\n",
      "[Epoch 471/1000] Train loss: 1.3131\n",
      "[Epoch 471/1000] Eval loss: 1.3710\n",
      "[Epoch 472/1000] Train loss: 1.3267\n",
      "[Epoch 472/1000] Eval loss: 1.3292\n",
      "[Epoch 473/1000] Train loss: 1.3284\n",
      "[Epoch 473/1000] Eval loss: 1.3411\n",
      "[Epoch 474/1000] Train loss: 1.2949\n",
      "[Epoch 474/1000] Eval loss: 1.3655\n",
      "[Epoch 475/1000] Train loss: 1.3097\n",
      "[Epoch 475/1000] Eval loss: 1.5127\n",
      "[Epoch 476/1000] Train loss: 1.3249\n",
      "[Epoch 476/1000] Eval loss: 1.3448\n",
      "[Epoch 477/1000] Train loss: 1.3165\n",
      "[Epoch 477/1000] Eval loss: 1.3564\n",
      "[Epoch 478/1000] Train loss: 1.3354\n",
      "[Epoch 478/1000] Eval loss: 1.3648\n",
      "[Epoch 479/1000] Train loss: 1.3378\n",
      "[Epoch 479/1000] Eval loss: 1.4374\n",
      "[Epoch 480/1000] Train loss: 1.3233\n",
      "[Epoch 480/1000] Eval loss: 1.3858\n",
      "[Epoch 481/1000] Train loss: 1.3128\n",
      "[Epoch 481/1000] Eval loss: 1.3498\n",
      "[Epoch 482/1000] Train loss: 1.2987\n",
      "[Epoch 482/1000] Eval loss: 1.4417\n",
      "[Epoch 483/1000] Train loss: 1.3139\n",
      "[Epoch 483/1000] Eval loss: 1.4989\n",
      "[Epoch 484/1000] Train loss: 1.3077\n",
      "[Epoch 484/1000] Eval loss: 1.3830\n",
      "[Epoch 485/1000] Train loss: 1.3246\n",
      "[Epoch 485/1000] Eval loss: 1.4816\n",
      "[Epoch 486/1000] Train loss: 1.3155\n",
      "[Epoch 486/1000] Eval loss: 1.4175\n",
      "[Epoch 487/1000] Train loss: 1.3058\n",
      "[Epoch 487/1000] Eval loss: 1.2954\n",
      "[Epoch 488/1000] Train loss: 1.3118\n",
      "[Epoch 488/1000] Eval loss: 1.3515\n",
      "[Epoch 489/1000] Train loss: 1.3009\n",
      "[Epoch 489/1000] Eval loss: 1.3340\n",
      "[Epoch 490/1000] Train loss: 1.3376\n",
      "[Epoch 490/1000] Eval loss: 1.2658\n",
      "[Epoch 491/1000] Train loss: 1.2942\n",
      "[Epoch 491/1000] Eval loss: 1.4226\n",
      "[Epoch 492/1000] Train loss: 1.2964\n",
      "[Epoch 492/1000] Eval loss: 1.3549\n",
      "[Epoch 493/1000] Train loss: 1.3453\n",
      "[Epoch 493/1000] Eval loss: 1.3064\n",
      "[Epoch 494/1000] Train loss: 1.3438\n",
      "[Epoch 494/1000] Eval loss: 1.3335\n",
      "[Epoch 495/1000] Train loss: 1.3099\n",
      "[Epoch 495/1000] Eval loss: 1.3014\n",
      "[Epoch 496/1000] Train loss: 1.3344\n",
      "[Epoch 496/1000] Eval loss: 1.3622\n",
      "[Epoch 497/1000] Train loss: 1.3013\n",
      "[Epoch 497/1000] Eval loss: 1.3479\n",
      "[Epoch 498/1000] Train loss: 1.3311\n",
      "[Epoch 498/1000] Eval loss: 1.3588\n",
      "[Epoch 499/1000] Train loss: 1.3183\n",
      "[Epoch 499/1000] Eval loss: 1.2914\n",
      "[Epoch 500/1000] Train loss: 1.2834\n",
      "[Epoch 500/1000] Eval loss: 1.4112\n",
      "[Epoch 501/1000] Train loss: 1.3123\n",
      "[Epoch 501/1000] Eval loss: 1.2941\n",
      "[Epoch 502/1000] Train loss: 1.3131\n",
      "[Epoch 502/1000] Eval loss: 1.2823\n",
      "[Epoch 503/1000] Train loss: 1.2853\n",
      "[Epoch 503/1000] Eval loss: 1.2754\n",
      "[Epoch 504/1000] Train loss: 1.3319\n",
      "[Epoch 504/1000] Eval loss: 1.4646\n",
      "[Epoch 505/1000] Train loss: 1.2939\n",
      "[Epoch 505/1000] Eval loss: 1.3959\n",
      "[Epoch 506/1000] Train loss: 1.2982\n",
      "[Epoch 506/1000] Eval loss: 1.4577\n",
      "[Epoch 507/1000] Train loss: 1.3244\n",
      "[Epoch 507/1000] Eval loss: 1.3090\n",
      "[Epoch 508/1000] Train loss: 1.3014\n",
      "[Epoch 508/1000] Eval loss: 1.3797\n",
      "[Epoch 509/1000] Train loss: 1.3096\n",
      "[Epoch 509/1000] Eval loss: 1.3727\n",
      "[Epoch 510/1000] Train loss: 1.3225\n",
      "[Epoch 510/1000] Eval loss: 1.2970\n",
      "[Epoch 511/1000] Train loss: 1.2827\n",
      "[Epoch 511/1000] Eval loss: 1.3192\n",
      "[Epoch 512/1000] Train loss: 1.3134\n",
      "[Epoch 512/1000] Eval loss: 1.3714\n",
      "[Epoch 513/1000] Train loss: 1.3072\n",
      "[Epoch 513/1000] Eval loss: 1.3093\n",
      "[Epoch 514/1000] Train loss: 1.2789\n",
      "[Epoch 514/1000] Eval loss: 1.3454\n",
      "[Epoch 515/1000] Train loss: 1.2996\n",
      "[Epoch 515/1000] Eval loss: 1.3177\n",
      "[Epoch 516/1000] Train loss: 1.2822\n",
      "[Epoch 516/1000] Eval loss: 1.4077\n",
      "[Epoch 517/1000] Train loss: 1.2934\n",
      "[Epoch 517/1000] Eval loss: 1.3323\n",
      "[Epoch 518/1000] Train loss: 1.2901\n",
      "[Epoch 518/1000] Eval loss: 1.2674\n",
      "[Epoch 519/1000] Train loss: 1.2910\n",
      "[Epoch 519/1000] Eval loss: 1.3956\n",
      "[Epoch 520/1000] Train loss: 1.3090\n",
      "[Epoch 520/1000] Eval loss: 1.3314\n",
      "[Epoch 521/1000] Train loss: 1.3098\n",
      "[Epoch 521/1000] Eval loss: 1.3339\n",
      "[Epoch 522/1000] Train loss: 1.2968\n",
      "[Epoch 522/1000] Eval loss: 1.3957\n",
      "[Epoch 523/1000] Train loss: 1.3046\n",
      "[Epoch 523/1000] Eval loss: 1.3152\n",
      "[Epoch 524/1000] Train loss: 1.3210\n",
      "[Epoch 524/1000] Eval loss: 1.3047\n",
      "[Epoch 525/1000] Train loss: 1.2990\n",
      "[Epoch 525/1000] Eval loss: 1.3172\n",
      "[Epoch 526/1000] Train loss: 1.2902\n",
      "[Epoch 526/1000] Eval loss: 1.3254\n",
      "[Epoch 527/1000] Train loss: 1.2882\n",
      "[Epoch 527/1000] Eval loss: 1.2920\n",
      "[Epoch 528/1000] Train loss: 1.3151\n",
      "[Epoch 528/1000] Eval loss: 1.2983\n",
      "[Epoch 529/1000] Train loss: 1.2994\n",
      "[Epoch 529/1000] Eval loss: 1.3468\n",
      "[Epoch 530/1000] Train loss: 1.2988\n",
      "[Epoch 530/1000] Eval loss: 1.2857\n",
      "[Epoch 531/1000] Train loss: 1.3069\n",
      "[Epoch 531/1000] Eval loss: 1.2772\n",
      "[Epoch 532/1000] Train loss: 1.3031\n",
      "[Epoch 532/1000] Eval loss: 1.3181\n",
      "[Epoch 533/1000] Train loss: 1.2975\n",
      "[Epoch 533/1000] Eval loss: 1.3580\n",
      "[Epoch 534/1000] Train loss: 1.3039\n",
      "[Epoch 534/1000] Eval loss: 1.3275\n",
      "[Epoch 535/1000] Train loss: 1.2798\n",
      "[Epoch 535/1000] Eval loss: 1.3303\n",
      "[Epoch 536/1000] Train loss: 1.3187\n",
      "[Epoch 536/1000] Eval loss: 1.3784\n",
      "[Epoch 537/1000] Train loss: 1.2925\n",
      "[Epoch 537/1000] Eval loss: 1.3172\n",
      "[Epoch 538/1000] Train loss: 1.3135\n",
      "[Epoch 538/1000] Eval loss: 1.3540\n",
      "[Epoch 539/1000] Train loss: 1.2951\n",
      "[Epoch 539/1000] Eval loss: 1.3069\n",
      "[Epoch 540/1000] Train loss: 1.2695\n",
      "[Epoch 540/1000] Eval loss: 1.3070\n",
      "[Epoch 541/1000] Train loss: 1.2884\n",
      "[Epoch 541/1000] Eval loss: 1.4193\n",
      "[Epoch 542/1000] Train loss: 1.2736\n",
      "[Epoch 542/1000] Eval loss: 1.4053\n",
      "[Epoch 543/1000] Train loss: 1.2796\n",
      "[Epoch 543/1000] Eval loss: 1.2939\n",
      "[Epoch 544/1000] Train loss: 1.2863\n",
      "[Epoch 544/1000] Eval loss: 1.3110\n",
      "[Epoch 545/1000] Train loss: 1.3135\n",
      "[Epoch 545/1000] Eval loss: 1.3541\n",
      "[Epoch 546/1000] Train loss: 1.2823\n",
      "[Epoch 546/1000] Eval loss: 1.3273\n",
      "[Epoch 547/1000] Train loss: 1.2666\n",
      "[Epoch 547/1000] Eval loss: 1.3521\n",
      "[Epoch 548/1000] Train loss: 1.2862\n",
      "[Epoch 548/1000] Eval loss: 1.2938\n",
      "[Epoch 549/1000] Train loss: 1.2892\n",
      "[Epoch 549/1000] Eval loss: 1.2782\n",
      "[Epoch 550/1000] Train loss: 1.2894\n",
      "[Epoch 550/1000] Eval loss: 1.2911\n",
      "[Epoch 551/1000] Train loss: 1.2833\n",
      "[Epoch 551/1000] Eval loss: 1.2875\n",
      "[Epoch 552/1000] Train loss: 1.2512\n",
      "[Epoch 552/1000] Eval loss: 1.3063\n",
      "[Epoch 553/1000] Train loss: 1.2762\n",
      "[Epoch 553/1000] Eval loss: 1.3685\n",
      "[Epoch 554/1000] Train loss: 1.3019\n",
      "[Epoch 554/1000] Eval loss: 1.3714\n",
      "[Epoch 555/1000] Train loss: 1.2872\n",
      "[Epoch 555/1000] Eval loss: 1.4015\n",
      "[Epoch 556/1000] Train loss: 1.3248\n",
      "[Epoch 556/1000] Eval loss: 1.3454\n",
      "[Epoch 557/1000] Train loss: 1.2924\n",
      "[Epoch 557/1000] Eval loss: 1.3082\n",
      "[Epoch 558/1000] Train loss: 1.2904\n",
      "[Epoch 558/1000] Eval loss: 1.3518\n",
      "[Epoch 559/1000] Train loss: 1.2811\n",
      "[Epoch 559/1000] Eval loss: 1.2966\n",
      "[Epoch 560/1000] Train loss: 1.2956\n",
      "[Epoch 560/1000] Eval loss: 1.3138\n",
      "[Epoch 561/1000] Train loss: 1.2962\n",
      "[Epoch 561/1000] Eval loss: 1.2844\n",
      "[Epoch 562/1000] Train loss: 1.2689\n",
      "[Epoch 562/1000] Eval loss: 1.2925\n",
      "[Epoch 563/1000] Train loss: 1.2715\n",
      "[Epoch 563/1000] Eval loss: 1.3469\n",
      "[Epoch 564/1000] Train loss: 1.2899\n",
      "[Epoch 564/1000] Eval loss: 1.3401\n",
      "[Epoch 565/1000] Train loss: 1.2651\n",
      "[Epoch 565/1000] Eval loss: 1.3293\n",
      "[Epoch 566/1000] Train loss: 1.2898\n",
      "[Epoch 566/1000] Eval loss: 1.3415\n",
      "[Epoch 567/1000] Train loss: 1.2868\n",
      "[Epoch 567/1000] Eval loss: 1.4344\n",
      "[Epoch 568/1000] Train loss: 1.2864\n",
      "[Epoch 568/1000] Eval loss: 1.3939\n",
      "[Epoch 569/1000] Train loss: 1.3112\n",
      "[Epoch 569/1000] Eval loss: 1.4070\n",
      "[Epoch 570/1000] Train loss: 1.2682\n",
      "[Epoch 570/1000] Eval loss: 1.3270\n",
      "[Epoch 571/1000] Train loss: 1.2900\n",
      "[Epoch 571/1000] Eval loss: 1.3146\n",
      "[Epoch 572/1000] Train loss: 1.2983\n",
      "[Epoch 572/1000] Eval loss: 1.3140\n",
      "[Epoch 573/1000] Train loss: 1.2722\n",
      "[Epoch 573/1000] Eval loss: 1.3942\n",
      "[Epoch 574/1000] Train loss: 1.2813\n",
      "[Epoch 574/1000] Eval loss: 1.2857\n",
      "[Epoch 575/1000] Train loss: 1.2625\n",
      "[Epoch 575/1000] Eval loss: 1.4401\n",
      "[Epoch 576/1000] Train loss: 1.2973\n",
      "[Epoch 576/1000] Eval loss: 1.2663\n",
      "[Epoch 577/1000] Train loss: 1.2836\n",
      "[Epoch 577/1000] Eval loss: 1.2385\n",
      "[Epoch 578/1000] Train loss: 1.2772\n",
      "[Epoch 578/1000] Eval loss: 1.3505\n",
      "[Epoch 579/1000] Train loss: 1.2868\n",
      "[Epoch 579/1000] Eval loss: 1.3163\n",
      "[Epoch 580/1000] Train loss: 1.2738\n",
      "[Epoch 580/1000] Eval loss: 1.3378\n",
      "[Epoch 581/1000] Train loss: 1.2551\n",
      "[Epoch 581/1000] Eval loss: 1.3291\n",
      "[Epoch 582/1000] Train loss: 1.2586\n",
      "[Epoch 582/1000] Eval loss: 1.3336\n",
      "[Epoch 583/1000] Train loss: 1.2651\n",
      "[Epoch 583/1000] Eval loss: 1.3590\n",
      "[Epoch 584/1000] Train loss: 1.2834\n",
      "[Epoch 584/1000] Eval loss: 1.3621\n",
      "[Epoch 585/1000] Train loss: 1.3031\n",
      "[Epoch 585/1000] Eval loss: 1.3018\n",
      "[Epoch 586/1000] Train loss: 1.2567\n",
      "[Epoch 586/1000] Eval loss: 1.3037\n",
      "[Epoch 587/1000] Train loss: 1.2744\n",
      "[Epoch 587/1000] Eval loss: 1.4424\n",
      "[Epoch 588/1000] Train loss: 1.2852\n",
      "[Epoch 588/1000] Eval loss: 1.3115\n",
      "[Epoch 589/1000] Train loss: 1.2952\n",
      "[Epoch 589/1000] Eval loss: 1.3125\n",
      "[Epoch 590/1000] Train loss: 1.2752\n",
      "[Epoch 590/1000] Eval loss: 1.2737\n",
      "[Epoch 591/1000] Train loss: 1.2697\n",
      "[Epoch 591/1000] Eval loss: 1.3375\n",
      "[Epoch 592/1000] Train loss: 1.2989\n",
      "[Epoch 592/1000] Eval loss: 1.3100\n",
      "[Epoch 593/1000] Train loss: 1.2931\n",
      "[Epoch 593/1000] Eval loss: 1.3132\n",
      "[Epoch 594/1000] Train loss: 1.2429\n",
      "[Epoch 594/1000] Eval loss: 1.2857\n",
      "[Epoch 595/1000] Train loss: 1.2843\n",
      "[Epoch 595/1000] Eval loss: 1.4481\n",
      "[Epoch 596/1000] Train loss: 1.2734\n",
      "[Epoch 596/1000] Eval loss: 1.3362\n",
      "[Epoch 597/1000] Train loss: 1.2802\n",
      "[Epoch 597/1000] Eval loss: 1.3944\n",
      "[Epoch 598/1000] Train loss: 1.2970\n",
      "[Epoch 598/1000] Eval loss: 1.3519\n",
      "[Epoch 599/1000] Train loss: 1.2740\n",
      "[Epoch 599/1000] Eval loss: 1.4607\n",
      "[Epoch 600/1000] Train loss: 1.2659\n",
      "[Epoch 600/1000] Eval loss: 1.2926\n",
      "[Epoch 601/1000] Train loss: 1.2630\n",
      "[Epoch 601/1000] Eval loss: 1.2332\n",
      "[Epoch 602/1000] Train loss: 1.2600\n",
      "[Epoch 602/1000] Eval loss: 1.3771\n",
      "[Epoch 603/1000] Train loss: 1.2946\n",
      "[Epoch 603/1000] Eval loss: 1.4880\n",
      "[Epoch 604/1000] Train loss: 1.2836\n",
      "[Epoch 604/1000] Eval loss: 1.2768\n",
      "[Epoch 605/1000] Train loss: 1.2697\n",
      "[Epoch 605/1000] Eval loss: 1.2454\n",
      "[Epoch 606/1000] Train loss: 1.2571\n",
      "[Epoch 606/1000] Eval loss: 1.2862\n",
      "[Epoch 607/1000] Train loss: 1.2632\n",
      "[Epoch 607/1000] Eval loss: 1.3342\n",
      "[Epoch 608/1000] Train loss: 1.2616\n",
      "[Epoch 608/1000] Eval loss: 1.2463\n",
      "[Epoch 609/1000] Train loss: 1.2565\n",
      "[Epoch 609/1000] Eval loss: 1.2339\n",
      "[Epoch 610/1000] Train loss: 1.2593\n",
      "[Epoch 610/1000] Eval loss: 1.3351\n",
      "[Epoch 611/1000] Train loss: 1.2778\n",
      "[Epoch 611/1000] Eval loss: 1.3427\n",
      "[Epoch 612/1000] Train loss: 1.2731\n",
      "[Epoch 612/1000] Eval loss: 1.2277\n",
      "[Epoch 613/1000] Train loss: 1.2614\n",
      "[Epoch 613/1000] Eval loss: 1.4967\n",
      "[Epoch 614/1000] Train loss: 1.2656\n",
      "[Epoch 614/1000] Eval loss: 1.4099\n",
      "[Epoch 615/1000] Train loss: 1.2604\n",
      "[Epoch 615/1000] Eval loss: 1.3287\n",
      "[Epoch 616/1000] Train loss: 1.2578\n",
      "[Epoch 616/1000] Eval loss: 1.2311\n",
      "[Epoch 617/1000] Train loss: 1.2536\n",
      "[Epoch 617/1000] Eval loss: 1.2434\n",
      "[Epoch 618/1000] Train loss: 1.2491\n",
      "[Epoch 618/1000] Eval loss: 1.3039\n",
      "[Epoch 619/1000] Train loss: 1.2569\n",
      "[Epoch 619/1000] Eval loss: 1.3341\n",
      "[Epoch 620/1000] Train loss: 1.2611\n",
      "[Epoch 620/1000] Eval loss: 1.3128\n",
      "[Epoch 621/1000] Train loss: 1.2682\n",
      "[Epoch 621/1000] Eval loss: 1.3254\n",
      "[Epoch 622/1000] Train loss: 1.2716\n",
      "[Epoch 622/1000] Eval loss: 1.3216\n",
      "[Epoch 623/1000] Train loss: 1.2818\n",
      "[Epoch 623/1000] Eval loss: 1.2611\n",
      "[Epoch 624/1000] Train loss: 1.2460\n",
      "[Epoch 624/1000] Eval loss: 1.4054\n",
      "[Epoch 625/1000] Train loss: 1.2495\n",
      "[Epoch 625/1000] Eval loss: 1.3269\n",
      "[Epoch 626/1000] Train loss: 1.2617\n",
      "[Epoch 626/1000] Eval loss: 1.4177\n",
      "[Epoch 627/1000] Train loss: 1.2821\n",
      "[Epoch 627/1000] Eval loss: 1.2987\n",
      "[Epoch 628/1000] Train loss: 1.2757\n",
      "[Epoch 628/1000] Eval loss: 1.3269\n",
      "[Epoch 629/1000] Train loss: 1.2649\n",
      "[Epoch 629/1000] Eval loss: 1.3562\n",
      "[Epoch 630/1000] Train loss: 1.2562\n",
      "[Epoch 630/1000] Eval loss: 1.3070\n",
      "[Epoch 631/1000] Train loss: 1.2658\n",
      "[Epoch 631/1000] Eval loss: 1.3993\n",
      "[Epoch 632/1000] Train loss: 1.2455\n",
      "[Epoch 632/1000] Eval loss: 1.3040\n",
      "[Epoch 633/1000] Train loss: 1.2904\n",
      "[Epoch 633/1000] Eval loss: 1.3283\n",
      "[Epoch 634/1000] Train loss: 1.2447\n",
      "[Epoch 634/1000] Eval loss: 1.2833\n",
      "[Epoch 635/1000] Train loss: 1.2470\n",
      "[Epoch 635/1000] Eval loss: 1.3428\n",
      "[Epoch 636/1000] Train loss: 1.2725\n",
      "[Epoch 636/1000] Eval loss: 1.3851\n",
      "[Epoch 637/1000] Train loss: 1.2704\n",
      "[Epoch 637/1000] Eval loss: 1.3748\n",
      "[Epoch 638/1000] Train loss: 1.2579\n",
      "[Epoch 638/1000] Eval loss: 1.2369\n",
      "[Epoch 639/1000] Train loss: 1.2576\n",
      "[Epoch 639/1000] Eval loss: 1.2303\n",
      "[Epoch 640/1000] Train loss: 1.2395\n",
      "[Epoch 640/1000] Eval loss: 1.2788\n",
      "[Epoch 641/1000] Train loss: 1.2569\n",
      "[Epoch 641/1000] Eval loss: 1.3526\n",
      "[Epoch 642/1000] Train loss: 1.2681\n",
      "[Epoch 642/1000] Eval loss: 1.2859\n",
      "[Epoch 643/1000] Train loss: 1.2751\n",
      "[Epoch 643/1000] Eval loss: 1.2567\n",
      "[Epoch 644/1000] Train loss: 1.2498\n",
      "[Epoch 644/1000] Eval loss: 1.2603\n",
      "[Epoch 645/1000] Train loss: 1.2621\n",
      "[Epoch 645/1000] Eval loss: 1.2913\n",
      "[Epoch 646/1000] Train loss: 1.2610\n",
      "[Epoch 646/1000] Eval loss: 1.3036\n",
      "[Epoch 647/1000] Train loss: 1.2511\n",
      "[Epoch 647/1000] Eval loss: 1.2592\n",
      "[Epoch 648/1000] Train loss: 1.2585\n",
      "[Epoch 648/1000] Eval loss: 1.3610\n",
      "[Epoch 649/1000] Train loss: 1.2520\n",
      "[Epoch 649/1000] Eval loss: 1.1684\n",
      "[Epoch 650/1000] Train loss: 1.2373\n",
      "[Epoch 650/1000] Eval loss: 1.3897\n",
      "[Epoch 651/1000] Train loss: 1.2676\n",
      "[Epoch 651/1000] Eval loss: 1.2223\n",
      "[Epoch 652/1000] Train loss: 1.2589\n",
      "[Epoch 652/1000] Eval loss: 1.4075\n",
      "[Epoch 653/1000] Train loss: 1.2854\n",
      "[Epoch 653/1000] Eval loss: 1.3070\n",
      "[Epoch 654/1000] Train loss: 1.2619\n",
      "[Epoch 654/1000] Eval loss: 1.2712\n",
      "[Epoch 655/1000] Train loss: 1.2693\n",
      "[Epoch 655/1000] Eval loss: 1.2878\n",
      "[Epoch 656/1000] Train loss: 1.2630\n",
      "[Epoch 656/1000] Eval loss: 1.3305\n",
      "[Epoch 657/1000] Train loss: 1.2529\n",
      "[Epoch 657/1000] Eval loss: 1.3712\n",
      "[Epoch 658/1000] Train loss: 1.2695\n",
      "[Epoch 658/1000] Eval loss: 1.3226\n",
      "[Epoch 659/1000] Train loss: 1.2667\n",
      "[Epoch 659/1000] Eval loss: 1.2585\n",
      "[Epoch 660/1000] Train loss: 1.2521\n",
      "[Epoch 660/1000] Eval loss: 1.3628\n",
      "[Epoch 661/1000] Train loss: 1.2472\n",
      "[Epoch 661/1000] Eval loss: 1.3495\n",
      "[Epoch 662/1000] Train loss: 1.2697\n",
      "[Epoch 662/1000] Eval loss: 1.2953\n",
      "[Epoch 663/1000] Train loss: 1.2351\n",
      "[Epoch 663/1000] Eval loss: 1.2913\n",
      "[Epoch 664/1000] Train loss: 1.2540\n",
      "[Epoch 664/1000] Eval loss: 1.3822\n",
      "[Epoch 665/1000] Train loss: 1.2475\n",
      "[Epoch 665/1000] Eval loss: 1.3087\n",
      "[Epoch 666/1000] Train loss: 1.2596\n",
      "[Epoch 666/1000] Eval loss: 1.3094\n",
      "[Epoch 667/1000] Train loss: 1.2466\n",
      "[Epoch 667/1000] Eval loss: 1.3406\n",
      "[Epoch 668/1000] Train loss: 1.2334\n",
      "[Epoch 668/1000] Eval loss: 1.2814\n",
      "[Epoch 669/1000] Train loss: 1.2546\n",
      "[Epoch 669/1000] Eval loss: 1.2735\n",
      "[Epoch 670/1000] Train loss: 1.2572\n",
      "[Epoch 670/1000] Eval loss: 1.3008\n",
      "[Epoch 671/1000] Train loss: 1.2382\n",
      "[Epoch 671/1000] Eval loss: 1.3252\n",
      "[Epoch 672/1000] Train loss: 1.2615\n",
      "[Epoch 672/1000] Eval loss: 1.3533\n",
      "[Epoch 673/1000] Train loss: 1.2405\n",
      "[Epoch 673/1000] Eval loss: 1.2258\n",
      "[Epoch 674/1000] Train loss: 1.2557\n",
      "[Epoch 674/1000] Eval loss: 1.4713\n",
      "[Epoch 675/1000] Train loss: 1.2604\n",
      "[Epoch 675/1000] Eval loss: 1.3270\n",
      "[Epoch 676/1000] Train loss: 1.2244\n",
      "[Epoch 676/1000] Eval loss: 1.3576\n",
      "[Epoch 677/1000] Train loss: 1.2822\n",
      "[Epoch 677/1000] Eval loss: 1.2590\n",
      "[Epoch 678/1000] Train loss: 1.2259\n",
      "[Epoch 678/1000] Eval loss: 1.3102\n",
      "[Epoch 679/1000] Train loss: 1.2452\n",
      "[Epoch 679/1000] Eval loss: 1.3298\n",
      "[Epoch 680/1000] Train loss: 1.2429\n",
      "[Epoch 680/1000] Eval loss: 1.2797\n",
      "[Epoch 681/1000] Train loss: 1.2232\n",
      "[Epoch 681/1000] Eval loss: 1.2209\n",
      "[Epoch 682/1000] Train loss: 1.2470\n",
      "[Epoch 682/1000] Eval loss: 1.3038\n",
      "[Epoch 683/1000] Train loss: 1.2436\n",
      "[Epoch 683/1000] Eval loss: 1.2070\n",
      "[Epoch 684/1000] Train loss: 1.2346\n",
      "[Epoch 684/1000] Eval loss: 1.3753\n",
      "[Epoch 685/1000] Train loss: 1.2509\n",
      "[Epoch 685/1000] Eval loss: 1.2440\n",
      "[Epoch 686/1000] Train loss: 1.2567\n",
      "[Epoch 686/1000] Eval loss: 1.2350\n",
      "[Epoch 687/1000] Train loss: 1.2339\n",
      "[Epoch 687/1000] Eval loss: 1.2261\n",
      "[Epoch 688/1000] Train loss: 1.2372\n",
      "[Epoch 688/1000] Eval loss: 1.2222\n",
      "[Epoch 689/1000] Train loss: 1.2508\n",
      "[Epoch 689/1000] Eval loss: 1.3612\n",
      "[Epoch 690/1000] Train loss: 1.2259\n",
      "[Epoch 690/1000] Eval loss: 1.2744\n",
      "[Epoch 691/1000] Train loss: 1.2322\n",
      "[Epoch 691/1000] Eval loss: 1.2738\n",
      "[Epoch 692/1000] Train loss: 1.2349\n",
      "[Epoch 692/1000] Eval loss: 1.3299\n",
      "[Epoch 693/1000] Train loss: 1.2396\n",
      "[Epoch 693/1000] Eval loss: 1.2578\n",
      "[Epoch 694/1000] Train loss: 1.2370\n",
      "[Epoch 694/1000] Eval loss: 1.3057\n",
      "[Epoch 695/1000] Train loss: 1.2273\n",
      "[Epoch 695/1000] Eval loss: 1.2299\n",
      "[Epoch 696/1000] Train loss: 1.2452\n",
      "[Epoch 696/1000] Eval loss: 1.2682\n",
      "[Epoch 697/1000] Train loss: 1.2514\n",
      "[Epoch 697/1000] Eval loss: 1.2593\n",
      "[Epoch 698/1000] Train loss: 1.2551\n",
      "[Epoch 698/1000] Eval loss: 1.2548\n",
      "[Epoch 699/1000] Train loss: 1.2452\n",
      "[Epoch 699/1000] Eval loss: 1.2692\n",
      "[Epoch 700/1000] Train loss: 1.2703\n",
      "[Epoch 700/1000] Eval loss: 1.2404\n",
      "[Epoch 701/1000] Train loss: 1.2292\n",
      "[Epoch 701/1000] Eval loss: 1.2886\n",
      "[Epoch 702/1000] Train loss: 1.2342\n",
      "[Epoch 702/1000] Eval loss: 1.3091\n",
      "[Epoch 703/1000] Train loss: 1.2264\n",
      "[Epoch 703/1000] Eval loss: 1.3058\n",
      "[Epoch 704/1000] Train loss: 1.2291\n",
      "[Epoch 704/1000] Eval loss: 1.2877\n",
      "[Epoch 705/1000] Train loss: 1.2497\n",
      "[Epoch 705/1000] Eval loss: 1.4706\n",
      "[Epoch 706/1000] Train loss: 1.2713\n",
      "[Epoch 706/1000] Eval loss: 1.2636\n",
      "[Epoch 707/1000] Train loss: 1.2550\n",
      "[Epoch 707/1000] Eval loss: 1.2375\n",
      "[Epoch 708/1000] Train loss: 1.2506\n",
      "[Epoch 708/1000] Eval loss: 1.2667\n",
      "[Epoch 709/1000] Train loss: 1.2338\n",
      "[Epoch 709/1000] Eval loss: 1.1952\n",
      "[Epoch 710/1000] Train loss: 1.2476\n",
      "[Epoch 710/1000] Eval loss: 1.2529\n",
      "[Epoch 711/1000] Train loss: 1.2160\n",
      "[Epoch 711/1000] Eval loss: 1.2136\n",
      "[Epoch 712/1000] Train loss: 1.2436\n",
      "[Epoch 712/1000] Eval loss: 1.3131\n",
      "[Epoch 713/1000] Train loss: 1.2234\n",
      "[Epoch 713/1000] Eval loss: 1.2975\n",
      "[Epoch 714/1000] Train loss: 1.2480\n",
      "[Epoch 714/1000] Eval loss: 1.2750\n",
      "[Epoch 715/1000] Train loss: 1.2294\n",
      "[Epoch 715/1000] Eval loss: 1.2122\n",
      "[Epoch 716/1000] Train loss: 1.2563\n",
      "[Epoch 716/1000] Eval loss: 1.2542\n",
      "[Epoch 717/1000] Train loss: 1.2231\n",
      "[Epoch 717/1000] Eval loss: 1.2274\n",
      "[Epoch 718/1000] Train loss: 1.2510\n",
      "[Epoch 718/1000] Eval loss: 1.1917\n",
      "[Epoch 719/1000] Train loss: 1.2103\n",
      "[Epoch 719/1000] Eval loss: 1.3043\n",
      "[Epoch 720/1000] Train loss: 1.2437\n",
      "[Epoch 720/1000] Eval loss: 1.2547\n",
      "[Epoch 721/1000] Train loss: 1.2166\n",
      "[Epoch 721/1000] Eval loss: 1.1929\n",
      "[Epoch 722/1000] Train loss: 1.2405\n",
      "[Epoch 722/1000] Eval loss: 1.3604\n",
      "[Epoch 723/1000] Train loss: 1.2362\n",
      "[Epoch 723/1000] Eval loss: 1.2584\n",
      "[Epoch 724/1000] Train loss: 1.2417\n",
      "[Epoch 724/1000] Eval loss: 1.2219\n",
      "[Epoch 725/1000] Train loss: 1.2507\n",
      "[Epoch 725/1000] Eval loss: 1.2456\n",
      "[Epoch 726/1000] Train loss: 1.2846\n",
      "[Epoch 726/1000] Eval loss: 1.2273\n",
      "[Epoch 727/1000] Train loss: 1.2283\n",
      "[Epoch 727/1000] Eval loss: 1.2672\n",
      "[Epoch 728/1000] Train loss: 1.2170\n",
      "[Epoch 728/1000] Eval loss: 1.4519\n",
      "[Epoch 729/1000] Train loss: 1.2321\n",
      "[Epoch 729/1000] Eval loss: 1.2725\n",
      "[Epoch 730/1000] Train loss: 1.2242\n",
      "[Epoch 730/1000] Eval loss: 1.3757\n",
      "[Epoch 731/1000] Train loss: 1.2299\n",
      "[Epoch 731/1000] Eval loss: 1.2312\n",
      "[Epoch 732/1000] Train loss: 1.2329\n",
      "[Epoch 732/1000] Eval loss: 1.3279\n",
      "[Epoch 733/1000] Train loss: 1.2466\n",
      "[Epoch 733/1000] Eval loss: 1.3181\n",
      "[Epoch 734/1000] Train loss: 1.2112\n",
      "[Epoch 734/1000] Eval loss: 1.1773\n",
      "[Epoch 735/1000] Train loss: 1.2670\n",
      "[Epoch 735/1000] Eval loss: 1.2574\n",
      "[Epoch 736/1000] Train loss: 1.2405\n",
      "[Epoch 736/1000] Eval loss: 1.3243\n",
      "[Epoch 737/1000] Train loss: 1.2183\n",
      "[Epoch 737/1000] Eval loss: 1.2835\n",
      "[Epoch 738/1000] Train loss: 1.2368\n",
      "[Epoch 738/1000] Eval loss: 1.3225\n",
      "[Epoch 739/1000] Train loss: 1.2375\n",
      "[Epoch 739/1000] Eval loss: 1.1908\n",
      "[Epoch 740/1000] Train loss: 1.2071\n",
      "[Epoch 740/1000] Eval loss: 1.1966\n",
      "[Epoch 741/1000] Train loss: 1.2445\n",
      "[Epoch 741/1000] Eval loss: 1.2911\n",
      "[Epoch 742/1000] Train loss: 1.2532\n",
      "[Epoch 742/1000] Eval loss: 1.1758\n",
      "[Epoch 743/1000] Train loss: 1.2283\n",
      "[Epoch 743/1000] Eval loss: 1.3141\n",
      "[Epoch 744/1000] Train loss: 1.2337\n",
      "[Epoch 744/1000] Eval loss: 1.3342\n",
      "[Epoch 745/1000] Train loss: 1.2225\n",
      "[Epoch 745/1000] Eval loss: 1.1906\n",
      "[Epoch 746/1000] Train loss: 1.2453\n",
      "[Epoch 746/1000] Eval loss: 1.2838\n",
      "[Epoch 747/1000] Train loss: 1.2105\n",
      "[Epoch 747/1000] Eval loss: 1.3362\n",
      "[Epoch 748/1000] Train loss: 1.2140\n",
      "[Epoch 748/1000] Eval loss: 1.1958\n",
      "[Epoch 749/1000] Train loss: 1.2178\n",
      "[Epoch 749/1000] Eval loss: 1.2709\n",
      "[Epoch 750/1000] Train loss: 1.2179\n",
      "[Epoch 750/1000] Eval loss: 1.2866\n",
      "[Epoch 751/1000] Train loss: 1.2163\n",
      "[Epoch 751/1000] Eval loss: 1.3069\n",
      "[Epoch 752/1000] Train loss: 1.1915\n",
      "[Epoch 752/1000] Eval loss: 1.2565\n",
      "[Epoch 753/1000] Train loss: 1.2261\n",
      "[Epoch 753/1000] Eval loss: 1.2835\n",
      "[Epoch 754/1000] Train loss: 1.2318\n",
      "[Epoch 754/1000] Eval loss: 1.2735\n",
      "[Epoch 755/1000] Train loss: 1.2055\n",
      "[Epoch 755/1000] Eval loss: 1.4489\n",
      "[Epoch 756/1000] Train loss: 1.2453\n",
      "[Epoch 756/1000] Eval loss: 1.2461\n",
      "[Epoch 757/1000] Train loss: 1.2423\n",
      "[Epoch 757/1000] Eval loss: 1.1685\n",
      "[Epoch 758/1000] Train loss: 1.2175\n",
      "[Epoch 758/1000] Eval loss: 1.1789\n",
      "[Epoch 759/1000] Train loss: 1.2224\n",
      "[Epoch 759/1000] Eval loss: 1.3069\n",
      "[Epoch 760/1000] Train loss: 1.2223\n",
      "[Epoch 760/1000] Eval loss: 1.3227\n",
      "[Epoch 761/1000] Train loss: 1.2329\n",
      "[Epoch 761/1000] Eval loss: 1.2332\n",
      "[Epoch 762/1000] Train loss: 1.2468\n",
      "[Epoch 762/1000] Eval loss: 1.3239\n",
      "[Epoch 763/1000] Train loss: 1.2537\n",
      "[Epoch 763/1000] Eval loss: 1.2413\n",
      "[Epoch 764/1000] Train loss: 1.2186\n",
      "[Epoch 764/1000] Eval loss: 1.2245\n",
      "[Epoch 765/1000] Train loss: 1.2036\n",
      "[Epoch 765/1000] Eval loss: 1.2212\n",
      "[Epoch 766/1000] Train loss: 1.2231\n",
      "[Epoch 766/1000] Eval loss: 1.3645\n",
      "[Epoch 767/1000] Train loss: 1.2146\n",
      "[Epoch 767/1000] Eval loss: 1.2717\n",
      "[Epoch 768/1000] Train loss: 1.2047\n",
      "[Epoch 768/1000] Eval loss: 1.2025\n",
      "[Epoch 769/1000] Train loss: 1.2136\n",
      "[Epoch 769/1000] Eval loss: 1.2761\n",
      "[Epoch 770/1000] Train loss: 1.2347\n",
      "[Epoch 770/1000] Eval loss: 1.2561\n",
      "[Epoch 771/1000] Train loss: 1.2066\n",
      "[Epoch 771/1000] Eval loss: 1.3099\n",
      "[Epoch 772/1000] Train loss: 1.2333\n",
      "[Epoch 772/1000] Eval loss: 1.2676\n",
      "[Epoch 773/1000] Train loss: 1.2163\n",
      "[Epoch 773/1000] Eval loss: 1.2082\n",
      "[Epoch 774/1000] Train loss: 1.2412\n",
      "[Epoch 774/1000] Eval loss: 1.2193\n",
      "[Epoch 775/1000] Train loss: 1.2238\n",
      "[Epoch 775/1000] Eval loss: 1.2747\n",
      "[Epoch 776/1000] Train loss: 1.2002\n",
      "[Epoch 776/1000] Eval loss: 1.2280\n",
      "[Epoch 777/1000] Train loss: 1.1887\n",
      "[Epoch 777/1000] Eval loss: 1.2246\n",
      "[Epoch 778/1000] Train loss: 1.2045\n",
      "[Epoch 778/1000] Eval loss: 1.2815\n",
      "[Epoch 779/1000] Train loss: 1.2544\n",
      "[Epoch 779/1000] Eval loss: 1.2491\n",
      "[Epoch 780/1000] Train loss: 1.2005\n",
      "[Epoch 780/1000] Eval loss: 1.2829\n",
      "[Epoch 781/1000] Train loss: 1.2080\n",
      "[Epoch 781/1000] Eval loss: 1.2242\n",
      "[Epoch 782/1000] Train loss: 1.2213\n",
      "[Epoch 782/1000] Eval loss: 1.1922\n",
      "[Epoch 783/1000] Train loss: 1.2305\n",
      "[Epoch 783/1000] Eval loss: 1.2586\n",
      "[Epoch 784/1000] Train loss: 1.2265\n",
      "[Epoch 784/1000] Eval loss: 1.2070\n",
      "[Epoch 785/1000] Train loss: 1.2192\n",
      "[Epoch 785/1000] Eval loss: 1.2765\n",
      "[Epoch 786/1000] Train loss: 1.2331\n",
      "[Epoch 786/1000] Eval loss: 1.2496\n",
      "[Epoch 787/1000] Train loss: 1.2079\n",
      "[Epoch 787/1000] Eval loss: 1.2127\n",
      "[Epoch 788/1000] Train loss: 1.2429\n",
      "[Epoch 788/1000] Eval loss: 1.2104\n",
      "[Epoch 789/1000] Train loss: 1.2012\n",
      "[Epoch 789/1000] Eval loss: 1.3889\n",
      "[Epoch 790/1000] Train loss: 1.2474\n",
      "[Epoch 790/1000] Eval loss: 1.3696\n",
      "[Epoch 791/1000] Train loss: 1.2588\n",
      "[Epoch 791/1000] Eval loss: 1.3973\n",
      "[Epoch 792/1000] Train loss: 1.2295\n",
      "[Epoch 792/1000] Eval loss: 1.1824\n",
      "[Epoch 793/1000] Train loss: 1.2262\n",
      "[Epoch 793/1000] Eval loss: 1.2981\n",
      "[Epoch 794/1000] Train loss: 1.2197\n",
      "[Epoch 794/1000] Eval loss: 1.1903\n",
      "[Epoch 795/1000] Train loss: 1.2153\n",
      "[Epoch 795/1000] Eval loss: 1.1987\n",
      "[Epoch 796/1000] Train loss: 1.2051\n",
      "[Epoch 796/1000] Eval loss: 1.2815\n",
      "[Epoch 797/1000] Train loss: 1.2153\n",
      "[Epoch 797/1000] Eval loss: 1.2277\n",
      "[Epoch 798/1000] Train loss: 1.2246\n",
      "[Epoch 798/1000] Eval loss: 1.2431\n",
      "[Epoch 799/1000] Train loss: 1.2273\n",
      "[Epoch 799/1000] Eval loss: 1.2284\n",
      "[Epoch 800/1000] Train loss: 1.2056\n",
      "[Epoch 800/1000] Eval loss: 1.2080\n",
      "[Epoch 801/1000] Train loss: 1.2192\n",
      "[Epoch 801/1000] Eval loss: 1.2154\n",
      "[Epoch 802/1000] Train loss: 1.2045\n",
      "[Epoch 802/1000] Eval loss: 1.2408\n",
      "[Epoch 803/1000] Train loss: 1.2242\n",
      "[Epoch 803/1000] Eval loss: 1.2309\n",
      "[Epoch 804/1000] Train loss: 1.2051\n",
      "[Epoch 804/1000] Eval loss: 1.1904\n",
      "[Epoch 805/1000] Train loss: 1.2174\n",
      "[Epoch 805/1000] Eval loss: 1.3492\n",
      "[Epoch 806/1000] Train loss: 1.2249\n",
      "[Epoch 806/1000] Eval loss: 1.2844\n",
      "[Epoch 807/1000] Train loss: 1.2034\n",
      "[Epoch 807/1000] Eval loss: 1.1822\n",
      "[Epoch 808/1000] Train loss: 1.2176\n",
      "[Epoch 808/1000] Eval loss: 1.2831\n",
      "[Epoch 809/1000] Train loss: 1.1985\n",
      "[Epoch 809/1000] Eval loss: 1.2050\n",
      "[Epoch 810/1000] Train loss: 1.2103\n",
      "[Epoch 810/1000] Eval loss: 1.1985\n",
      "[Epoch 811/1000] Train loss: 1.2447\n",
      "[Epoch 811/1000] Eval loss: 1.2203\n",
      "[Epoch 812/1000] Train loss: 1.2228\n",
      "[Epoch 812/1000] Eval loss: 1.2125\n",
      "[Epoch 813/1000] Train loss: 1.2048\n",
      "[Epoch 813/1000] Eval loss: 1.1337\n",
      "[Epoch 814/1000] Train loss: 1.1898\n",
      "[Epoch 814/1000] Eval loss: 1.1605\n",
      "[Epoch 815/1000] Train loss: 1.2061\n",
      "[Epoch 815/1000] Eval loss: 1.2704\n",
      "[Epoch 816/1000] Train loss: 1.1974\n",
      "[Epoch 816/1000] Eval loss: 1.2391\n",
      "[Epoch 817/1000] Train loss: 1.2054\n",
      "[Epoch 817/1000] Eval loss: 1.1956\n",
      "[Epoch 818/1000] Train loss: 1.2211\n",
      "[Epoch 818/1000] Eval loss: 1.2010\n",
      "[Epoch 819/1000] Train loss: 1.2116\n",
      "[Epoch 819/1000] Eval loss: 1.2893\n",
      "[Epoch 820/1000] Train loss: 1.2085\n",
      "[Epoch 820/1000] Eval loss: 1.3274\n",
      "[Epoch 821/1000] Train loss: 1.2277\n",
      "[Epoch 821/1000] Eval loss: 1.1936\n",
      "[Epoch 822/1000] Train loss: 1.1993\n",
      "[Epoch 822/1000] Eval loss: 1.2537\n",
      "[Epoch 823/1000] Train loss: 1.2386\n",
      "[Epoch 823/1000] Eval loss: 1.1598\n",
      "[Epoch 824/1000] Train loss: 1.2229\n",
      "[Epoch 824/1000] Eval loss: 1.2958\n",
      "[Epoch 825/1000] Train loss: 1.2510\n",
      "[Epoch 825/1000] Eval loss: 1.2406\n",
      "[Epoch 826/1000] Train loss: 1.1943\n",
      "[Epoch 826/1000] Eval loss: 1.1716\n",
      "[Epoch 827/1000] Train loss: 1.2240\n",
      "[Epoch 827/1000] Eval loss: 1.2734\n",
      "[Epoch 828/1000] Train loss: 1.1897\n",
      "[Epoch 828/1000] Eval loss: 1.2486\n",
      "[Epoch 829/1000] Train loss: 1.2078\n",
      "[Epoch 829/1000] Eval loss: 1.1865\n",
      "[Epoch 830/1000] Train loss: 1.2068\n",
      "[Epoch 830/1000] Eval loss: 1.2229\n",
      "[Epoch 831/1000] Train loss: 1.1949\n",
      "[Epoch 831/1000] Eval loss: 1.2352\n",
      "[Epoch 832/1000] Train loss: 1.1955\n",
      "[Epoch 832/1000] Eval loss: 1.2136\n",
      "[Epoch 833/1000] Train loss: 1.2170\n",
      "[Epoch 833/1000] Eval loss: 1.2245\n",
      "[Epoch 834/1000] Train loss: 1.2193\n",
      "[Epoch 834/1000] Eval loss: 1.2250\n",
      "[Epoch 835/1000] Train loss: 1.2063\n",
      "[Epoch 835/1000] Eval loss: 1.1518\n",
      "[Epoch 836/1000] Train loss: 1.1848\n",
      "[Epoch 836/1000] Eval loss: 1.1906\n",
      "[Epoch 837/1000] Train loss: 1.1983\n",
      "[Epoch 837/1000] Eval loss: 1.3011\n",
      "[Epoch 838/1000] Train loss: 1.2041\n",
      "[Epoch 838/1000] Eval loss: 1.1730\n",
      "[Epoch 839/1000] Train loss: 1.2029\n",
      "[Epoch 839/1000] Eval loss: 1.1384\n",
      "[Epoch 840/1000] Train loss: 1.1694\n",
      "[Epoch 840/1000] Eval loss: 1.1393\n",
      "[Epoch 841/1000] Train loss: 1.2128\n",
      "[Epoch 841/1000] Eval loss: 1.2085\n",
      "[Epoch 842/1000] Train loss: 1.2079\n",
      "[Epoch 842/1000] Eval loss: 1.3029\n",
      "[Epoch 843/1000] Train loss: 1.2058\n",
      "[Epoch 843/1000] Eval loss: 1.2627\n",
      "[Epoch 844/1000] Train loss: 1.2024\n",
      "[Epoch 844/1000] Eval loss: 1.2460\n",
      "[Epoch 845/1000] Train loss: 1.1989\n",
      "[Epoch 845/1000] Eval loss: 1.3377\n",
      "[Epoch 846/1000] Train loss: 1.2240\n",
      "[Epoch 846/1000] Eval loss: 1.2205\n",
      "[Epoch 847/1000] Train loss: 1.1925\n",
      "[Epoch 847/1000] Eval loss: 1.1795\n",
      "[Epoch 848/1000] Train loss: 1.1859\n",
      "[Epoch 848/1000] Eval loss: 1.2276\n",
      "[Epoch 849/1000] Train loss: 1.2008\n",
      "[Epoch 849/1000] Eval loss: 1.2800\n",
      "[Epoch 850/1000] Train loss: 1.1985\n",
      "[Epoch 850/1000] Eval loss: 1.2316\n",
      "[Epoch 851/1000] Train loss: 1.1926\n",
      "[Epoch 851/1000] Eval loss: 1.2084\n",
      "[Epoch 852/1000] Train loss: 1.1963\n",
      "[Epoch 852/1000] Eval loss: 1.2652\n",
      "[Epoch 853/1000] Train loss: 1.1849\n",
      "[Epoch 853/1000] Eval loss: 1.2098\n",
      "[Epoch 854/1000] Train loss: 1.1903\n",
      "[Epoch 854/1000] Eval loss: 1.2702\n",
      "[Epoch 855/1000] Train loss: 1.2091\n",
      "[Epoch 855/1000] Eval loss: 1.2318\n",
      "[Epoch 856/1000] Train loss: 1.1980\n",
      "[Epoch 856/1000] Eval loss: 1.2833\n",
      "[Epoch 857/1000] Train loss: 1.1905\n",
      "[Epoch 857/1000] Eval loss: 1.2554\n",
      "[Epoch 858/1000] Train loss: 1.2238\n",
      "[Epoch 858/1000] Eval loss: 1.4246\n",
      "[Epoch 859/1000] Train loss: 1.2170\n",
      "[Epoch 859/1000] Eval loss: 1.1811\n",
      "[Epoch 860/1000] Train loss: 1.2347\n",
      "[Epoch 860/1000] Eval loss: 1.1505\n",
      "[Epoch 861/1000] Train loss: 1.2047\n",
      "[Epoch 861/1000] Eval loss: 1.2484\n",
      "[Epoch 862/1000] Train loss: 1.1762\n",
      "[Epoch 862/1000] Eval loss: 1.2498\n",
      "[Epoch 863/1000] Train loss: 1.2077\n",
      "[Epoch 863/1000] Eval loss: 1.2553\n",
      "[Epoch 864/1000] Train loss: 1.2347\n",
      "[Epoch 864/1000] Eval loss: 1.1954\n",
      "[Epoch 865/1000] Train loss: 1.2130\n",
      "[Epoch 865/1000] Eval loss: 1.1619\n",
      "[Epoch 866/1000] Train loss: 1.1928\n",
      "[Epoch 866/1000] Eval loss: 1.2107\n",
      "[Epoch 867/1000] Train loss: 1.1847\n",
      "[Epoch 867/1000] Eval loss: 1.2272\n",
      "[Epoch 868/1000] Train loss: 1.1978\n",
      "[Epoch 868/1000] Eval loss: 1.1952\n",
      "[Epoch 869/1000] Train loss: 1.2203\n",
      "[Epoch 869/1000] Eval loss: 1.2550\n",
      "[Epoch 870/1000] Train loss: 1.1909\n",
      "[Epoch 870/1000] Eval loss: 1.3355\n",
      "[Epoch 871/1000] Train loss: 1.2075\n",
      "[Epoch 871/1000] Eval loss: 1.1968\n",
      "[Epoch 872/1000] Train loss: 1.2104\n",
      "[Epoch 872/1000] Eval loss: 1.2054\n",
      "[Epoch 873/1000] Train loss: 1.1829\n",
      "[Epoch 873/1000] Eval loss: 1.1634\n",
      "[Epoch 874/1000] Train loss: 1.1802\n",
      "[Epoch 874/1000] Eval loss: 1.2598\n",
      "[Epoch 875/1000] Train loss: 1.2303\n",
      "[Epoch 875/1000] Eval loss: 1.2051\n",
      "[Epoch 876/1000] Train loss: 1.1896\n",
      "[Epoch 876/1000] Eval loss: 1.2955\n",
      "[Epoch 877/1000] Train loss: 1.2213\n",
      "[Epoch 877/1000] Eval loss: 1.3125\n",
      "[Epoch 878/1000] Train loss: 1.1801\n",
      "[Epoch 878/1000] Eval loss: 1.2494\n",
      "[Epoch 879/1000] Train loss: 1.2082\n",
      "[Epoch 879/1000] Eval loss: 1.2455\n",
      "[Epoch 880/1000] Train loss: 1.2048\n",
      "[Epoch 880/1000] Eval loss: 1.2036\n",
      "[Epoch 881/1000] Train loss: 1.1693\n",
      "[Epoch 881/1000] Eval loss: 1.2314\n",
      "[Epoch 882/1000] Train loss: 1.1713\n",
      "[Epoch 882/1000] Eval loss: 1.1846\n",
      "[Epoch 883/1000] Train loss: 1.1859\n",
      "[Epoch 883/1000] Eval loss: 1.2247\n",
      "[Epoch 884/1000] Train loss: 1.1931\n",
      "[Epoch 884/1000] Eval loss: 1.2469\n",
      "[Epoch 885/1000] Train loss: 1.1764\n",
      "[Epoch 885/1000] Eval loss: 1.2128\n",
      "[Epoch 886/1000] Train loss: 1.1931\n",
      "[Epoch 886/1000] Eval loss: 1.2418\n",
      "[Epoch 887/1000] Train loss: 1.1835\n",
      "[Epoch 887/1000] Eval loss: 1.3182\n",
      "[Epoch 888/1000] Train loss: 1.2168\n",
      "[Epoch 888/1000] Eval loss: 1.2380\n",
      "[Epoch 889/1000] Train loss: 1.1939\n",
      "[Epoch 889/1000] Eval loss: 1.2520\n",
      "[Epoch 890/1000] Train loss: 1.2276\n",
      "[Epoch 890/1000] Eval loss: 1.3159\n",
      "[Epoch 891/1000] Train loss: 1.1883\n",
      "[Epoch 891/1000] Eval loss: 1.1260\n",
      "[Epoch 892/1000] Train loss: 1.1872\n",
      "[Epoch 892/1000] Eval loss: 1.3987\n",
      "[Epoch 893/1000] Train loss: 1.1865\n",
      "[Epoch 893/1000] Eval loss: 1.2575\n",
      "[Epoch 894/1000] Train loss: 1.1958\n",
      "[Epoch 894/1000] Eval loss: 1.3248\n",
      "[Epoch 895/1000] Train loss: 1.2063\n",
      "[Epoch 895/1000] Eval loss: 1.1862\n",
      "[Epoch 896/1000] Train loss: 1.1909\n",
      "[Epoch 896/1000] Eval loss: 1.2727\n",
      "[Epoch 897/1000] Train loss: 1.1812\n",
      "[Epoch 897/1000] Eval loss: 1.2789\n",
      "[Epoch 898/1000] Train loss: 1.1712\n",
      "[Epoch 898/1000] Eval loss: 1.3065\n",
      "[Epoch 899/1000] Train loss: 1.1842\n",
      "[Epoch 899/1000] Eval loss: 1.2185\n",
      "[Epoch 900/1000] Train loss: 1.1722\n",
      "[Epoch 900/1000] Eval loss: 1.2413\n",
      "[Epoch 901/1000] Train loss: 1.2041\n",
      "[Epoch 901/1000] Eval loss: 1.1964\n",
      "[Epoch 902/1000] Train loss: 1.1634\n",
      "[Epoch 902/1000] Eval loss: 1.2568\n",
      "[Epoch 903/1000] Train loss: 1.1865\n",
      "[Epoch 903/1000] Eval loss: 1.1434\n",
      "[Epoch 904/1000] Train loss: 1.1843\n",
      "[Epoch 904/1000] Eval loss: 1.1517\n",
      "[Epoch 905/1000] Train loss: 1.1763\n",
      "[Epoch 905/1000] Eval loss: 1.2492\n",
      "[Epoch 906/1000] Train loss: 1.1809\n",
      "[Epoch 906/1000] Eval loss: 1.2176\n",
      "[Epoch 907/1000] Train loss: 1.2001\n",
      "[Epoch 907/1000] Eval loss: 1.2828\n",
      "[Epoch 908/1000] Train loss: 1.1981\n",
      "[Epoch 908/1000] Eval loss: 1.0864\n",
      "[Epoch 909/1000] Train loss: 1.1777\n",
      "[Epoch 909/1000] Eval loss: 1.1678\n",
      "[Epoch 910/1000] Train loss: 1.1795\n",
      "[Epoch 910/1000] Eval loss: 1.2469\n",
      "[Epoch 911/1000] Train loss: 1.1842\n",
      "[Epoch 911/1000] Eval loss: 1.2172\n",
      "[Epoch 912/1000] Train loss: 1.1745\n",
      "[Epoch 912/1000] Eval loss: 1.2181\n",
      "[Epoch 913/1000] Train loss: 1.1918\n",
      "[Epoch 913/1000] Eval loss: 1.2839\n",
      "[Epoch 914/1000] Train loss: 1.1834\n",
      "[Epoch 914/1000] Eval loss: 1.2072\n",
      "[Epoch 915/1000] Train loss: 1.1692\n",
      "[Epoch 915/1000] Eval loss: 1.2007\n",
      "[Epoch 916/1000] Train loss: 1.2151\n",
      "[Epoch 916/1000] Eval loss: 1.1763\n",
      "[Epoch 917/1000] Train loss: 1.1876\n",
      "[Epoch 917/1000] Eval loss: 1.2644\n",
      "[Epoch 918/1000] Train loss: 1.1969\n",
      "[Epoch 918/1000] Eval loss: 1.2017\n",
      "[Epoch 919/1000] Train loss: 1.1833\n",
      "[Epoch 919/1000] Eval loss: 1.2549\n",
      "[Epoch 920/1000] Train loss: 1.2051\n",
      "[Epoch 920/1000] Eval loss: 1.2184\n",
      "[Epoch 921/1000] Train loss: 1.2021\n",
      "[Epoch 921/1000] Eval loss: 1.2340\n",
      "[Epoch 922/1000] Train loss: 1.1904\n",
      "[Epoch 922/1000] Eval loss: 1.2080\n",
      "[Epoch 923/1000] Train loss: 1.1647\n",
      "[Epoch 923/1000] Eval loss: 1.2391\n",
      "[Epoch 924/1000] Train loss: 1.1824\n",
      "[Epoch 924/1000] Eval loss: 1.3024\n",
      "[Epoch 925/1000] Train loss: 1.1742\n",
      "[Epoch 925/1000] Eval loss: 1.3004\n",
      "[Epoch 926/1000] Train loss: 1.2384\n",
      "[Epoch 926/1000] Eval loss: 1.1594\n",
      "[Epoch 927/1000] Train loss: 1.1847\n",
      "[Epoch 927/1000] Eval loss: 1.2361\n",
      "[Epoch 928/1000] Train loss: 1.1884\n",
      "[Epoch 928/1000] Eval loss: 1.2307\n",
      "[Epoch 929/1000] Train loss: 1.2102\n",
      "[Epoch 929/1000] Eval loss: 1.2291\n",
      "[Epoch 930/1000] Train loss: 1.1887\n",
      "[Epoch 930/1000] Eval loss: 1.1906\n",
      "[Epoch 931/1000] Train loss: 1.1957\n",
      "[Epoch 931/1000] Eval loss: 1.2706\n",
      "[Epoch 932/1000] Train loss: 1.1679\n",
      "[Epoch 932/1000] Eval loss: 1.2469\n",
      "[Epoch 933/1000] Train loss: 1.2097\n",
      "[Epoch 933/1000] Eval loss: 1.2680\n",
      "[Epoch 934/1000] Train loss: 1.1912\n",
      "[Epoch 934/1000] Eval loss: 1.1617\n",
      "[Epoch 935/1000] Train loss: 1.1753\n",
      "[Epoch 935/1000] Eval loss: 1.2535\n",
      "[Epoch 936/1000] Train loss: 1.1996\n",
      "[Epoch 936/1000] Eval loss: 1.2108\n",
      "[Epoch 937/1000] Train loss: 1.1845\n",
      "[Epoch 937/1000] Eval loss: 1.1710\n",
      "[Epoch 938/1000] Train loss: 1.1650\n",
      "[Epoch 938/1000] Eval loss: 1.2167\n",
      "[Epoch 939/1000] Train loss: 1.2011\n",
      "[Epoch 939/1000] Eval loss: 1.2482\n",
      "[Epoch 940/1000] Train loss: 1.2008\n",
      "[Epoch 940/1000] Eval loss: 1.1948\n",
      "[Epoch 941/1000] Train loss: 1.2304\n",
      "[Epoch 941/1000] Eval loss: 1.2722\n",
      "[Epoch 942/1000] Train loss: 1.1792\n",
      "[Epoch 942/1000] Eval loss: 1.1684\n",
      "[Epoch 943/1000] Train loss: 1.1802\n",
      "[Epoch 943/1000] Eval loss: 1.2702\n",
      "[Epoch 944/1000] Train loss: 1.2031\n",
      "[Epoch 944/1000] Eval loss: 1.2168\n",
      "[Epoch 945/1000] Train loss: 1.1939\n",
      "[Epoch 945/1000] Eval loss: 1.1542\n",
      "[Epoch 946/1000] Train loss: 1.2088\n",
      "[Epoch 946/1000] Eval loss: 1.1912\n",
      "[Epoch 947/1000] Train loss: 1.2064\n",
      "[Epoch 947/1000] Eval loss: 1.1935\n",
      "[Epoch 948/1000] Train loss: 1.2103\n",
      "[Epoch 948/1000] Eval loss: 1.1944\n",
      "[Epoch 949/1000] Train loss: 1.1673\n",
      "[Epoch 949/1000] Eval loss: 1.1623\n",
      "[Epoch 950/1000] Train loss: 1.1643\n",
      "[Epoch 950/1000] Eval loss: 1.1252\n",
      "[Epoch 951/1000] Train loss: 1.1904\n",
      "[Epoch 951/1000] Eval loss: 1.1998\n",
      "[Epoch 952/1000] Train loss: 1.1577\n",
      "[Epoch 952/1000] Eval loss: 1.2150\n",
      "[Epoch 953/1000] Train loss: 1.1941\n",
      "[Epoch 953/1000] Eval loss: 1.2733\n",
      "[Epoch 954/1000] Train loss: 1.1553\n",
      "[Epoch 954/1000] Eval loss: 1.1917\n",
      "[Epoch 955/1000] Train loss: 1.1846\n",
      "[Epoch 955/1000] Eval loss: 1.2750\n",
      "[Epoch 956/1000] Train loss: 1.1629\n",
      "[Epoch 956/1000] Eval loss: 1.2073\n",
      "[Epoch 957/1000] Train loss: 1.1847\n",
      "[Epoch 957/1000] Eval loss: 1.3665\n",
      "[Epoch 958/1000] Train loss: 1.1740\n",
      "[Epoch 958/1000] Eval loss: 1.2847\n",
      "[Epoch 959/1000] Train loss: 1.1717\n",
      "[Epoch 959/1000] Eval loss: 1.2440\n",
      "[Epoch 960/1000] Train loss: 1.1831\n",
      "[Epoch 960/1000] Eval loss: 1.2345\n",
      "[Epoch 961/1000] Train loss: 1.1646\n",
      "[Epoch 961/1000] Eval loss: 1.1761\n",
      "[Epoch 962/1000] Train loss: 1.1788\n",
      "[Epoch 962/1000] Eval loss: 1.1924\n",
      "[Epoch 963/1000] Train loss: 1.1697\n",
      "[Epoch 963/1000] Eval loss: 1.2952\n",
      "[Epoch 964/1000] Train loss: 1.1687\n",
      "[Epoch 964/1000] Eval loss: 1.2165\n",
      "[Epoch 965/1000] Train loss: 1.1728\n",
      "[Epoch 965/1000] Eval loss: 1.1991\n",
      "[Epoch 966/1000] Train loss: 1.1860\n",
      "[Epoch 966/1000] Eval loss: 1.2923\n",
      "[Epoch 967/1000] Train loss: 1.1630\n",
      "[Epoch 967/1000] Eval loss: 1.2294\n",
      "[Epoch 968/1000] Train loss: 1.1937\n",
      "[Epoch 968/1000] Eval loss: 1.1976\n",
      "[Epoch 969/1000] Train loss: 1.2103\n",
      "[Epoch 969/1000] Eval loss: 1.2428\n",
      "[Epoch 970/1000] Train loss: 1.1627\n",
      "[Epoch 970/1000] Eval loss: 1.2704\n",
      "[Epoch 971/1000] Train loss: 1.1840\n",
      "[Epoch 971/1000] Eval loss: 1.1946\n",
      "[Epoch 972/1000] Train loss: 1.1890\n",
      "[Epoch 972/1000] Eval loss: 1.1989\n",
      "[Epoch 973/1000] Train loss: 1.2020\n",
      "[Epoch 973/1000] Eval loss: 1.2725\n",
      "[Epoch 974/1000] Train loss: 1.1940\n",
      "[Epoch 974/1000] Eval loss: 1.3305\n",
      "[Epoch 975/1000] Train loss: 1.2547\n",
      "[Epoch 975/1000] Eval loss: 1.1999\n",
      "[Epoch 976/1000] Train loss: 1.1639\n",
      "[Epoch 976/1000] Eval loss: 1.2820\n",
      "[Epoch 977/1000] Train loss: 1.1721\n",
      "[Epoch 977/1000] Eval loss: 1.2324\n",
      "[Epoch 978/1000] Train loss: 1.1896\n",
      "[Epoch 978/1000] Eval loss: 1.2779\n",
      "[Epoch 979/1000] Train loss: 1.1937\n",
      "[Epoch 979/1000] Eval loss: 1.2402\n",
      "[Epoch 980/1000] Train loss: 1.1939\n",
      "[Epoch 980/1000] Eval loss: 1.2126\n",
      "[Epoch 981/1000] Train loss: 1.1745\n",
      "[Epoch 981/1000] Eval loss: 1.2702\n",
      "[Epoch 982/1000] Train loss: 1.1581\n",
      "[Epoch 982/1000] Eval loss: 1.1790\n",
      "[Epoch 983/1000] Train loss: 1.1697\n",
      "[Epoch 983/1000] Eval loss: 1.1907\n",
      "[Epoch 984/1000] Train loss: 1.1651\n",
      "[Epoch 984/1000] Eval loss: 1.2758\n",
      "[Epoch 985/1000] Train loss: 1.1663\n",
      "[Epoch 985/1000] Eval loss: 1.2250\n",
      "[Epoch 986/1000] Train loss: 1.1858\n",
      "[Epoch 986/1000] Eval loss: 1.3399\n",
      "[Epoch 987/1000] Train loss: 1.1884\n",
      "[Epoch 987/1000] Eval loss: 1.2579\n",
      "[Epoch 988/1000] Train loss: 1.2068\n",
      "[Epoch 988/1000] Eval loss: 1.1927\n",
      "[Epoch 989/1000] Train loss: 1.1672\n",
      "[Epoch 989/1000] Eval loss: 1.2117\n",
      "[Epoch 990/1000] Train loss: 1.1723\n",
      "[Epoch 990/1000] Eval loss: 1.2221\n",
      "[Epoch 991/1000] Train loss: 1.1688\n",
      "[Epoch 991/1000] Eval loss: 1.3083\n",
      "[Epoch 992/1000] Train loss: 1.1641\n",
      "[Epoch 992/1000] Eval loss: 1.2979\n",
      "[Epoch 993/1000] Train loss: 1.1975\n",
      "[Epoch 993/1000] Eval loss: 1.2404\n",
      "[Epoch 994/1000] Train loss: 1.1828\n",
      "[Epoch 994/1000] Eval loss: 1.1907\n",
      "[Epoch 995/1000] Train loss: 1.1830\n",
      "[Epoch 995/1000] Eval loss: 1.2853\n",
      "[Epoch 996/1000] Train loss: 1.2049\n",
      "[Epoch 996/1000] Eval loss: 1.2296\n",
      "[Epoch 997/1000] Train loss: 1.1546\n",
      "[Epoch 997/1000] Eval loss: 1.1611\n",
      "[Epoch 998/1000] Train loss: 1.1710\n",
      "[Epoch 998/1000] Eval loss: 1.2413\n",
      "[Epoch 999/1000] Train loss: 1.1578\n",
      "[Epoch 999/1000] Eval loss: 1.2777\n",
      "[Epoch 1000/1000] Train loss: 1.1734\n",
      "[Epoch 1000/1000] Eval loss: 1.2232\n"
     ]
    }
   ],
   "source": [
    "# trainer\n",
    "model = MLP_Model(input_dim=x_train.shape[1]).to(device)\n",
    "n_epochs = config['n_epochs']\n",
    "criterion = nn.MSELoss(reduction='mean')  # define loss function\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=config['learning_rate'], momentum=0.7)  # define optimizer\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # train\n",
    "    model.train()\n",
    "    loss_record = []\n",
    "    for X, y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        pred = model(X)\n",
    "        loss = criterion(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_record.append(loss.detach().item())  # loss value of a batch : loss.detach().item()\n",
    "    mean_train_loss = sum(loss_record) / len(loss_record)\n",
    "    \n",
    "    print(f'Epoch [{epoch + 1:03d}/{n_epochs:03d}] Train loss: {mean_train_loss:.4f}')\n",
    "    \n",
    "    # evaluate\n",
    "    model.eval()\n",
    "    loss_record = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in valid_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            loss = criterion(pred, y)\n",
    "            loss_record.append(loss.detach().item())  # loss value of a batch : loss.detach().item()\n",
    "    mean_eval_loss = sum(loss_record) / len(loss_record)\n",
    "    \n",
    "    print(f'Epoch [{epoch + 1:03d}/{n_epochs:03d}] Eval loss: {mean_eval_loss:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 469.349643,
   "end_time": "2023-02-23T07:01:18.426352",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-02-23T06:53:29.076709",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
